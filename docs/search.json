[
  {
    "objectID": "posts/text-analisis-sentimiento/index.html",
    "href": "posts/text-analisis-sentimiento/index.html",
    "title": "Análisis de texto: sentimientos",
    "section": "",
    "text": "Después del primer intento de analizar texto, en español, sentí que todavía se podían hacer más cosas. Además, he descubierto que aquí puedo meter cosas interactivas. Ahora quiero seguir experimentando con ese tipo de cosas, y ampliar lo de análisis de texto.\nTodas las ideas de análisis de texto vienen del increíble texto de Julia Silge: Text Mining with R. Hay un montón de material para investigar de cómo hacer análisis de texto en inglés. Análisis en español reproducibles también hay, pero no todos son tan amigables (que es algo que yo siempre intento). Voy a utilizar el mismo conjunto de datos de la entrada anterior y que pueden descargar aquí).\n\npacman::p_load(tidyverse, tidytext, tm, wordcloud2, plotly)\n\nSon los mismos paquetes de la vez pasada más una sorpresa: plotly, paquete que nos permite que al pasar el cursor sobre la gráfica nos dé información. Sé que se puede hacer más, pero lo iré explorando de a poco.\nEl análisis de sentimiento es, de manera muy simplificada y sencilla, evaluar la intención de una palabra para ver si se dice con un “tono” positivo o negativo, qué emoción expresa y como se relacionan. Yo sé que suena muy sencillo, pero al mismo tiempo requirió mucho trabajo e investigaciones llegar a este punto.\nEl inicio es igual. Conseguimos datos de texto, los ordenamos (tidy), luego separamos las palabras (unnest tokens), limpiamos la nueva base de datos (quitar stop words) y a partir de este punto podemos hacer análisis más interesantes.\n\ninp &lt;- \"D:/dhumb/Documents/projects/data_blog\"\n\ndata &lt;- read.csv(paste(inp, \"datos_sismo.csv\", sep =\"/\"), \n                 stringsAsFactors = F) %&gt;% \n  select(Sujeto, Informacion_objeto) %&gt;% \n  mutate(\n    Informacion_objeto = str_remove_all(Informacion_objeto, \"[[:digit:]]\"),\n    Informacion_objeto = str_remove_all(Informacion_objeto, \"[[:punct:]]\"),\n    Informacion_objeto = str_squish(Informacion_objeto)\n  )\n\n\nprim &lt;- data %&gt;% \n  unnest_tokens(Palabra, Informacion_objeto) %&gt;% \n  filter(!Palabra %in% stopwords(\"es\")) %&gt;% \n  mutate(filtro = ifelse(nchar(Palabra)&lt; 4, 1, 0)) %&gt;% \n  filter(filtro == 0) %&gt;% \n  select(-filtro) %&gt;% \n  count(Palabra) %&gt;% \n  arrange(-n)\n\nAhora, vamos a cargar el léxico “afinn”. Esto lo encontré en este blog de Juan Bosco Mendoza (máximo respeto). Dejemos que él nos explique qué es este lexicon.\nPara este análisis de sentimiento usaremos el léxico Afinn. Este es un conjunto de palabras, puntuadas de acuerdo a qué tan positivamente o negativamente son percibidas. Las palabras que son percibidas de manera positiva tienen puntuaciones de -4 a -1; y las positivas de 1 a 4.\nLa versión que usaremos es una traducción automática, de inglés a español, de la versión del léxico presente en el conjunto de datos sentiments de tidytext, con algunas correcciones manuales. Por supuesto, esto quiere decir que este léxico tendrá algunos defectos, pero será suficiente para nuestro análisis.\nDescargamos este léxico de la siguiente dirección: https://raw.githubusercontent.com/jboscomendoza/rpubs/master/sentimientos_afinn/lexico_afinn.en.es.csv\n\nafinn &lt;- read.csv(\"https://raw.githubusercontent.com/jboscomendoza/rpubs/master/sentimientos_afinn/lexico_afinn.en.es.csv\")\n\nComo es un link de un archivo csv podemos cargarlo sin descargarlo en R :D\n\npaf &lt;- inner_join(prim, afinn, by = \"Palabra\") %&gt;% \n  mutate(tipo = ifelse(Puntuacion &gt; 0, \"Positiva\", \"Negativa\"))\n\nWarning in inner_join(prim, afinn, by = \"Palabra\"): Each row in `x` is expected to match at most 1 row in `y`.\nℹ Row 67 of `x` matches multiple rows.\nℹ If multiple matches are expected, set `multiple = \"all\"` to silence this\n  warning.\n\ndim(prim)\n\n[1] 8143    2\n\ndim(paf)\n\n[1] 297   5\n\n\nPara el tema de sentimientos, unimos las bases de datos solo con las observaciones que están en ambas. Por esa razón, podemos observar que en el análisis original hay 8,520 palabras, mientras que ya unidas solo hay 329 palabras.\n\n\n\nprim %&gt;% \n  top_n(50) %&gt;% \n  ggplot(aes(x = reorder(Palabra, n), y =  n)) +\n  geom_bar(stat = \"identity\") + \n  coord_flip() +\n  labs(x = \"\", y = \"Frecuencia\", title = \"Palabras!!\")\n\nSelecting by n\n\n\n\n\n\n\n\n\n\nQue bonita gráfica, no? Es lo que ya sabemos hacer en ggplot: datos, variables a gráficar (aes), el tipo de gráfica que queremos (geom), la giramos (coord_flip) y le ponemos etiquetas (labs). Esto funciona bien para publicaciones, pero quiero intentar hacer gráficas interactivas\n\np50 &lt;- prim %&gt;% \n  top_n(50)\n\nSelecting by n\n\nplot_ly(p50, y = ~Palabra, x = ~n, type = \"bar\") %&gt;% \n  layout(title = \"Palabras!!\",\n         xaxis = list(title = \"\"),\n         yaxis = list(title = \"\"))\n\n\n\n\n\nComo mencioné, sigo aprendiendo a usar plotly si saben de otro lugar para aprender avísenme. Pero, regresemos al análisis de sentimientos.\n\nsent &lt;- ggplot(paf, aes(x = reorder(Palabra, n), y = n, fill = tipo)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  labs(title = \"Sentimientos\", x = \"\", y = \"\")\n\nggplotly(sent)\n\n\n\n\n\nOtra de las ventajas de plotly es que te permite convertir tus gráficas de ggplot en gráficas interactivas: puedes graficar todas las palabras y le haces zoom al área que quieras.\nYa que tenemos un conjunto de datos por sentimiento, vamos a crear dos nubes de palabras. Una con sentimientos positivos y otra con sentimientos negativos.\nNube de palabras negativa\n\nset.seed(123)\nnube_n &lt;- paf %&gt;% \n  filter(tipo == \"Negativa\")\nnega &lt;- wordcloud2(nube_n)\nnega\n\n\n\n\n\nNube de palabras positivas:\n\nnube_p &lt;- paf %&gt;% \n  filter(tipo == \"Positiva\")\nposi &lt;- wordcloud2(nube_p)\nposi\n\n\n\n\n\nCon esto tenemos una primera aproximación al análisis de sentimientos en español. Hay un paquete llamado syuzhet que encontré gracias a desareca. Voy a seguir investigando para hacer mejores análisis.\n¡Muchas gracias por leerme!"
  },
  {
    "objectID": "posts/text-analisis-sentimiento/index.html#gráficas",
    "href": "posts/text-analisis-sentimiento/index.html#gráficas",
    "title": "Análisis de texto: sentimientos",
    "section": "",
    "text": "prim %&gt;% \n  top_n(50) %&gt;% \n  ggplot(aes(x = reorder(Palabra, n), y =  n)) +\n  geom_bar(stat = \"identity\") + \n  coord_flip() +\n  labs(x = \"\", y = \"Frecuencia\", title = \"Palabras!!\")\n\nSelecting by n\n\n\n\n\n\n\n\n\n\nQue bonita gráfica, no? Es lo que ya sabemos hacer en ggplot: datos, variables a gráficar (aes), el tipo de gráfica que queremos (geom), la giramos (coord_flip) y le ponemos etiquetas (labs). Esto funciona bien para publicaciones, pero quiero intentar hacer gráficas interactivas\n\np50 &lt;- prim %&gt;% \n  top_n(50)\n\nSelecting by n\n\nplot_ly(p50, y = ~Palabra, x = ~n, type = \"bar\") %&gt;% \n  layout(title = \"Palabras!!\",\n         xaxis = list(title = \"\"),\n         yaxis = list(title = \"\"))\n\n\n\n\n\nComo mencioné, sigo aprendiendo a usar plotly si saben de otro lugar para aprender avísenme. Pero, regresemos al análisis de sentimientos.\n\nsent &lt;- ggplot(paf, aes(x = reorder(Palabra, n), y = n, fill = tipo)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  labs(title = \"Sentimientos\", x = \"\", y = \"\")\n\nggplotly(sent)\n\n\n\n\n\nOtra de las ventajas de plotly es que te permite convertir tus gráficas de ggplot en gráficas interactivas: puedes graficar todas las palabras y le haces zoom al área que quieras.\nYa que tenemos un conjunto de datos por sentimiento, vamos a crear dos nubes de palabras. Una con sentimientos positivos y otra con sentimientos negativos.\nNube de palabras negativa\n\nset.seed(123)\nnube_n &lt;- paf %&gt;% \n  filter(tipo == \"Negativa\")\nnega &lt;- wordcloud2(nube_n)\nnega\n\n\n\n\n\nNube de palabras positivas:\n\nnube_p &lt;- paf %&gt;% \n  filter(tipo == \"Positiva\")\nposi &lt;- wordcloud2(nube_p)\nposi\n\n\n\n\n\nCon esto tenemos una primera aproximación al análisis de sentimientos en español. Hay un paquete llamado syuzhet que encontré gracias a desareca. Voy a seguir investigando para hacer mejores análisis.\n¡Muchas gracias por leerme!"
  },
  {
    "objectID": "posts/shiny/index.html",
    "href": "posts/shiny/index.html",
    "title": "Mini intro a Chainy (Shiny)",
    "section": "",
    "text": "A ustedes no les pasa que sienten que pueden hacer algo mejor, ¿pero no saben exactamente qué falta? A mí me pasa seguido, pero afortunadamente el internet tiene cosas preciosas que te invitan a intentarlo. Y luego de ver todas las cosas bonitas que se pueden hacer en Shiny decidí seguir este tutorial, el cheatsheet y las recomendaciones de R ladies\nAhora, para no perder la bonita costumbre de trabajar con datos de solicitudes, también he estado leyendo sobre los modelos de word embedding para Procesamiento de Lenguaje Natural (PLN) word2vec y doc2vec. En resumen, estos modelos de machine learning lo que hacen es encontrar palabras por contextos similares (palabras adyacentes). Por ejemplo, nuestros teclados en los celulares de autocorrector, o cuando buscas algo en Google y completa el texto. Me he inspirado de diversos trabajos en español: como este análisis de rap, un ejercicio para detectar noticias falsas y un artículo sobre un centro de emergencias de la Universidad del Azuay, Ecuador.\nEntonces, en esta entrada haré lo siguiente: de un conjunto de datos de solicitudes de información pública realizaré un clasificador temático con doc2vec, y los resultados serán presentados en una web app interactiva para que la exploren por ustedes mismas, para que no vean solo lo que les presento.\nLas SIP utilizadas corresponden a las dieciséis alcaldías de la Ciudad de México, mi fuente de información es el Instituto Nacional de Transparencia, Acceso a la Información y Proteccion de Datos Personales (INAI)\n\n\nCuando buscas y descargas los “datos abiertos” de la Plataforma Nacional de Transparencia (PNT), te devuelve un archivo de tipo zip en tu correo. Desde que empiezas la búsqueda hasta recibir el correo pasan entre 15 y 20 minutos.\nPara conservar los datos de la manera en que se cargaron a la PNT, voy a reutilizar los csv de este proyecto pero que estoy haciendo en python. Posteriormente, voy a unir todos los archivos en una sola base de datos para utilizar tidyverse para limpiar los datos.\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(purrr)\nlibrary(readr)\n\nWarning: package 'readr' was built under R version 4.3.3\n\nlibrary(shiny)\n\nWarning: package 'shiny' was built under R version 4.3.3\n\nlibrary(udpipe)\n\nWarning: package 'udpipe' was built under R version 4.3.3\n\nlibrary(stringr)\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\nlibrary(doc2vec)\n\nWarning: package 'doc2vec' was built under R version 4.3.3\n\nlibrary(word2vec)\n\nWarning: package 'word2vec' was built under R version 4.3.3\n\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\n\nComo siempre, a mí me gusta ‘llamar’ las librerías con las que voy a trabajar en el primer código. Luego ‘leo’ todos los csv. En esta ocasión utilicé el paquete reader en lugar de la función base de R read.csv porque me salían mensajes de error por el encoding.\n\ndirectory &lt;- \"C:/Users/dhumb/Documents/projects/sip-alcaldias-nlp/data/SIP\"  \nfiles &lt;- list.files(directory)\n\ndata &lt;- map(files,\n            ~ read_csv(paste(directory, .x, sep = \"/\"), \n                       locale = locale(encoding = \"latin1\"),\n                       show_col_types = FALSE) %&gt;% \n                         as_tibble() %&gt;% \n                         mutate_all(as.character)) %&gt;% \n  bind_rows() \n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\nsummary(data)\n\n    FOLIO           FECHASOLICITUD     DEPENDENCIA          ESTATUS         \n Length:212235      Length:212235      Length:212235      Length:212235     \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n MEDIOENTRADA       TIPOSOLICITUD      DESCRIPCIONSOLICITUD  OTROSDATOS       \n Length:212235      Length:212235      Length:212235        Length:212235     \n Class :character   Class :character   Class :character     Class :character  \n Mode  :character   Mode  :character   Mode  :character     Mode  :character  \n ARCHIVOADJUNTOSOLICITUD MEDIOENTREGA       FECHALIMITE       \n Length:212235           Length:212235      Length:212235     \n Class :character        Class :character   Class :character  \n Mode  :character        Mode  :character   Mode  :character  \n  RESPUESTA         TEXTORESPUESTA     FECHARESPUESTA     FECHASOLICITUDTERMINO\n Length:212235      Length:212235      Length:212235      Length:212235        \n Class :character   Class :character   Class :character   Class :character     \n Mode  :character   Mode  :character   Mode  :character   Mode  :character     \n     PAIS              ESTADO           MUNICIPIO         CODIGOPOSTAL      \n Length:212235      Length:212235      Length:212235      Length:212235     \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n    SECTOR            PRORROGA          PREVENCION        DISPONIBILIDAD    \n Length:212235      Length:212235      Length:212235      Length:212235     \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n TIPODERECHOARCOP      QUEJA          \n Length:212235      Length:212235     \n Class :character   Class :character  \n Mode  :character   Mode  :character  \n\n\nPosteriormente, hice una breve limpieza de datos. Había hecho una para reemplazar nombres de alcaldías, pero coinciden con aquellas solicitudes sobre datos personales.\n\ndata &lt;- data %&gt;% \n  filter(TIPOSOLICITUD == 'Información pública') %&gt;% #Porque solo nos interesan las SIP, y habia 16 de datos personales\n  mutate(\n    FECHASOLICITUD = dmy(FECHASOLICITUD),\n    FECHALIMITE = dmy(FECHALIMITE),\n    FECHARESPUESTA = dmy(FECHARESPUESTA),\n    FECHASOLICITUDTERMINO = dmy(FECHASOLICITUDTERMINO),\n    DEPENDENCIA = str_remove_all(DEPENDENCIA, \"Alcaldía\"),\n    DEPENDENCIA = str_trim(DEPENDENCIA, 'both'),\n    FOLIO = str_remove_all(FOLIO, \"[:punct:]\"),\n    FOLIO = str_remove_all(FOLIO, \"=\")\n  )\n\nsummary(data)\n\n    FOLIO           FECHASOLICITUD       DEPENDENCIA          ESTATUS         \n Length:208436      Min.   :2019-02-22   Length:208436      Length:208436     \n Class :character   1st Qu.:2020-03-08   Class :character   Class :character  \n Mode  :character   Median :2021-12-10   Mode  :character   Mode  :character  \n                    Mean   :2021-09-26                                        \n                    3rd Qu.:2023-03-08                                        \n                    Max.   :2024-02-25                                        \n                                                                              \n MEDIOENTRADA       TIPOSOLICITUD      DESCRIPCIONSOLICITUD  OTROSDATOS       \n Length:208436      Length:208436      Length:208436        Length:208436     \n Class :character   Class :character   Class :character     Class :character  \n Mode  :character   Mode  :character   Mode  :character     Mode  :character  \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n ARCHIVOADJUNTOSOLICITUD MEDIOENTREGA        FECHALIMITE        \n Length:208436           Length:208436      Min.   :2019-03-08  \n Class :character        Class :character   1st Qu.:2020-04-20  \n Mode  :character        Mode  :character   Median :2022-01-13  \n                                            Mean   :2021-11-11  \n                                            3rd Qu.:2023-03-24  \n                                            Max.   :2024-03-15  \n                                            NA's   :380         \n  RESPUESTA         TEXTORESPUESTA     FECHARESPUESTA      \n Length:208436      Length:208436      Min.   :2019-02-26  \n Class :character   Class :character   1st Qu.:2020-04-20  \n Mode  :character   Mode  :character   Median :2021-12-16  \n                                       Mean   :2021-10-30  \n                                       3rd Qu.:2023-03-10  \n                                       Max.   :2024-02-25  \n                                       NA's   :1747        \n FECHASOLICITUDTERMINO     PAIS              ESTADO           MUNICIPIO        \n Min.   :2019-02-26    Length:208436      Length:208436      Length:208436     \n 1st Qu.:2020-04-20    Class :character   Class :character   Class :character  \n Median :2021-12-16    Mode  :character   Mode  :character   Mode  :character  \n Mean   :2021-10-29                                                            \n 3rd Qu.:2023-03-09                                                            \n Max.   :2024-02-25                                                            \n NA's   :2291                                                                  \n CODIGOPOSTAL          SECTOR            PRORROGA          PREVENCION       \n Length:208436      Length:208436      Length:208436      Length:208436     \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n DISPONIBILIDAD     TIPODERECHOARCOP      QUEJA          \n Length:208436      Length:208436      Length:208436     \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n                                                         \n\n\nComo pueden observar, hay un total de 208,436 solicitudes para el periodo 2019-2024 en las 16 alcaldías de la CDMX. Luego, doc2vec tiene la restricción de que los textos no deben superar las mil palabras. Por eso cree la variable y aplique un filtro. Para terminar trabajando con 206,566 solicitudes.\n\ndata &lt;- data %&gt;% \n  mutate(\n    txt_clean_word2vec(DESCRIPCIONSOLICITUD),\n    nword = txt_count_words(DESCRIPCIONSOLICITUD)\n  ) %&gt;% \n  filter(nword &gt; 0 & nword &lt;= 1000)\nsummary(data)\n\n    FOLIO           FECHASOLICITUD       DEPENDENCIA          ESTATUS         \n Length:206566      Min.   :2019-02-22   Length:206566      Length:206566     \n Class :character   1st Qu.:2020-03-08   Class :character   Class :character  \n Mode  :character   Median :2021-12-01   Mode  :character   Mode  :character  \n                    Mean   :2021-09-26                                        \n                    3rd Qu.:2023-03-10                                        \n                    Max.   :2024-02-25                                        \n                                                                              \n MEDIOENTRADA       TIPOSOLICITUD      DESCRIPCIONSOLICITUD  OTROSDATOS       \n Length:206566      Length:206566      Length:206566        Length:206566     \n Class :character   Class :character   Class :character     Class :character  \n Mode  :character   Mode  :character   Mode  :character     Mode  :character  \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n ARCHIVOADJUNTOSOLICITUD MEDIOENTREGA        FECHALIMITE        \n Length:206566           Length:206566      Min.   :2019-03-08  \n Class :character        Class :character   1st Qu.:2020-04-20  \n Mode  :character        Mode  :character   Median :2021-12-29  \n                                            Mean   :2021-11-11  \n                                            3rd Qu.:2023-03-29  \n                                            Max.   :2024-03-15  \n                                            NA's   :380         \n  RESPUESTA         TEXTORESPUESTA     FECHARESPUESTA      \n Length:206566      Length:206566      Min.   :2019-02-26  \n Class :character   Class :character   1st Qu.:2020-04-20  \n Mode  :character   Mode  :character   Median :2021-12-16  \n                                       Mean   :2021-10-30  \n                                       3rd Qu.:2023-03-15  \n                                       Max.   :2024-02-25  \n                                       NA's   :1747        \n FECHASOLICITUDTERMINO     PAIS              ESTADO           MUNICIPIO        \n Min.   :2019-02-26    Length:206566      Length:206566      Length:206566     \n 1st Qu.:2020-04-20    Class :character   Class :character   Class :character  \n Median :2021-12-14    Mode  :character   Mode  :character   Mode  :character  \n Mean   :2021-10-28                                                            \n 3rd Qu.:2023-03-14                                                            \n Max.   :2024-02-25                                                            \n NA's   :2291                                                                  \n CODIGOPOSTAL          SECTOR            PRORROGA          PREVENCION       \n Length:206566      Length:206566      Length:206566      Length:206566     \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n DISPONIBILIDAD     TIPODERECHOARCOP      QUEJA          \n Length:206566      Length:206566      Length:206566     \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n                                                         \n txt_clean_word2vec(DESCRIPCIONSOLICITUD)     nword        \n Length:206566                            Min.   :   1.00  \n Class :character                         1st Qu.:  29.00  \n Mode  :character                         Median :  55.00  \n                                          Mean   :  90.47  \n                                          3rd Qu.: 109.00  \n                                          Max.   :1000.00  \n                                                           \n\n\n\n\n\nY ahora es momento de utilizar doc2vec. Para entenderlo, es necesario explicar que este es una extensión de la arquitectura de machine learning word2vec. Esta detecta el contexto de las palabras de acuerdo a sus palabras vecinas. Hay dos modelos: Continous Bag of Words (CBOW) que predice la palabra objetivo de acuerdo con las palabras de alrededor, y se recomienda para datos pequeños. Y el otro, Continous Skip-Gram Model que funciona al revés: a partir de una palabra objetivo, predice las palabras de contexto. Este se recomienda para conjuntos de datos más grandes.\nAhora bien, doc2vec, como una extensión, permite al modelo “entender” frases, párrafos o documentos. Si leen el artículo sobre emergencias en Ecuador vienen varios artículos discutiendo las ventajas de uno sobre otro para determinados conjuntos de datos. Así que por facilidad, y porque además es solo el primer paso, se entrenará un modelo doc2vec. Para esto, utilizo los mismos parámetros del blog de bnosac.be.\n\nsip &lt;- data %&gt;% \n  select(FOLIO, DESCRIPCIONSOLICITUD) %&gt;% \n  rename(\n    doc_id = FOLIO,\n    text = DESCRIPCIONSOLICITUD)\n\nmodel &lt;- paragraph2vec(x=sip, type='PV-DBOW',\n                       dim = 150, iter = 10, min_count = 3, \n                       lr = 0.05, threads = 2)\n\nY ya, con eso se genera el modelo. Sencillo, ¿no? Ahora, aún no descubro por qué, pero el modelo tiene menos renglones que los datos. Y justo por esta razón, mi idea original de utilizar un clasificador automático se fue al traste, pero no importa. Porque aún se puede hacer algo interesante con chainy.\n\n\n\nShiny es un entorno de trabajo basado en web para visualizaciones interactivas. En otras palabras, es una herramienta para que otras personas puedan interactuar con los análisis, gráficas, tablas y demás cosas que hagamos en R y Python. Y esto nos permite, entre muchas cosas, que las personas que no necesitan saber de datos puedan interactuar y ver lo que nosotras consideramos importante.\nAntes de entrar de lleno a chainy es necesario entender que se puede hacer todo lo que ya sabemos hacer en R habitualmente. Con la diferencia de que hay que adaptarlo para que sea interactivo, es decir, que otra persona pueda ajustar cualquier valor, variable o parámetro sin necesidad de tocar el código. Por eso, uno de los posibles usos para el modelo que doc2vec que se entrenó antes, es encontrar documentos que tengan similitud con nuevas palabras. Como pueden ver en el siguiente ejemplo:\n\nsimilar &lt;- predict(model, \n                   newdata = c(\"agua\"), \n                   type = 'nearest', which = 'word2doc', top_n = 5)\nsimilar\n\n[[1]]\n  term1         term2 similarity rank\n1  agua 0424000219620  0.6598905    1\n2  agua 0429000043820  0.6564962    2\n3  agua 0424000219720  0.6475419    3\n4  agua -Construcción  0.6281804    4\n5  agua       Espejos  0.6231290    5\n\n\nY no es perfecto, pero sí nos muestra solicitudes que contengan la palabra, o palabras, que estemos buscando.\n\ndata %&gt;% \n  filter(FOLIO==\"0424000219720\") %&gt;% \n  select(DESCRIPCIONSOLICITUD)\n\n# A tibble: 1 × 1\n  DESCRIPCIONSOLICITUD                                                          \n  &lt;chr&gt;                                                                         \n1 \"¿Cuántas pipas tiene la Alcaldía para reparto de agua?\\n¿De dónde se surten?…\n\n\nShiny necesita dos secciones para funcionar: la UI (User Interface o interfaz de usuario) que es lo que la persona va a ver: una gráfica, una tabla, un botón, sombra aquí, sombra allá, etc. Y el Server que es donde van las funciones o la “lógica” de lo que queremos que haga nuestra aplicación de chainy.\n\nui &lt;- fluidPage(\n  titlePanel(\"Buscador de SIP por palabra\"),\n  sidebarLayout(\n    sidebarPanel(\n      textInput(\"newdata\", \"Escribe una palabra:\", value = \"\"),\n      numericInput(\"top_n\", \"Máximo de solicitudes similares:\", value = 5, min = 1),\n      actionButton(\"submit\", \"Puchale aquí\")\n    ),\n    mainPanel(\n      tableOutput(\"similar_docs\")\n    )\n  )\n)\n\nEn este código podemos observar lo siguiente:\n\nLa funcion fluidpage() sin la cual nada funciona, es como en ggplot.\n\ntitlePanel, que nos permite poner un título al chainy.\nsidebarLayout que va a configurar lo que aparece a un ladito, en este caso, los parámetros que puede cambiar la persona\n\ntextInput (la palabra)\nnumericInput (el máximo de solicitudes que puede aparecer, como vimos en el ejemplo aparecen otros términos que no son el folio y así no nos sirve)\nactionButton (el botón que va a activar nuestra app)\n\nmainPanel en donde se va a mostrar lo que queremos, en este caso la tabla con las solicitudes.\n\n\nEn general, esta parte me parece que es autoexplicativa y tiene lógica sobre lo que queremos que la persona vea. Además, los nombres en inglés ‘newdata’, ‘top_n’ y ‘submit’ están relacionados con la parte del server porque de nada sirve que lo que se ve este muy bonito si no hace lo que queremos.\n\nserver &lt;- function(input, output) {\n  \n  observeEvent(input$submit, {\n    req(input$newdata)\n    \n    similar &lt;- predict(model, \n                       newdata = input$newdata, \n                       type = \"nearest\", \n                       which = \"word2doc\", \n                       top_n = input$top_n)\n    \n    similar &lt;- similar[[1]]  #como es una lista, solo queremos el contenido\n    \n    similar_folio &lt;- data %&gt;%\n      filter(FOLIO %in% similar$term2) %&gt;%\n      select(FOLIO, DESCRIPCIONSOLICITUD)\n    \n    output$similar_docs &lt;- renderTable({\n      similar_folio\n    })\n  })\n}\n\nEn este caso, todo funciona como cuando se define una función. Ya sé que yo no soy muy fan de las funciones porque #Tidyverse, pero la idea es que todo vaya dentro de las llaves { } paso a pasito. En este caso, todo empieza cuando la persona presiona el botón.\n\nserver &lt;- function(input, output) {\n  \n  observeEvent(input$submit, {\n    req(input$newdata)\n    \n    similar &lt;- predict(model, \n                       newdata = input$newdata, \n                       type = \"nearest\", \n                       which = \"word2doc\", \n                       top_n = input$top_n)\n    \n    similar &lt;- similar[[1]]  #como es una lista, solo queremos el contenido\n    \n    similar_folio &lt;- data %&gt;%\n      filter(FOLIO %in% similar$term2) %&gt;%\n      select(FOLIO, DESCRIPCIONSOLICITUD, FECHASOLICITUD)\n    \n    output$similar_docs &lt;- renderTable({\n      similar_folio\n    })\n  })\n}\n\nY por último podemos ver que de verdad nuestra app funcione. Pero antes, un disclaimer: esta shiny app es muuuuy sencilla, en este caso solo admite buscar una palabra y no hay mucho de interesante. Hay muchos ejemplos en internet, especialmente en la galería de shiny y no quise hacer un refrito de lo mismo. Por eso preferí frustrarme un rato con doc2vec.\n\n\n\n\nshinyApp(ui = ui, server = server)\n\nShiny applications not supported in static R Markdown documents\n\n\nEntonces, para finalizar esta entrada, un shiny app necesita 3 elementos (que no son flores, azúcar y muchos colores):\n\nUna UI\nUn server (o lógica, o lo que queramos mostrar)\nLa función shinyApp(ui = ui, server = server)\n\nPor último, dado que esto es un markdown (o un documento plano) no hay chance de que se vea la app de chainy. Entonces, trate de montarla en shinyapps.io Y es más difícil de lo que imagine. Así que, algunas consideraciones: el csv final (solo con folio, descripción y fecha) pesa 122 mb, así que lo convertí en un dataframe de R (rds) y pesa 22 mb. El modelo fue ajustado, porque como estaba originalmente era casi de 500 mb. Así que en la app final tiene 50 dimensiones y fue entrenado en 6 “hilos” en paralelo. Para revisar la app puchale aquí.\nComo siempre, mis DM están abiertos en @dhumbertojs y espero que pronto pueda poner comentarios en el blog. Si tienen alguna recomendación o sugerencia, siempre es bienvenida."
  },
  {
    "objectID": "posts/shiny/index.html#datos",
    "href": "posts/shiny/index.html#datos",
    "title": "Mini intro a Chainy (Shiny)",
    "section": "",
    "text": "Cuando buscas y descargas los “datos abiertos” de la Plataforma Nacional de Transparencia (PNT), te devuelve un archivo de tipo zip en tu correo. Desde que empiezas la búsqueda hasta recibir el correo pasan entre 15 y 20 minutos.\nPara conservar los datos de la manera en que se cargaron a la PNT, voy a reutilizar los csv de este proyecto pero que estoy haciendo en python. Posteriormente, voy a unir todos los archivos en una sola base de datos para utilizar tidyverse para limpiar los datos.\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(purrr)\nlibrary(readr)\n\nWarning: package 'readr' was built under R version 4.3.3\n\nlibrary(shiny)\n\nWarning: package 'shiny' was built under R version 4.3.3\n\nlibrary(udpipe)\n\nWarning: package 'udpipe' was built under R version 4.3.3\n\nlibrary(stringr)\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\nlibrary(doc2vec)\n\nWarning: package 'doc2vec' was built under R version 4.3.3\n\nlibrary(word2vec)\n\nWarning: package 'word2vec' was built under R version 4.3.3\n\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\n\nComo siempre, a mí me gusta ‘llamar’ las librerías con las que voy a trabajar en el primer código. Luego ‘leo’ todos los csv. En esta ocasión utilicé el paquete reader en lugar de la función base de R read.csv porque me salían mensajes de error por el encoding.\n\ndirectory &lt;- \"C:/Users/dhumb/Documents/projects/sip-alcaldias-nlp/data/SIP\"  \nfiles &lt;- list.files(directory)\n\ndata &lt;- map(files,\n            ~ read_csv(paste(directory, .x, sep = \"/\"), \n                       locale = locale(encoding = \"latin1\"),\n                       show_col_types = FALSE) %&gt;% \n                         as_tibble() %&gt;% \n                         mutate_all(as.character)) %&gt;% \n  bind_rows() \n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\nsummary(data)\n\n    FOLIO           FECHASOLICITUD     DEPENDENCIA          ESTATUS         \n Length:212235      Length:212235      Length:212235      Length:212235     \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n MEDIOENTRADA       TIPOSOLICITUD      DESCRIPCIONSOLICITUD  OTROSDATOS       \n Length:212235      Length:212235      Length:212235        Length:212235     \n Class :character   Class :character   Class :character     Class :character  \n Mode  :character   Mode  :character   Mode  :character     Mode  :character  \n ARCHIVOADJUNTOSOLICITUD MEDIOENTREGA       FECHALIMITE       \n Length:212235           Length:212235      Length:212235     \n Class :character        Class :character   Class :character  \n Mode  :character        Mode  :character   Mode  :character  \n  RESPUESTA         TEXTORESPUESTA     FECHARESPUESTA     FECHASOLICITUDTERMINO\n Length:212235      Length:212235      Length:212235      Length:212235        \n Class :character   Class :character   Class :character   Class :character     \n Mode  :character   Mode  :character   Mode  :character   Mode  :character     \n     PAIS              ESTADO           MUNICIPIO         CODIGOPOSTAL      \n Length:212235      Length:212235      Length:212235      Length:212235     \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n    SECTOR            PRORROGA          PREVENCION        DISPONIBILIDAD    \n Length:212235      Length:212235      Length:212235      Length:212235     \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n TIPODERECHOARCOP      QUEJA          \n Length:212235      Length:212235     \n Class :character   Class :character  \n Mode  :character   Mode  :character  \n\n\nPosteriormente, hice una breve limpieza de datos. Había hecho una para reemplazar nombres de alcaldías, pero coinciden con aquellas solicitudes sobre datos personales.\n\ndata &lt;- data %&gt;% \n  filter(TIPOSOLICITUD == 'Información pública') %&gt;% #Porque solo nos interesan las SIP, y habia 16 de datos personales\n  mutate(\n    FECHASOLICITUD = dmy(FECHASOLICITUD),\n    FECHALIMITE = dmy(FECHALIMITE),\n    FECHARESPUESTA = dmy(FECHARESPUESTA),\n    FECHASOLICITUDTERMINO = dmy(FECHASOLICITUDTERMINO),\n    DEPENDENCIA = str_remove_all(DEPENDENCIA, \"Alcaldía\"),\n    DEPENDENCIA = str_trim(DEPENDENCIA, 'both'),\n    FOLIO = str_remove_all(FOLIO, \"[:punct:]\"),\n    FOLIO = str_remove_all(FOLIO, \"=\")\n  )\n\nsummary(data)\n\n    FOLIO           FECHASOLICITUD       DEPENDENCIA          ESTATUS         \n Length:208436      Min.   :2019-02-22   Length:208436      Length:208436     \n Class :character   1st Qu.:2020-03-08   Class :character   Class :character  \n Mode  :character   Median :2021-12-10   Mode  :character   Mode  :character  \n                    Mean   :2021-09-26                                        \n                    3rd Qu.:2023-03-08                                        \n                    Max.   :2024-02-25                                        \n                                                                              \n MEDIOENTRADA       TIPOSOLICITUD      DESCRIPCIONSOLICITUD  OTROSDATOS       \n Length:208436      Length:208436      Length:208436        Length:208436     \n Class :character   Class :character   Class :character     Class :character  \n Mode  :character   Mode  :character   Mode  :character     Mode  :character  \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n ARCHIVOADJUNTOSOLICITUD MEDIOENTREGA        FECHALIMITE        \n Length:208436           Length:208436      Min.   :2019-03-08  \n Class :character        Class :character   1st Qu.:2020-04-20  \n Mode  :character        Mode  :character   Median :2022-01-13  \n                                            Mean   :2021-11-11  \n                                            3rd Qu.:2023-03-24  \n                                            Max.   :2024-03-15  \n                                            NA's   :380         \n  RESPUESTA         TEXTORESPUESTA     FECHARESPUESTA      \n Length:208436      Length:208436      Min.   :2019-02-26  \n Class :character   Class :character   1st Qu.:2020-04-20  \n Mode  :character   Mode  :character   Median :2021-12-16  \n                                       Mean   :2021-10-30  \n                                       3rd Qu.:2023-03-10  \n                                       Max.   :2024-02-25  \n                                       NA's   :1747        \n FECHASOLICITUDTERMINO     PAIS              ESTADO           MUNICIPIO        \n Min.   :2019-02-26    Length:208436      Length:208436      Length:208436     \n 1st Qu.:2020-04-20    Class :character   Class :character   Class :character  \n Median :2021-12-16    Mode  :character   Mode  :character   Mode  :character  \n Mean   :2021-10-29                                                            \n 3rd Qu.:2023-03-09                                                            \n Max.   :2024-02-25                                                            \n NA's   :2291                                                                  \n CODIGOPOSTAL          SECTOR            PRORROGA          PREVENCION       \n Length:208436      Length:208436      Length:208436      Length:208436     \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n DISPONIBILIDAD     TIPODERECHOARCOP      QUEJA          \n Length:208436      Length:208436      Length:208436     \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n                                                         \n\n\nComo pueden observar, hay un total de 208,436 solicitudes para el periodo 2019-2024 en las 16 alcaldías de la CDMX. Luego, doc2vec tiene la restricción de que los textos no deben superar las mil palabras. Por eso cree la variable y aplique un filtro. Para terminar trabajando con 206,566 solicitudes.\n\ndata &lt;- data %&gt;% \n  mutate(\n    txt_clean_word2vec(DESCRIPCIONSOLICITUD),\n    nword = txt_count_words(DESCRIPCIONSOLICITUD)\n  ) %&gt;% \n  filter(nword &gt; 0 & nword &lt;= 1000)\nsummary(data)\n\n    FOLIO           FECHASOLICITUD       DEPENDENCIA          ESTATUS         \n Length:206566      Min.   :2019-02-22   Length:206566      Length:206566     \n Class :character   1st Qu.:2020-03-08   Class :character   Class :character  \n Mode  :character   Median :2021-12-01   Mode  :character   Mode  :character  \n                    Mean   :2021-09-26                                        \n                    3rd Qu.:2023-03-10                                        \n                    Max.   :2024-02-25                                        \n                                                                              \n MEDIOENTRADA       TIPOSOLICITUD      DESCRIPCIONSOLICITUD  OTROSDATOS       \n Length:206566      Length:206566      Length:206566        Length:206566     \n Class :character   Class :character   Class :character     Class :character  \n Mode  :character   Mode  :character   Mode  :character     Mode  :character  \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n ARCHIVOADJUNTOSOLICITUD MEDIOENTREGA        FECHALIMITE        \n Length:206566           Length:206566      Min.   :2019-03-08  \n Class :character        Class :character   1st Qu.:2020-04-20  \n Mode  :character        Mode  :character   Median :2021-12-29  \n                                            Mean   :2021-11-11  \n                                            3rd Qu.:2023-03-29  \n                                            Max.   :2024-03-15  \n                                            NA's   :380         \n  RESPUESTA         TEXTORESPUESTA     FECHARESPUESTA      \n Length:206566      Length:206566      Min.   :2019-02-26  \n Class :character   Class :character   1st Qu.:2020-04-20  \n Mode  :character   Mode  :character   Median :2021-12-16  \n                                       Mean   :2021-10-30  \n                                       3rd Qu.:2023-03-15  \n                                       Max.   :2024-02-25  \n                                       NA's   :1747        \n FECHASOLICITUDTERMINO     PAIS              ESTADO           MUNICIPIO        \n Min.   :2019-02-26    Length:206566      Length:206566      Length:206566     \n 1st Qu.:2020-04-20    Class :character   Class :character   Class :character  \n Median :2021-12-14    Mode  :character   Mode  :character   Mode  :character  \n Mean   :2021-10-28                                                            \n 3rd Qu.:2023-03-14                                                            \n Max.   :2024-02-25                                                            \n NA's   :2291                                                                  \n CODIGOPOSTAL          SECTOR            PRORROGA          PREVENCION       \n Length:206566      Length:206566      Length:206566      Length:206566     \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n DISPONIBILIDAD     TIPODERECHOARCOP      QUEJA          \n Length:206566      Length:206566      Length:206566     \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n                                                         \n txt_clean_word2vec(DESCRIPCIONSOLICITUD)     nword        \n Length:206566                            Min.   :   1.00  \n Class :character                         1st Qu.:  29.00  \n Mode  :character                         Median :  55.00  \n                                          Mean   :  90.47  \n                                          3rd Qu.: 109.00  \n                                          Max.   :1000.00"
  },
  {
    "objectID": "posts/shiny/index.html#word2vec",
    "href": "posts/shiny/index.html#word2vec",
    "title": "Mini intro a Chainy (Shiny)",
    "section": "",
    "text": "Y ahora es momento de utilizar doc2vec. Para entenderlo, es necesario explicar que este es una extensión de la arquitectura de machine learning word2vec. Esta detecta el contexto de las palabras de acuerdo a sus palabras vecinas. Hay dos modelos: Continous Bag of Words (CBOW) que predice la palabra objetivo de acuerdo con las palabras de alrededor, y se recomienda para datos pequeños. Y el otro, Continous Skip-Gram Model que funciona al revés: a partir de una palabra objetivo, predice las palabras de contexto. Este se recomienda para conjuntos de datos más grandes.\nAhora bien, doc2vec, como una extensión, permite al modelo “entender” frases, párrafos o documentos. Si leen el artículo sobre emergencias en Ecuador vienen varios artículos discutiendo las ventajas de uno sobre otro para determinados conjuntos de datos. Así que por facilidad, y porque además es solo el primer paso, se entrenará un modelo doc2vec. Para esto, utilizo los mismos parámetros del blog de bnosac.be.\n\nsip &lt;- data %&gt;% \n  select(FOLIO, DESCRIPCIONSOLICITUD) %&gt;% \n  rename(\n    doc_id = FOLIO,\n    text = DESCRIPCIONSOLICITUD)\n\nmodel &lt;- paragraph2vec(x=sip, type='PV-DBOW',\n                       dim = 150, iter = 10, min_count = 3, \n                       lr = 0.05, threads = 2)\n\nY ya, con eso se genera el modelo. Sencillo, ¿no? Ahora, aún no descubro por qué, pero el modelo tiene menos renglones que los datos. Y justo por esta razón, mi idea original de utilizar un clasificador automático se fue al traste, pero no importa. Porque aún se puede hacer algo interesante con chainy."
  },
  {
    "objectID": "posts/shiny/index.html#shiny",
    "href": "posts/shiny/index.html#shiny",
    "title": "Mini intro a Chainy (Shiny)",
    "section": "",
    "text": "Shiny es un entorno de trabajo basado en web para visualizaciones interactivas. En otras palabras, es una herramienta para que otras personas puedan interactuar con los análisis, gráficas, tablas y demás cosas que hagamos en R y Python. Y esto nos permite, entre muchas cosas, que las personas que no necesitan saber de datos puedan interactuar y ver lo que nosotras consideramos importante.\nAntes de entrar de lleno a chainy es necesario entender que se puede hacer todo lo que ya sabemos hacer en R habitualmente. Con la diferencia de que hay que adaptarlo para que sea interactivo, es decir, que otra persona pueda ajustar cualquier valor, variable o parámetro sin necesidad de tocar el código. Por eso, uno de los posibles usos para el modelo que doc2vec que se entrenó antes, es encontrar documentos que tengan similitud con nuevas palabras. Como pueden ver en el siguiente ejemplo:\n\nsimilar &lt;- predict(model, \n                   newdata = c(\"agua\"), \n                   type = 'nearest', which = 'word2doc', top_n = 5)\nsimilar\n\n[[1]]\n  term1         term2 similarity rank\n1  agua 0424000219620  0.6598905    1\n2  agua 0429000043820  0.6564962    2\n3  agua 0424000219720  0.6475419    3\n4  agua -Construcción  0.6281804    4\n5  agua       Espejos  0.6231290    5\n\n\nY no es perfecto, pero sí nos muestra solicitudes que contengan la palabra, o palabras, que estemos buscando.\n\ndata %&gt;% \n  filter(FOLIO==\"0424000219720\") %&gt;% \n  select(DESCRIPCIONSOLICITUD)\n\n# A tibble: 1 × 1\n  DESCRIPCIONSOLICITUD                                                          \n  &lt;chr&gt;                                                                         \n1 \"¿Cuántas pipas tiene la Alcaldía para reparto de agua?\\n¿De dónde se surten?…\n\n\nShiny necesita dos secciones para funcionar: la UI (User Interface o interfaz de usuario) que es lo que la persona va a ver: una gráfica, una tabla, un botón, sombra aquí, sombra allá, etc. Y el Server que es donde van las funciones o la “lógica” de lo que queremos que haga nuestra aplicación de chainy.\n\nui &lt;- fluidPage(\n  titlePanel(\"Buscador de SIP por palabra\"),\n  sidebarLayout(\n    sidebarPanel(\n      textInput(\"newdata\", \"Escribe una palabra:\", value = \"\"),\n      numericInput(\"top_n\", \"Máximo de solicitudes similares:\", value = 5, min = 1),\n      actionButton(\"submit\", \"Puchale aquí\")\n    ),\n    mainPanel(\n      tableOutput(\"similar_docs\")\n    )\n  )\n)\n\nEn este código podemos observar lo siguiente:\n\nLa funcion fluidpage() sin la cual nada funciona, es como en ggplot.\n\ntitlePanel, que nos permite poner un título al chainy.\nsidebarLayout que va a configurar lo que aparece a un ladito, en este caso, los parámetros que puede cambiar la persona\n\ntextInput (la palabra)\nnumericInput (el máximo de solicitudes que puede aparecer, como vimos en el ejemplo aparecen otros términos que no son el folio y así no nos sirve)\nactionButton (el botón que va a activar nuestra app)\n\nmainPanel en donde se va a mostrar lo que queremos, en este caso la tabla con las solicitudes.\n\n\nEn general, esta parte me parece que es autoexplicativa y tiene lógica sobre lo que queremos que la persona vea. Además, los nombres en inglés ‘newdata’, ‘top_n’ y ‘submit’ están relacionados con la parte del server porque de nada sirve que lo que se ve este muy bonito si no hace lo que queremos.\n\nserver &lt;- function(input, output) {\n  \n  observeEvent(input$submit, {\n    req(input$newdata)\n    \n    similar &lt;- predict(model, \n                       newdata = input$newdata, \n                       type = \"nearest\", \n                       which = \"word2doc\", \n                       top_n = input$top_n)\n    \n    similar &lt;- similar[[1]]  #como es una lista, solo queremos el contenido\n    \n    similar_folio &lt;- data %&gt;%\n      filter(FOLIO %in% similar$term2) %&gt;%\n      select(FOLIO, DESCRIPCIONSOLICITUD)\n    \n    output$similar_docs &lt;- renderTable({\n      similar_folio\n    })\n  })\n}\n\nEn este caso, todo funciona como cuando se define una función. Ya sé que yo no soy muy fan de las funciones porque #Tidyverse, pero la idea es que todo vaya dentro de las llaves { } paso a pasito. En este caso, todo empieza cuando la persona presiona el botón.\n\nserver &lt;- function(input, output) {\n  \n  observeEvent(input$submit, {\n    req(input$newdata)\n    \n    similar &lt;- predict(model, \n                       newdata = input$newdata, \n                       type = \"nearest\", \n                       which = \"word2doc\", \n                       top_n = input$top_n)\n    \n    similar &lt;- similar[[1]]  #como es una lista, solo queremos el contenido\n    \n    similar_folio &lt;- data %&gt;%\n      filter(FOLIO %in% similar$term2) %&gt;%\n      select(FOLIO, DESCRIPCIONSOLICITUD, FECHASOLICITUD)\n    \n    output$similar_docs &lt;- renderTable({\n      similar_folio\n    })\n  })\n}\n\nY por último podemos ver que de verdad nuestra app funcione. Pero antes, un disclaimer: esta shiny app es muuuuy sencilla, en este caso solo admite buscar una palabra y no hay mucho de interesante. Hay muchos ejemplos en internet, especialmente en la galería de shiny y no quise hacer un refrito de lo mismo. Por eso preferí frustrarme un rato con doc2vec."
  },
  {
    "objectID": "posts/shiny/index.html#its-alive",
    "href": "posts/shiny/index.html#its-alive",
    "title": "Mini intro a Chainy (Shiny)",
    "section": "",
    "text": "shinyApp(ui = ui, server = server)\n\nShiny applications not supported in static R Markdown documents\n\n\nEntonces, para finalizar esta entrada, un shiny app necesita 3 elementos (que no son flores, azúcar y muchos colores):\n\nUna UI\nUn server (o lógica, o lo que queramos mostrar)\nLa función shinyApp(ui = ui, server = server)\n\nPor último, dado que esto es un markdown (o un documento plano) no hay chance de que se vea la app de chainy. Entonces, trate de montarla en shinyapps.io Y es más difícil de lo que imagine. Así que, algunas consideraciones: el csv final (solo con folio, descripción y fecha) pesa 122 mb, así que lo convertí en un dataframe de R (rds) y pesa 22 mb. El modelo fue ajustado, porque como estaba originalmente era casi de 500 mb. Así que en la app final tiene 50 dimensiones y fue entrenado en 6 “hilos” en paralelo. Para revisar la app puchale aquí.\nComo siempre, mis DM están abiertos en @dhumbertojs y espero que pronto pueda poner comentarios en el blog. Si tienen alguna recomendación o sugerencia, siempre es bienvenida."
  },
  {
    "objectID": "posts/linea-12/index.html",
    "href": "posts/linea-12/index.html",
    "title": "A un año de la Línea 12 con la API del INFO",
    "section": "",
    "text": "El 4 de julio de 2022 se presentó un informe de Solicitudes de Información Pública (SIP) sobre la Línea 12 del Metro en la Ciudad de México. En resumen, un tramo de la línea colapso por defectos en la construcción, las personas implicadas de su construcción están en puestos de gobierno y de toma de decisiones. Para sorpresa de nadie, los posibles implicados se están deslindando de responsabilidades y señalamientos.\nPero, el informe se realizó con base en las SIP del 3 de mayo del 2021 al 11 de mayo de 2022, es decir: sobre lo que preguntan las personas a las instituciones de la Ciudad de México. Para ver la presentación pueden ver el siguiente video y si quieren pueden leerlo aquí.\nY hasta ahí todo sin pena ni gloria: todo es trágico, la gente pide información y a se le deja esperando que alguien le responda. Clásico de una democracia, ¿verdad? Pues así era, hasta que “alguien” se enojó y regaño a dos comisionados del Instituto desde donde se realizó el informe. ¿Y la autonomía a’pá?\nSi no me creen, vean este video donde en el pleno los comisionados, cofcofmachitoscofcof, continúan con la línea establecida por el gobierno, ofrecen otros datos (sello de esta era política): mayor número de solicitudes (porque evidentemente más preguntas significa más transparencia), y que más del 95% han sido respondidas.\n¿Qué significa haber respondido una solicitud de transparencia? Más adelante hay un párrafo sobre algunos hallazgos sobre las respuestas de esta base de datos. Además, si conocen de transparencia saben que una posible respuesta es que esa institución no tiene esa información. En aproximadamente la mitad de los casos no sabemos qué respondió el sujeto obligado.\nEn fin, este no es un rant, este es un blog de datos y eso es lo que haremos. Dado que ya se publicaron las SIP que se utilizaron en el informe, vamos a replicar las gráficas y ver que otra cosa sale.\n\n\nEntonces, a mi me gusta llamar primero a las libraries que vamos a utilizar, luego los datos y empezar a explorar.\n\nlibrary(tm)\n\nLoading required package: NLP\n\nlibrary(httr)\n\n\nAttaching package: 'httr'\n\n\nThe following object is masked from 'package:NLP':\n\n    content\n\nlibrary(tidyr)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(plotly)\n\nLoading required package: ggplot2\n\n\n\nAttaching package: 'ggplot2'\n\n\nThe following object is masked from 'package:NLP':\n\n    annotate\n\n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:httr':\n\n    config\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\nlibrary(xtable)\nlibrary(ggplot2)\nlibrary(stringr)\nlibrary(syuzhet)\nlibrary(jsonlite)\nlibrary(tidytext)\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\n\nAhora, podemos hacer lo de siempre y descargar los datos, importarlos y limpiarlos. Pero, como el punto de todo esto es aprender a hacer cosas nuevas vamos a leer la API de los datos abiertos del INFO.\n\n\n\nAsí debe verse\n\n\nLe damos clic en explorar\n\n\n\nNueva pantalla…\n\n\nY en el botón verde que dice “API de datos” le damos clic y se verá de la siguiente manera:\n\n\n\nTa-dá!\n\n\nSeleccionamos lo que está subrayado (así como queda en el código de abajo) que es el enlace que necesitamos para “llamar” a los datos. Para revisar por qué hice esto pueden checar el trabajo de Alan Yeung\n\nurl &lt;- \"https://datosabiertos.infocdmx.org.mx/api/3/action/datastore_search?resource_id=07fff148-a1bf-4fb7-9ed0-ed66b6907890\"\nraw &lt;- GET(url)\nstatus_code(raw)\n\n[1] 200\n\n\nDebe salir 200 para saber que se logró llamar a la información, si sale otra cosa vean el blog ya mencionado. Ambas funciones, GET y status_code, son del paquete httr.\n\nobs &lt;- \"&limit=1807\"\nurl &lt;- paste0(url, obs)\nlista &lt;- fromJSON(url)\ndata &lt;- lista$result$records\n\nPor default la consulta tiene un límite de 100 observaciones, por eso a la url hay que agregarle el string &limit= donde el número es el total de observaciones que hay publicadas. Y del paquete jsonlite la función fromJSON nos permite obtener los datos (records). Y listo! Con estas instrucciones ya podemos utilizar todas los datasets que tiene publicados el INFO.\n\n\n\nYa teniendo los datos listos, podemos hacer análisis adicionales a lo que se presenta en el reporte (desde la página 17). Particularmente quiero explorar los textos y alguna cosa que se me vaya ocurriendo.\n\nnames(data)\n\n [1] \"_id\"                         \"folio\"                      \n [3] \"fecha_de_ingreso\"            \"descripcion_de_la_solicitud\"\n [5] \"estatus\"                     \"medio_entrada\"              \n [7] \"tipo_solicitud\"              \"fecha_limite_de_respuesta\"  \n [9] \"respuesta\"                   \"dependencia\"                \n[11] \"organo_de_gobierno\"         \n\n\ndata %&gt;%\n    count(dependencia, sort = T) %&gt;%\n    top_n(10) %&gt;%\n    xtable() %&gt;%\n    print(type = \"html\")\nSelecting by n\n\n\n\n\n\n\n\ndependencia\n\n\nn\n\n\n\n\n1\n\n\nSistema de Transporte Colectivo\n\n\n459\n\n\n\n\n2\n\n\nJefatura de Gobierno de la Ciudad de México\n\n\n398\n\n\n\n\n3\n\n\nSecretaría de Obras y Servicios\n\n\n196\n\n\n\n\n4\n\n\nSecretaría de Gestión Integral de Riesgos y Protección Civil\n\n\n142\n\n\n\n\n5\n\n\nFiscalía General de Justicia de la CDMX\n\n\n66\n\n\n\n\n6\n\n\nSecretaría de Movilidad\n\n\n62\n\n\n\n\n7\n\n\nSecretaría de la Contraloría General\n\n\n56\n\n\n\n\n8\n\n\nSecretaría de Gobierno\n\n\n49\n\n\n\n\n9\n\n\nSecretaría de Administración y Finanzas\n\n\n37\n\n\n\n\n10\n\n\nComisión Ejecutiva de Atención a Víctimas de la Ciudad de México\n\n\n35\n\n\n\ndata %&gt;%\n    count(organo_de_gobierno, sort = T) %&gt;%\n    xtable() %&gt;%\n    print(type = \"html\")\n\n\n\n\n\n\n\norgano_de_gobierno\n\n\nn\n\n\n\n\n1\n\n\nAdministración Pública Central\n\n\n998\n\n\n\n\n2\n\n\nOrganismos desconcentrados, descentralizados, paraestatales y auxiliares\n\n\n563\n\n\n\n\n3\n\n\nÓrganos Autónomos\n\n\n109\n\n\n\n\n4\n\n\nPoder Legislativo\n\n\n47\n\n\n\n\n5\n\n\nSindicatos\n\n\n41\n\n\n\n\n6\n\n\nAlcaldías\n\n\n36\n\n\n\n\n7\n\n\nPartidos Políticos\n\n\n6\n\n\n\n\n8\n\n\nPoder Judicial\n\n\n5\n\n\n\n\n9\n\n\nFideicomisos y fondos públicos\n\n\n2\n\n\n\nEs evidente, que el Sistema de Transporte Colectivo (metro) iba a ser el sujeto obligado con más solicitudes de información pública sobre el tema.\n\n# data %&gt;%\n#   count(respuesta)\n\nDe las 1,807 solicitudes, hay 281 grupos de respuestas, y si empezamos a revisar vemos que los grupos se pueden reducir… No estaba en el plan, pero estaría interesante para revisar. Dado que se ve gigantesco, chéquenlo con calma en su equipo. Pero, a bote pronto, hay 600 solicitudes sin respuesta (33%), 444 (25%) se contestaron vía infomex (descanse en paz) o por la Plataforma Nacional de Transparencia (pero no sabemos que se respondió); 188 (10%) dijeron que la solicitud le corresponde a otro ente OJO este es el texto directo sin adornos abogadiles (nada contra ustedes; sin embargo, nadie entiende como escriben). 79 (4%) fueron prevenidas (esto significa que a las personas servidoras públicas no les quedó clara la, o las, preguntas y le piden más información a la persona solicitante) y 51 (3%) se declararon incompetentes para responder y 26 (1%) se reservaron, esto significa que es información que poseen las instituciones y que por motivos de seguridad no puede ser entregada por un tiempo determinado.\nDespués de todo ese rollo, falta 26% de las solicitudes… que están en abogañol o que no se puede clasificar en un ratito. Si quieren ayuda envíenme un DM Las cifras las fui sacando de medio leer los resultados en una hoja de Excel :P\n\ndias &lt;- data %&gt;%\n    mutate(dia = date(fecha_de_ingreso)) %&gt;%\n    count(dia) %&gt;%\n    ggplot(aes(x = dia, y = n)) +\n    geom_line() +\n    labs(\n        x = \"\", y = \"\",\n        title = \"Solicitudes por día\"\n    ) +\n    theme_classic()\nggplotly(dias)\n\n\n\n\n\nEl pico de solicitudes está el 5 de junio de 2022. En blogs pasados, específicamente en el análisis de “Días sin ti” utilicé gráficas interactivas, donde podías hacer zoom y te daba información básica de la observación, aquí utilizo la misma técnica.\n\n\n\nAlgo que no va a ser muy riguroso es el análisis de texto, por qué? Porque las solicitudes de información se caracterizan por ser texto libre y contener, en algunos casos, datos personales. Si bien este dataset tiene testados los datos personales, estos son reemplazados por asteriscos. Aun así, espero encontrar algo interesante.\n\ntexto &lt;- data %&gt;%\n    select(descripcion_de_la_solicitud) %&gt;%\n    unnest_tokens(palabra, descripcion_de_la_solicitud) %&gt;%\n    mutate(palabra = str_replace_all(palabra, c(\"á\" = \"a\", \"é\" = \"e\", \"í\" = \"i\", \"ó\" = \"o\"))) %&gt;%\n    filter(!palabra %in% stopwords(\"es\")) %&gt;%\n    filter(!palabra %in% c(\"metro\", \"12\", \"sistema\", \"transporte\", \"colectivo\", \"ciudad\", \"mexico\", \"solicito\", \"3\", \"linea\", \"informacion\", \"cdmx\", \"2021\"))\n\nEsto ya se la saben, limpieza de textos para tener solo palabras. Ahora, mientras redactaba esto, salieron palabras comunes que son demasiado obvias: metro, 12, línea, sistema, transporte, colectivo, etc. Por eso las filtro antes\n\ntexto %&gt;%\n    count(palabra, sort = T) %&gt;%\n    top_n(20)\n\nSelecting by n\n\n\n         palabra    n\n1        empresa 1174\n2           mayo 1067\n3            dnv  886\n4  mantenimiento  759\n5          copia  717\n6        informe  652\n7          tramo  610\n8   construccion  598\n9          fecha  569\n10      dictamen  543\n11       colapso  539\n12     accidente  508\n13      gobierno  493\n14      contrato  451\n15   expedientes  448\n16          obra  444\n17      respecto  432\n18      ocurrido  431\n19    documentos  417\n20        trenes  415\n\n\nAhora, el análisis de sentimiento con Syuzhet, que es unir dos dataframes.\n\ntexto_nrc &lt;- get_nrc_sentiment(char_v = texto$palabra, language = \"spanish\")\ntexto_fin &lt;- bind_cols(texto, texto_nrc)\n\n\ntexto_fin %&gt;%\n    pivot_longer(\n        cols = 2:11\n    ) %&gt;%\n    group_by(name) %&gt;%\n    summarise(total = sum(value)) %&gt;%\n    ungroup() %&gt;%\n    mutate(name = reorder(name, total)) %&gt;%\n    ggplot(aes(x = name, y = total, fill = name)) +\n    geom_bar(stat = \"identity\") +\n    scale_fill_manual(\n        breaks = c(\"disgust\", \"surprise\", \"anger\", \"joy\", \"anticipation\", \"fear\", \"sadness\", \"trust\", \"positive\", \"negative\"),\n        values = c(\"#24D204\", \"#06CBBE\", \"#CB0606\", \"#FBFE00\", \"#FF9200\", \"#46BF5F\", \"#5479C3\", \"#01FF4C\", \"#FF00DC\", \"#000000\")\n    ) +\n    theme_classic() +\n    labs(\n        title = \"Análisis de sentimientos\",\n        subtitle = \"Syuzhet\",\n        x = \"\", y = \"\"\n    ) +\n    theme(legend.position = \"blank\")\n\n\n\n\n\n\n\n\nResalta que la mayoría de las palabras tienen un sentido negativo… Lo cual tiene cierta lógica, uno no pide información porque ande feliz. Por otro lado, también es sorprendente que no haya tantas palabras relacionadas con el enojo… Si quieren entender que está pasando detrás, vean la documentación de Syuzhet.\nSi a alguien se le ocurre algo más que se pueda hacer, hágamelo saber. Por ahora, creo que esto nos da en qué pensar. Si bien es limitado el número de variables en estas bases de datos, mientras más análisis se realicen con esta información se podrán aprovechar mejor. O bien, nos daremos cuenta de que información hace falta y se podría solicitar que se libere.\nMuchas gracias a Zule por su lectura y recomendaciones para que este texto sea más entendible."
  },
  {
    "objectID": "posts/linea-12/index.html#análisis",
    "href": "posts/linea-12/index.html#análisis",
    "title": "A un año de la Línea 12 con la API del INFO",
    "section": "",
    "text": "Entonces, a mi me gusta llamar primero a las libraries que vamos a utilizar, luego los datos y empezar a explorar.\n\nlibrary(tm)\n\nLoading required package: NLP\n\nlibrary(httr)\n\n\nAttaching package: 'httr'\n\n\nThe following object is masked from 'package:NLP':\n\n    content\n\nlibrary(tidyr)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(plotly)\n\nLoading required package: ggplot2\n\n\n\nAttaching package: 'ggplot2'\n\n\nThe following object is masked from 'package:NLP':\n\n    annotate\n\n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:httr':\n\n    config\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\nlibrary(xtable)\nlibrary(ggplot2)\nlibrary(stringr)\nlibrary(syuzhet)\nlibrary(jsonlite)\nlibrary(tidytext)\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\n\nAhora, podemos hacer lo de siempre y descargar los datos, importarlos y limpiarlos. Pero, como el punto de todo esto es aprender a hacer cosas nuevas vamos a leer la API de los datos abiertos del INFO.\n\n\n\nAsí debe verse\n\n\nLe damos clic en explorar\n\n\n\nNueva pantalla…\n\n\nY en el botón verde que dice “API de datos” le damos clic y se verá de la siguiente manera:\n\n\n\nTa-dá!\n\n\nSeleccionamos lo que está subrayado (así como queda en el código de abajo) que es el enlace que necesitamos para “llamar” a los datos. Para revisar por qué hice esto pueden checar el trabajo de Alan Yeung\n\nurl &lt;- \"https://datosabiertos.infocdmx.org.mx/api/3/action/datastore_search?resource_id=07fff148-a1bf-4fb7-9ed0-ed66b6907890\"\nraw &lt;- GET(url)\nstatus_code(raw)\n\n[1] 200\n\n\nDebe salir 200 para saber que se logró llamar a la información, si sale otra cosa vean el blog ya mencionado. Ambas funciones, GET y status_code, son del paquete httr.\n\nobs &lt;- \"&limit=1807\"\nurl &lt;- paste0(url, obs)\nlista &lt;- fromJSON(url)\ndata &lt;- lista$result$records\n\nPor default la consulta tiene un límite de 100 observaciones, por eso a la url hay que agregarle el string &limit= donde el número es el total de observaciones que hay publicadas. Y del paquete jsonlite la función fromJSON nos permite obtener los datos (records). Y listo! Con estas instrucciones ya podemos utilizar todas los datasets que tiene publicados el INFO."
  },
  {
    "objectID": "posts/linea-12/index.html#análisis-básico",
    "href": "posts/linea-12/index.html#análisis-básico",
    "title": "A un año de la Línea 12 con la API del INFO",
    "section": "",
    "text": "Ya teniendo los datos listos, podemos hacer análisis adicionales a lo que se presenta en el reporte (desde la página 17). Particularmente quiero explorar los textos y alguna cosa que se me vaya ocurriendo.\n\nnames(data)\n\n [1] \"_id\"                         \"folio\"                      \n [3] \"fecha_de_ingreso\"            \"descripcion_de_la_solicitud\"\n [5] \"estatus\"                     \"medio_entrada\"              \n [7] \"tipo_solicitud\"              \"fecha_limite_de_respuesta\"  \n [9] \"respuesta\"                   \"dependencia\"                \n[11] \"organo_de_gobierno\"         \n\n\ndata %&gt;%\n    count(dependencia, sort = T) %&gt;%\n    top_n(10) %&gt;%\n    xtable() %&gt;%\n    print(type = \"html\")\nSelecting by n\n\n\n\n\n\n\n\ndependencia\n\n\nn\n\n\n\n\n1\n\n\nSistema de Transporte Colectivo\n\n\n459\n\n\n\n\n2\n\n\nJefatura de Gobierno de la Ciudad de México\n\n\n398\n\n\n\n\n3\n\n\nSecretaría de Obras y Servicios\n\n\n196\n\n\n\n\n4\n\n\nSecretaría de Gestión Integral de Riesgos y Protección Civil\n\n\n142\n\n\n\n\n5\n\n\nFiscalía General de Justicia de la CDMX\n\n\n66\n\n\n\n\n6\n\n\nSecretaría de Movilidad\n\n\n62\n\n\n\n\n7\n\n\nSecretaría de la Contraloría General\n\n\n56\n\n\n\n\n8\n\n\nSecretaría de Gobierno\n\n\n49\n\n\n\n\n9\n\n\nSecretaría de Administración y Finanzas\n\n\n37\n\n\n\n\n10\n\n\nComisión Ejecutiva de Atención a Víctimas de la Ciudad de México\n\n\n35\n\n\n\ndata %&gt;%\n    count(organo_de_gobierno, sort = T) %&gt;%\n    xtable() %&gt;%\n    print(type = \"html\")\n\n\n\n\n\n\n\norgano_de_gobierno\n\n\nn\n\n\n\n\n1\n\n\nAdministración Pública Central\n\n\n998\n\n\n\n\n2\n\n\nOrganismos desconcentrados, descentralizados, paraestatales y auxiliares\n\n\n563\n\n\n\n\n3\n\n\nÓrganos Autónomos\n\n\n109\n\n\n\n\n4\n\n\nPoder Legislativo\n\n\n47\n\n\n\n\n5\n\n\nSindicatos\n\n\n41\n\n\n\n\n6\n\n\nAlcaldías\n\n\n36\n\n\n\n\n7\n\n\nPartidos Políticos\n\n\n6\n\n\n\n\n8\n\n\nPoder Judicial\n\n\n5\n\n\n\n\n9\n\n\nFideicomisos y fondos públicos\n\n\n2\n\n\n\nEs evidente, que el Sistema de Transporte Colectivo (metro) iba a ser el sujeto obligado con más solicitudes de información pública sobre el tema.\n\n# data %&gt;%\n#   count(respuesta)\n\nDe las 1,807 solicitudes, hay 281 grupos de respuestas, y si empezamos a revisar vemos que los grupos se pueden reducir… No estaba en el plan, pero estaría interesante para revisar. Dado que se ve gigantesco, chéquenlo con calma en su equipo. Pero, a bote pronto, hay 600 solicitudes sin respuesta (33%), 444 (25%) se contestaron vía infomex (descanse en paz) o por la Plataforma Nacional de Transparencia (pero no sabemos que se respondió); 188 (10%) dijeron que la solicitud le corresponde a otro ente OJO este es el texto directo sin adornos abogadiles (nada contra ustedes; sin embargo, nadie entiende como escriben). 79 (4%) fueron prevenidas (esto significa que a las personas servidoras públicas no les quedó clara la, o las, preguntas y le piden más información a la persona solicitante) y 51 (3%) se declararon incompetentes para responder y 26 (1%) se reservaron, esto significa que es información que poseen las instituciones y que por motivos de seguridad no puede ser entregada por un tiempo determinado.\nDespués de todo ese rollo, falta 26% de las solicitudes… que están en abogañol o que no se puede clasificar en un ratito. Si quieren ayuda envíenme un DM Las cifras las fui sacando de medio leer los resultados en una hoja de Excel :P\n\ndias &lt;- data %&gt;%\n    mutate(dia = date(fecha_de_ingreso)) %&gt;%\n    count(dia) %&gt;%\n    ggplot(aes(x = dia, y = n)) +\n    geom_line() +\n    labs(\n        x = \"\", y = \"\",\n        title = \"Solicitudes por día\"\n    ) +\n    theme_classic()\nggplotly(dias)\n\n\n\n\n\nEl pico de solicitudes está el 5 de junio de 2022. En blogs pasados, específicamente en el análisis de “Días sin ti” utilicé gráficas interactivas, donde podías hacer zoom y te daba información básica de la observación, aquí utilizo la misma técnica."
  },
  {
    "objectID": "posts/linea-12/index.html#análisis-de-texto",
    "href": "posts/linea-12/index.html#análisis-de-texto",
    "title": "A un año de la Línea 12 con la API del INFO",
    "section": "",
    "text": "Algo que no va a ser muy riguroso es el análisis de texto, por qué? Porque las solicitudes de información se caracterizan por ser texto libre y contener, en algunos casos, datos personales. Si bien este dataset tiene testados los datos personales, estos son reemplazados por asteriscos. Aun así, espero encontrar algo interesante.\n\ntexto &lt;- data %&gt;%\n    select(descripcion_de_la_solicitud) %&gt;%\n    unnest_tokens(palabra, descripcion_de_la_solicitud) %&gt;%\n    mutate(palabra = str_replace_all(palabra, c(\"á\" = \"a\", \"é\" = \"e\", \"í\" = \"i\", \"ó\" = \"o\"))) %&gt;%\n    filter(!palabra %in% stopwords(\"es\")) %&gt;%\n    filter(!palabra %in% c(\"metro\", \"12\", \"sistema\", \"transporte\", \"colectivo\", \"ciudad\", \"mexico\", \"solicito\", \"3\", \"linea\", \"informacion\", \"cdmx\", \"2021\"))\n\nEsto ya se la saben, limpieza de textos para tener solo palabras. Ahora, mientras redactaba esto, salieron palabras comunes que son demasiado obvias: metro, 12, línea, sistema, transporte, colectivo, etc. Por eso las filtro antes\n\ntexto %&gt;%\n    count(palabra, sort = T) %&gt;%\n    top_n(20)\n\nSelecting by n\n\n\n         palabra    n\n1        empresa 1174\n2           mayo 1067\n3            dnv  886\n4  mantenimiento  759\n5          copia  717\n6        informe  652\n7          tramo  610\n8   construccion  598\n9          fecha  569\n10      dictamen  543\n11       colapso  539\n12     accidente  508\n13      gobierno  493\n14      contrato  451\n15   expedientes  448\n16          obra  444\n17      respecto  432\n18      ocurrido  431\n19    documentos  417\n20        trenes  415\n\n\nAhora, el análisis de sentimiento con Syuzhet, que es unir dos dataframes.\n\ntexto_nrc &lt;- get_nrc_sentiment(char_v = texto$palabra, language = \"spanish\")\ntexto_fin &lt;- bind_cols(texto, texto_nrc)\n\n\ntexto_fin %&gt;%\n    pivot_longer(\n        cols = 2:11\n    ) %&gt;%\n    group_by(name) %&gt;%\n    summarise(total = sum(value)) %&gt;%\n    ungroup() %&gt;%\n    mutate(name = reorder(name, total)) %&gt;%\n    ggplot(aes(x = name, y = total, fill = name)) +\n    geom_bar(stat = \"identity\") +\n    scale_fill_manual(\n        breaks = c(\"disgust\", \"surprise\", \"anger\", \"joy\", \"anticipation\", \"fear\", \"sadness\", \"trust\", \"positive\", \"negative\"),\n        values = c(\"#24D204\", \"#06CBBE\", \"#CB0606\", \"#FBFE00\", \"#FF9200\", \"#46BF5F\", \"#5479C3\", \"#01FF4C\", \"#FF00DC\", \"#000000\")\n    ) +\n    theme_classic() +\n    labs(\n        title = \"Análisis de sentimientos\",\n        subtitle = \"Syuzhet\",\n        x = \"\", y = \"\"\n    ) +\n    theme(legend.position = \"blank\")\n\n\n\n\n\n\n\n\nResalta que la mayoría de las palabras tienen un sentido negativo… Lo cual tiene cierta lógica, uno no pide información porque ande feliz. Por otro lado, también es sorprendente que no haya tantas palabras relacionadas con el enojo… Si quieren entender que está pasando detrás, vean la documentación de Syuzhet.\nSi a alguien se le ocurre algo más que se pueda hacer, hágamelo saber. Por ahora, creo que esto nos da en qué pensar. Si bien es limitado el número de variables en estas bases de datos, mientras más análisis se realicen con esta información se podrán aprovechar mejor. O bien, nos daremos cuenta de que información hace falta y se podría solicitar que se libere.\nMuchas gracias a Zule por su lectura y recomendaciones para que este texto sea más entendible."
  },
  {
    "objectID": "posts/ile-en-cdmx/index.html",
    "href": "posts/ile-en-cdmx/index.html",
    "title": "Interrupción Legal del Embarazo en la Ciudad de México",
    "section": "",
    "text": "Este post es una actualización y revisión de un post de la primera iteración de este blog."
  },
  {
    "objectID": "posts/ile-en-cdmx/index.html#datos-sobre-ile-en-la-ciudad-de-méxico",
    "href": "posts/ile-en-cdmx/index.html#datos-sobre-ile-en-la-ciudad-de-méxico",
    "title": "Interrupción Legal del Embarazo en la Ciudad de México",
    "section": "Datos sobre ILE en la Ciudad de México",
    "text": "Datos sobre ILE en la Ciudad de México\nEl 24 de abril, es decir, el viernes de la semana pasada, en la Ciudad de México se cumplieron 13 años de la despenalización de la Interrupción Legal del Embarazo. Adicionalmente, desde el año pasado la ADIP ha abierto los datos respecto a las interrupciones en la Ciudad de México en clínicas y hospitales de la Secretaría de la Salud de la Ciudad de México.\nPor eso, vamos a revisar la base de datos actualizada disponible en el sitio de la ADIP. Para hacer esto, vamos a combinar los datos que están segmentados por periodos: - 2016 a 2018 - 2019 a 2021 - 1er semestre 2022\nPor razones de facilidad y replicabilidad, descargué los datos y los subí a una carpeta de google drive\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\norigen_16 &lt;- \"https://docs.google.com/spreadsheets/d/e/2PACX-1vQ_HoUvYXipMvAB0DkLcMbTNWWVYx-9k4CQomTXmT04yVOrqunILg5CnEWDVRaDniJavSalb0bwOX4e/pub?output=csv\"\n\nd16 &lt;- read.csv(origen_16, stringsAsFactors = F, fileEncoding = \"UTF-8\") %&gt;%\n    mutate_all(as.character)\n\norigen_19 &lt;- \"https://docs.google.com/spreadsheets/d/e/2PACX-1vTKDzF5efQP58F0JhV6iaQavOTIEc4yRJcPIrr3Hj_fOdlPj34bBVWEkHhjEbi0dN7QU0VxbOabrjOE/pub?output=csv\"\n\nd19 &lt;- read.csv(origen_19, stringsAsFactors = F, fileEncoding = \"UTF-8\") %&gt;%\n    mutate_all(as.character)\n\norigen_22 &lt;- \"https://docs.google.com/spreadsheets/d/e/2PACX-1vSioEYHSp8R0bXmDA8N3KTRcFCjwodY34gnR9-vBq56b6ATUWyTbuUsik3tLniRHzFTGmd69NTubWS_/pub?output=csv\"\n\nd22 &lt;- read.csv(origen_16, stringsAsFactors = F, fileEncoding = \"UTF-8\") %&gt;%\n    mutate_all(as.character)\n\ndatos &lt;- bind_rows(d16, d19, d22)\n\nEn el chunk anterior, los objetos llamados origen son los enlaces a las bases de datos. La función read.csv tiene varios argumentos (como todas las funciones para leer bases de datos): - file es el primero y más importante, y es desde donde se va a leer la base de datos. Puede escribirse directamente. - stringsAsFactors es para que las variables que son texto no se conviertan en factores (un factor es una variable de categorías mutuamente excluyentes). - fileEncoding es para leer bien los acentos y carácteres especiales. UTF-8 y Windows 1252 son los más comunes.\nAdicionalmente, porque en un archivo la variable “fecha de primera menstruación” está almacenado como texto mientras que en otro como numérico, no se pueden combinar sin transformar alguno de los data frames. Por eso utilizó la función mutate_all que modifica todas las variables, en este caso para convertirlas en texto (strings).\n\nlibrary(DT)\n\nWarning: package 'DT' was built under R version 4.2.3\n\ndatatable(head(datos), rownames = F, class = \"display\")\n\n\n\n\n\nSi quieren saber que significan las variables, pueden descargar el diccionario de datos. Un Diccionario de datos es el estándar para explicar los nombres de las variables.\nAhora, los paquetes. Usualmente, los paquetes van al principio del código y van juntos.\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(janitor)\n\nWarning: package 'janitor' was built under R version 4.2.3\n\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\nVamos a hacer tablas con el conteo por las variables. Como es un ejemplo, trataré de hacer cosas basicas. Esto se hace con el paquete janitor. Además de hacer tablas, el paquete Janitor “limpia” las bases de datos. En este caso, vamos a cambiar los nombres de las variables: la variable Año suele tener\n\ndatos &lt;- clean_names(datos)\n\nnames(datos)\n\n [1] \"anio\"                      \"mes\"                      \n [3] \"fecha_ingreso\"             \"referida\"                 \n [5] \"estado_civil\"              \"edad\"                     \n [7] \"institucion_derechohab\"    \"nivel_edu\"                \n [9] \"ocupacion\"                 \"religion\"                 \n[11] \"parentesco\"                \"entidad\"                  \n[13] \"alcaldia\"                  \"municipio\"                \n[15] \"edad_primera_menstruacion\" \"edad_inicio_vida_sexual\"  \n[17] \"fecha_ultima_menstruacion\" \"semanas_embarazo\"         \n[19] \"numero_hijos\"              \"numero_embarazos\"         \n[21] \"numero_abortos\"            \"numero_partos\"            \n[23] \"numero_cesareas\"           \"numero_iles\"              \n[25] \"recibio_consejeria\"        \"uso_anticonceptivo\"       \n[27] \"fecha_primera_valoracion\"  \"numero_consultas\"         \n[29] \"motivos_interrupcion\"      \"fecha_ingreso_hosp\"       \n[31] \"fecha_egreso_hosp\"         \"desc_servicio\"            \n[33] \"semanas_gestacion_usg\"     \"dias_gestacion_usg\"       \n[35] \"firma_consentimiento\"      \"se_complica\"              \n[37] \"con_dolor\"                 \"analgesico\"               \n[39] \"anticonceptivo_post\"       \"fecha_cierre\"             \n[41] \"resultado_ile\"             \"procedimiento_ile\"        \n\n\n\ntabyl(datos, anio)\n\n anio     n      percent\n 2015     2 1.414467e-05\n 2016 36076 2.551416e-01\n 2017 35194 2.489038e-01\n 2018 31436 2.223259e-01\n 2019 15129 1.069974e-01\n 2020 11267 7.968401e-02\n 2021 12292 8.693315e-02\n\n\nEsta primera tabla muestra el número de procedimientos por año y el porcentaje del total. La función tabyl proviene del paquete janitor.\n\ntabyl(datos, anio, mes)\n\n anio Abril Agosto Diciembre Enero Febrero Julio Junio Marzo Mayo Noviembre\n 2015     0      0         0     0       0     0     0     0    0         2\n 2016  3316   3132      2302  2782    2938  3048  3316  2900 3048      3112\n 2017  2384   3186      2542  3518    2928  2790  2980  3352 3112      2722\n 2018  2852   2648      1788  3284    2852  2366  2614  3038 2894      1948\n 2019  1219   1334       941  1419    1271  1210  1218  1285 1480      1232\n 2020   883    786       803  1462    1373   782   663  1358  636       814\n 2021  1066   1158      1010   785     797  1021  1154  1063  960      1124\n Octubre Septiembre\n       0          0\n    3156       3026\n    3248       2432\n    2656       2496\n    1330       1190\n     888        819\n    1157        997\n\n\nEn este caso, la tabla no sale tan pulcra. Por esa razón vamos a hacerla con dplyr.\n\ntabla &lt;- datos %&gt;%\n    mutate(cont = 1) %&gt;%\n    group_by(anio, mes) %&gt;%\n    summarise(total = sum(cont))\n\n`summarise()` has grouped output by 'anio'. You can override using the\n`.groups` argument.\n\ndatatable(tabla, rownames = F)\n\n\n\n\n\nEsta tabla se hizo con dplyr. Este paquete nos permite manipular bases de datos de manera sencilla. Hay que pensar el procesamiento como pasos secuenciales. Es igual que la rutina de la mañana: te despiertas, revisas el teléfono, vas al baño, desayunas, etc.\nEn este caso, a la base “datos” le aplicaremos distintas operaciones gracias al operador pipe (%&gt;%). Es decir a la base de datos le haremos un mutate(crear una nueva variable) luego ( %&gt;% ) agrupamos las variables año y mes; para finalizar ( %&gt;% ) le hacemos un summarise (colpasamos la base de datos) en ese caso sumaremos la variable cont (que es ponerle un 1 a cada renglón) por año y mes.\nComo ya habrán notado, los meses están desordenados."
  },
  {
    "objectID": "posts/ile-en-cdmx/index.html#gráficas",
    "href": "posts/ile-en-cdmx/index.html#gráficas",
    "title": "Interrupción Legal del Embarazo en la Ciudad de México",
    "section": "Gráficas",
    "text": "Gráficas\n\ngraf &lt;- datos %&gt;%\n    mutate(cont = 1) %&gt;%\n    group_by(anio, mes) %&gt;%\n    summarise(total = sum(cont)) %&gt;%\n    ungroup() %&gt;%\n    group_by(anio) %&gt;%\n    mutate(\n        tot = sum(total),\n        porc = total / tot\n    ) %&gt;%\n    ungroup() %&gt;%\n    mutate(\n        mes = factor(mes,\n            levels = c(\n                \"Enero\", \"Febrero\", \"Marzo\", \"Abril\", \"Mayo\", \"Junio\",\n                \"Julio\", \"Agosto\", \"Septiembre\", \"Octubre\", \"Noviembre\", \"Diciembre\"\n            )\n        ),\n        anio = factor(anio,\n            levels = c(2016:2022)\n        )\n    )\n\n`summarise()` has grouped output by 'anio'. You can override using the\n`.groups` argument.\n\n\nEste código calcula el porcentaje por mes y año. Además, ordena los meses y el año como factores.\n\nggplot(graf, aes(x = mes, y = porc, group = anio)) +\n    geom_line(aes(color = anio)) +\n    scale_y_continuous(\n        labels = scales::percent_format(),\n        limits = c(0.05, 0.15)\n    )\n\nWarning: Removed 1 row containing missing values (`geom_line()`).\n\n\n\n\n\n\n\n\n\nEsta gráfica muestra el porcentaje por mes y por año. En esta gráfica utilizo lineas para mostrar la distribución de interrupciones por mes para los años disponibles. Esto a través del geom_line en donde cada año tiene un color distinto.\nAdemás, en scale_y_continous defino do parametros: labels, que es como se presentan los números, en este caso como porcentaje; y limits muestra que parte de la gráfica se debe visualizar. En este caso escogi entre el 5% y el 15% para ver los detalles. Mientras que en el caso de scales::, esta es una forma de utilizar una función de un paquete sin tener que poner library. ¿Qué por qué necesitamos esto? A veces cargar un paquete es demasiado para nuestra computadora, piensa que un paquete es como un foco, no prendes un foco de un cuarto en el que no estás.\n\ngraf2 &lt;- datos %&gt;%\n    mutate(cont = 1) %&gt;%\n    filter(anio &gt; 2015 & anio &lt; 2022) %&gt;%\n    group_by(anio, mes) %&gt;%\n    summarise(total = sum(cont)) %&gt;%\n    ungroup() %&gt;%\n    group_by(anio) %&gt;%\n    mutate(\n        tot = sum(total),\n        porc = total / tot\n    ) %&gt;%\n    ungroup() %&gt;%\n    mutate(\n        mes = factor(mes,\n            levels = c(\n                \"Enero\", \"Febrero\", \"Marzo\", \"Abril\", \"Mayo\", \"Junio\",\n                \"Julio\", \"Agosto\", \"Septiembre\", \"Octubre\", \"Noviembre\", \"Diciembre\"\n            )\n        ),\n        anio = factor(anio,\n            levels = c(2016:2021)\n        )\n    )\n\n`summarise()` has grouped output by 'anio'. You can override using the\n`.groups` argument.\n\n\nQuitamos el año en cuestión y volvemos a graficar.En este caso, no filtramos utilizando el mismo objeto debido a que un factor no se puede filtrar.\n\nggplot(graf2, aes(x = mes, y = porc, group = anio)) +\n    geom_line(aes(color = anio)) +\n    geom_point(aes(color = anio)) +\n    scale_y_continuous(\n        limits = c(0.05, 0.15),\n        labels = scales::percent_format()\n    ) +\n    labs(\n        title = \"Porcentaje de procedimientos mensuales en la CDMX\",\n        subtitle = \"2016 al 2021\",\n        x = \"\", y = \"\",\n        color = \"Año\"\n    ) +\n    theme_classic() +\n    theme(\n        axis.text.x = element_text(angle = 45, hjust = 0.9),\n        legend.position = \"bottom\"\n    )\n\n\n\n\n\n\n\n\nEn este caso, agregamos nuevos argumentos en theme. axis.text.x es para modificar como vemos las eetiquetas del eje de las x (el eje horizontal). En este caso, lo giré 45° y lo ajusté para que no se sobreponga.\nAunque son cosas sencillas, pueden ser interesantes para pensar y presentar puntos. Y aprovechando que tenemos una base con tantas variables, podemos jugar con los datos y ver que otras cosas aparecen. Por ejemplo:\n\nggplot(datos, aes(x = estado_civil, y = as.numeric(edad))) +\n    geom_boxplot() +\n    labs(\n        title = \"Diagrama de caja y brazos por estado civil\",\n        x = \"\", y = \"Edad\"\n    ) +\n    scale_y_continuous(breaks = seq(10, 60, by = 2)) +\n    coord_flip()\n\n\n\n\n\n\n\n\nUn diagrama de caja y brazos (boxplot) nos muestra de manera gráfica los cuartiles de una variable. Es decir, los extremos de la caja representan el primer y tercer cuartil. Y la barra dentro de la caja representa el promedio. Mientras que los puntos representan outliers o valores atípicos.\nComo ya vimos cambiar la escala del eje es fácil, pero también podemos agregarle más detalle para interpretarla mejor: breaks permite modificar la escala, en este caso utilicé una secuencia (seq) del 10 al 60 de 2 en 2.\nPor esta razón, esta gráfica muestra la distribución por edad de acuerdo al estado civil reportado para el procedimiento. Algo que salta a la vista es el hecho de que la mujer más joven sometida a un procedimiento es de 12 años.\nPor último, vamos a hacer esta misma gráfica, pero la separaremos por años.\n\nggplot(datos, aes(x = estado_civil, y = as.numeric(edad))) +\n    geom_boxplot() +\n    labs(\n        title = \"Diagrama de caja y brazos por estado civil\",\n        x = \"\", y = \"Edad\"\n    ) +\n    scale_y_continuous(breaks = seq(10, 60, by = 2)) +\n    coord_flip() +\n    facet_grid(anio ~ .)\n\n\n\n\n\n\n\n\nLa función facet_grid puede ser utilizado de manera fija (vertical u horizontal) o ajustarlo dentro de un rectángulo con facet_wrap. Los argumentos son los mismos en ambos casos: (variable1 ~ variable2). Con esto quiero decir que puede separar las gráficas por otras variables. En este caso, vemos los diagramas de caja y brazos por año. Pero así se ve muy feo, probemos otra configuración de los facet\n\nggplot(datos, aes(x = estado_civil, y = as.numeric(edad))) +\n    geom_boxplot() +\n    labs(\n        title = \"Diagrama de caja y brazos por estado civil\",\n        x = \"\", y = \"Edad\"\n    ) +\n    scale_y_continuous(breaks = seq(10, 60, by = 5)) +\n    theme(axis.text.x = element_text(angle = 90)) +\n    coord_flip() +\n    facet_grid(cols = vars(as.numeric(anio)))\n\n\n\n\n\n\n\n\nAquí le especificamos a R que ponga un número de columnas igual al de nuestra variable de interés (como no la podemos “pasar” directamente utilizamos vars de dplyr).\n\nggplot(datos, aes(x = nivel_edu, y = as.numeric(numero_hijos))) +\n    geom_boxplot() +\n    scale_y_continuous(breaks = seq(0, 10, by = 1)) +\n    labs(\n        title = \"Distribución de hijes por nivel educativo\",\n        x = \"\", y = \"Número de hijes\"\n    ) +\n    coord_flip()\n\nWarning: Removed 18398 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\nDe manera similar, podemos observar el número de hijes por nivel educativo de las pacientes. Hay muchísimos valores atípicos."
  },
  {
    "objectID": "posts/ile-en-cdmx/index.html#función-summary-correlación-y-diagramas-de-dispersión",
    "href": "posts/ile-en-cdmx/index.html#función-summary-correlación-y-diagramas-de-dispersión",
    "title": "Interrupción Legal del Embarazo en la Ciudad de México",
    "section": "Función summary, correlación y diagramas de dispersión",
    "text": "Función summary, correlación y diagramas de dispersión\nAsimismo, algo que no he mencionada claramente es que después de usar la función mutate_all todas las variables se modificaron, para convertirse en strings (o texto) y esto no siempre es útil al momento de gráficar. Por eso, si observaron, utilicé la función as_numeric dentro de las gráficas: para especificar que se trataba de una variable numérica.\nPara hacer más análisis, es conveniente conocer las distribuciones de las variables y su relación entre ellas. Por lo que convertiremos aquellas variables numéricas y exploraremos el contenido de ese conjunto de datos.\n\nhead(datos)\n\n  anio   mes fecha_ingreso referida estado_civil edad institucion_derechohab\n1 2016 Abril    2016-04-01     &lt;NA&gt;      Soltera   24                Ninguno\n2 2016 Abril    2016-04-01     &lt;NA&gt;      Soltera   30                Ninguno\n3 2016 Abril    2016-04-01     &lt;NA&gt;       Casada   38                Ninguno\n4 2016 Abril    2016-04-01     &lt;NA&gt;      Soltera   23                Ninguno\n5 2016 Abril    2016-04-01     &lt;NA&gt;      Soltera   18                Ninguno\n6 2016 Abril    2016-04-01     &lt;NA&gt;      Soltera   18                Ninguno\n                         nivel_edu                           ocupacion religion\n1                     Preparatoria                          Estudiante  Ninguna\n2                       Secundaria Trabajadora del hogar no remunerada Católica\n3 Sin acceso a la educacion formal Trabajadora del hogar no remunerada Católica\n4                     Preparatoria                            Empleada  Ninguna\n5                       Secundaria                          Estudiante  Ninguna\n6                       Secundaria                            Empleada  Ninguna\n  parentesco          entidad      alcaldia           municipio\n1       &lt;NA&gt; Ciudad de México  Azcapotzalco                CDMX\n2       &lt;NA&gt; Estado de México Fuera de CDMX Ecatepec de Morelos\n3       &lt;NA&gt; Estado de México Fuera de CDMX Ecatepec de Morelos\n4       &lt;NA&gt; Estado de México          &lt;NA&gt;                &lt;NA&gt;\n5       &lt;NA&gt; Estado de México          &lt;NA&gt;                &lt;NA&gt;\n6       &lt;NA&gt; Estado de México          &lt;NA&gt;                &lt;NA&gt;\n  edad_primera_menstruacion edad_inicio_vida_sexual fecha_ultima_menstruacion\n1                        12                      13                27/01/2016\n2                        12                      17                08/01/2016\n3                        13                      15                15/02/2016\n4                        10                      15                20/02/2016\n5                        13                      15                18/02/2016\n6                        14                      16                01/02/2016\n  semanas_embarazo numero_hijos numero_embarazos numero_abortos numero_partos\n1                1            8                0              0             0\n2                3            9                0              1             0\n3                7            4                0              5             0\n4                2            4                0              0             0\n5                1            4                0              0             0\n6                2            7                0              1             0\n  numero_cesareas numero_iles recibio_consejeria uso_anticonceptivo\n1               0        &lt;NA&gt;                 Si            Ninguno\n2               1        &lt;NA&gt;                 Si            Ninguno\n3               1        &lt;NA&gt;                 Si            Ninguno\n4               1        &lt;NA&gt;                 Si            Ninguno\n5               0        &lt;NA&gt;                 Si            Ninguno\n6               0        &lt;NA&gt;                 Si            Ninguno\n  fecha_primera_valoracion numero_consultas    motivos_interrupcion\n1               01/04/2016                1 Interrupción voluntaria\n2               01/04/2016                1 Interrupción voluntaria\n3               01/04/2016                1 Interrupción voluntaria\n4               01/04/2016                1 Interrupción voluntaria\n5               01/04/2016                1 Interrupción voluntaria\n6               01/04/2016                1 Interrupción voluntaria\n  fecha_ingreso_hosp fecha_egreso_hosp desc_servicio semanas_gestacion_usg\n1               &lt;NA&gt;              &lt;NA&gt;          &lt;NA&gt;                     3\n2               &lt;NA&gt;              &lt;NA&gt;          &lt;NA&gt;                     6\n3               &lt;NA&gt;              &lt;NA&gt;          &lt;NA&gt;                     2\n4               &lt;NA&gt;              &lt;NA&gt;          &lt;NA&gt;                     1\n5               &lt;NA&gt;              &lt;NA&gt;          &lt;NA&gt;                     0\n6               &lt;NA&gt;              &lt;NA&gt;          &lt;NA&gt;                     5\n  dias_gestacion_usg firma_consentimiento se_complica con_dolor analgesico\n1               &lt;NA&gt;                 &lt;NA&gt;        &lt;NA&gt;      &lt;NA&gt;       &lt;NA&gt;\n2               &lt;NA&gt;                 &lt;NA&gt;        &lt;NA&gt;      &lt;NA&gt;       &lt;NA&gt;\n3               &lt;NA&gt;                 &lt;NA&gt;        &lt;NA&gt;      &lt;NA&gt;       &lt;NA&gt;\n4               &lt;NA&gt;                 &lt;NA&gt;        &lt;NA&gt;      &lt;NA&gt;       &lt;NA&gt;\n5               &lt;NA&gt;                 &lt;NA&gt;        &lt;NA&gt;      &lt;NA&gt;       &lt;NA&gt;\n6               &lt;NA&gt;                 &lt;NA&gt;        &lt;NA&gt;      &lt;NA&gt;       &lt;NA&gt;\n  anticonceptivo_post fecha_cierre resultado_ile procedimiento_ile\n1              Condón   08/04/2016      Completa       Medicamento\n2              Condón   08/04/2016      Completa       Medicamento\n3              Condón   08/04/2016      Completa       Medicamento\n4              Condón   08/04/2016      Completa       Medicamento\n5             Ninguno   15/04/2016          Otro       Medicamento\n6              Condón   08/04/2016      Completa       Medicamento\n\n\nCuando no conocemos el contenido de los datos siempre es útil ver los primeros renglones de un conjunto, y exactamente eso es lo que hace la función head.\n\ndatos &lt;- datos %&gt;%\n    mutate(\n        fecha_ingreso = lubridate::ymd(fecha_ingreso),\n        edad = as.numeric(edad),\n        edad_primera_menstruacion = as.numeric(edad_primera_menstruacion),\n        edad_inicio_vida_sexual = as.numeric(edad_inicio_vida_sexual),\n        fecha_ultima_menstruacion = lubridate::dym(fecha_ultima_menstruacion),\n        semanas_embarazo = as.numeric(semanas_embarazo),\n        numero_hijos = as.numeric(numero_hijos),\n        numero_embarazos = as.numeric(numero_embarazos),\n        numero_abortos = as.numeric(numero_abortos),\n        numero_partos = as.numeric(numero_partos),\n        fecha_primera_valoracion = lubridate::dmy(fecha_primera_valoracion),\n        numero_consultas = as.numeric(numero_consultas),\n        semanas_gestacion_usg = as.numeric(semanas_gestacion_usg),\n    )\n\nWarning: There were 3 warnings in `mutate()`.\nThe first warning was:\nℹ In argument: `edad_primera_menstruacion =\n  as.numeric(edad_primera_menstruacion)`.\nCaused by warning:\n! NAs introduced by coercion\nℹ Run `dplyr::last_dplyr_warnings()` to see the 2 remaining warnings.\n\nsummary(datos)\n\n     anio               mes            fecha_ingreso          referida        \n Length:141396      Length:141396      Min.   :2016-01-04   Length:141396     \n Class :character   Class :character   1st Qu.:2016-12-16   Class :character  \n Mode  :character   Mode  :character   Median :2017-12-20   Mode  :character  \n                                       Mean   :2018-03-31                     \n                                       3rd Qu.:2019-03-14                     \n                                       Max.   :2021-12-31                     \n                                                                              \n estado_civil            edad       institucion_derechohab  nivel_edu        \n Length:141396      Min.   :11.00   Length:141396          Length:141396     \n Class :character   1st Qu.:21.00   Class :character       Class :character  \n Mode  :character   Median :25.00   Mode  :character       Mode  :character  \n                    Mean   :25.77                                            \n                    3rd Qu.:30.00                                            \n                    Max.   :56.00                                            \n                                                                             \n  ocupacion           religion          parentesco          entidad         \n Length:141396      Length:141396      Length:141396      Length:141396     \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n   alcaldia          municipio         edad_primera_menstruacion\n Length:141396      Length:141396      Min.   :   0.00          \n Class :character   Class :character   1st Qu.:  12.00          \n Mode  :character   Mode  :character   Median :  12.00          \n                                       Mean   :  12.66          \n                                       3rd Qu.:  14.00          \n                                       Max.   :1218.00          \n                                       NA's   :7263             \n edad_inicio_vida_sexual fecha_ultima_menstruacion semanas_embarazo\n Min.   : -1.00          Min.   :NA                Min.   : 0.000  \n 1st Qu.: 15.00          1st Qu.:NA                1st Qu.: 6.000  \n Median : 17.00          Median :NA                Median : 7.000  \n Mean   : 16.96          Mean   :NaN               Mean   : 7.366  \n 3rd Qu.: 18.00          3rd Qu.:NA                3rd Qu.: 9.000  \n Max.   :128.00          Max.   :NA                Max.   :39.000  \n NA's   :7065            NA's   :141396            NA's   :9182    \n  numero_hijos   numero_embarazos numero_abortos   numero_partos   \n Min.   : 0.00   Min.   : 0.000   Min.   : 0.000   Min.   : 0.000  \n 1st Qu.: 0.00   1st Qu.: 1.000   1st Qu.: 0.000   1st Qu.: 0.000  \n Median : 1.00   Median : 2.000   Median : 0.000   Median : 0.000  \n Mean   : 1.03   Mean   : 2.341   Mean   : 0.175   Mean   : 0.699  \n 3rd Qu.: 2.00   3rd Qu.: 3.000   3rd Qu.: 0.000   3rd Qu.: 1.000  \n Max.   :10.00   Max.   :47.000   Max.   :10.000   Max.   :12.000  \n NA's   :18398   NA's   :5500     NA's   :7909     NA's   :7355    \n numero_cesareas    numero_iles        recibio_consejeria uso_anticonceptivo\n Length:141396      Length:141396      Length:141396      Length:141396     \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n fecha_primera_valoracion numero_consultas motivos_interrupcion\n Min.   :2015-01-13       Min.   :0.00     Length:141396       \n 1st Qu.:2016-08-17       1st Qu.:1.00     Class :character    \n Median :2017-04-27       Median :2.00     Mode  :character    \n Mean   :2017-05-08       Mean   :1.63                         \n 3rd Qu.:2018-01-22       3rd Qu.:2.00                         \n Max.   :2022-06-30       Max.   :7.00                         \n NA's   :72122            NA's   :55083                        \n fecha_ingreso_hosp fecha_egreso_hosp  desc_servicio      semanas_gestacion_usg\n Length:141396      Length:141396      Length:141396      Min.   : 0.000       \n Class :character   Class :character   Class :character   1st Qu.: 5.000       \n Mode  :character   Mode  :character   Mode  :character   Median : 7.000       \n                                                          Mean   : 6.849       \n                                                          3rd Qu.: 8.000       \n                                                          Max.   :13.000       \n                                                          NA's   :58           \n dias_gestacion_usg firma_consentimiento se_complica         con_dolor        \n Length:141396      Length:141396        Length:141396      Length:141396     \n Class :character   Class :character     Class :character   Class :character  \n Mode  :character   Mode  :character     Mode  :character   Mode  :character  \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n  analgesico        anticonceptivo_post fecha_cierre       resultado_ile     \n Length:141396      Length:141396       Length:141396      Length:141396     \n Class :character   Class :character    Class :character   Class :character  \n Mode  :character   Mode  :character    Mode  :character   Mode  :character  \n                                                                             \n                                                                             \n                                                                             \n                                                                             \n procedimiento_ile \n Length:141396     \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n                   \n\n\nLa función summary muestra las medidas de dispersión de las variables numéricas. Estas son: mínimo, primer cuartil, mediana, promedio (media), tercer cuartil y máximo. Para ampliar el análisis y tener mayor precisión, calcularemos la matriz de correlación de las variables numéricas.\n\ndata_corr &lt;- datos %&gt;%\n    select_if(is.numeric) %&gt;%\n    cor(use = \"complete.obs\")\n\ndata_corr\n\n                                  edad edad_primera_menstruacion\nedad                       1.000000000               0.057586227\nedad_primera_menstruacion  0.057586227               1.000000000\nedad_inicio_vida_sexual    0.297156958               0.165297888\nsemanas_embarazo          -0.047583584               0.002419982\nnumero_hijos               0.529754901               0.018214861\nnumero_embarazos           0.509453410               0.015384603\nnumero_abortos             0.184712016              -0.005272162\nnumero_partos              0.438648925               0.014829545\nnumero_consultas           0.007061204              -0.013576089\nsemanas_gestacion_usg     -0.051257514               0.009819498\n                          edad_inicio_vida_sexual semanas_embarazo numero_hijos\nedad                                  0.297156958     -0.047583584  0.529754901\nedad_primera_menstruacion             0.165297888      0.002419982  0.018214861\nedad_inicio_vida_sexual               1.000000000     -0.035772751 -0.089176568\nsemanas_embarazo                     -0.035772751      1.000000000  0.007242731\nnumero_hijos                         -0.089176568      0.007242731  1.000000000\nnumero_embarazos                     -0.086979103      0.002583078  0.777413606\nnumero_abortos                       -0.025962601     -0.016181134  0.133229390\nnumero_partos                        -0.097278151      0.025068613  0.811973489\nnumero_consultas                      0.005425544     -0.011453455 -0.011822880\nsemanas_gestacion_usg                -0.038712091      0.543637998  0.024342230\n                          numero_embarazos numero_abortos numero_partos\nedad                          0.5094534098    0.184712016   0.438648925\nedad_primera_menstruacion     0.0153846034   -0.005272162   0.014829545\nedad_inicio_vida_sexual      -0.0869791025   -0.025962601  -0.097278151\nsemanas_embarazo              0.0025830776   -0.016181134   0.025068613\nnumero_hijos                  0.7774136061    0.133229390   0.811973489\nnumero_embarazos              1.0000000000    0.359192997   0.689282273\nnumero_abortos                0.3591929968    1.000000000   0.082375706\nnumero_partos                 0.6892822729    0.082375706   1.000000000\nnumero_consultas              0.0007671129   -0.004946456  -0.005796846\nsemanas_gestacion_usg         0.0033645966   -0.013170875   0.040325056\n                          numero_consultas semanas_gestacion_usg\nedad                          0.0070612036          -0.051257514\nedad_primera_menstruacion    -0.0135760890           0.009819498\nedad_inicio_vida_sexual       0.0054255435          -0.038712091\nsemanas_embarazo             -0.0114534551           0.543637998\nnumero_hijos                 -0.0118228801           0.024342230\nnumero_embarazos              0.0007671129           0.003364597\nnumero_abortos               -0.0049464559          -0.013170875\nnumero_partos                -0.0057968461           0.040325056\nnumero_consultas              1.0000000000          -0.059300863\nsemanas_gestacion_usg        -0.0593008633           1.000000000\n\n\nEsta es una matriz de correlación, la interpretación “estándar” (dependera del análisis y de las fuentes) es que una correlación perfecta tendría que tomar valores de 1 o -1, mientras que valores más cercanos a 0 implican que no existe una correlación. Además, un valor superior a 0.6 indica una fuerte correlación: si tiene signo negativo implica que el aumento de una variable necesariamente reduce la otra; mientras que un signo positivo, indica que el aumento de una variable significa el aumento de la otra.\nSin embargo, esta no es una manera inmediata de entender la relación entre variables.\n\nlibrary(corrplot)\n\nWarning: package 'corrplot' was built under R version 4.2.3\n\n\ncorrplot 0.92 loaded\n\ncorrplot(data_corr,\n    type = \"upper\", order = \"hclust\",\n    tl.col = \"black\", tl.srt = 45\n)\n\n\n\n\n\n\n\n\nAhora bien, vamos por partes. Este paquete está diseñado para visualizar matrices de correlaciones, por lo cual es muy útil. Necesita, por lo menos, el parámetro corr que es la matriz de correlación. El resto de los parámetros son meramente estéticos: type = “upper” sirve para ver solo la parte superior, order indica como se van a ordenar las correlaciones (jerarquía) y tl.col y tl.srt sirven para determinar el color y la inclinación de las etiquetas. Los parametros de una función pueden consultarse si en la terminal o en el código escribe un signo de interrogación seguido del nombre de la función sin paréntesis: ?corrplot. Esto funciona si el paquete está cargado (library).\nAlgo que podemos observar es que las correlaciones pueden ser interpretadas fácilmente: número de embarazos con número de parto; semanas de gestación y semanas de embarazo; edad y número de hijos. Todas con una relación positiva, lo que signfica, por ejemplo, que si aumenta la edad aumenta el número de hijos.\nSin embargo, con una correlación negativa está, aunque débil, edad de inicio de vida sexual y el número de embarazos. Lo que se puede interpretar como que personas que inician su vida sexual más tarde tienen un menor número de embarazos.\nPara explorar estas relaciones se puede utilizar un diagrama de dispersión (scatter plot).\n\nggplot(datos, aes(y = edad_inicio_vida_sexual, x = numero_embarazos)) +\n    geom_point(aes(col = nivel_edu, size = numero_abortos)) +\n    theme_classic() +\n    theme(legend.position = \"bottom\")\n\nWarning: Removed 9136 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\nCon este código podemos visualizar la correlación entre el número de embarazos, eje x, y la edad, eje y, junto con otras dos variables: nivel educativo y número de abortos.\nY con estas herramientas ahora ustedes pueden realizar sus primeros análisis y empezar a jugar con otras bases de datos. Si bien el análisis puede continuar, este ejemplo pretende mostrar algunas operaciones básicas que se pueden hacer a una base de datos. Además, es necesario tener contexto de los datos, ya que sin un conocimiento previo de los datos limitan que tantos problemas podemos imaginar de un conjunto de datos.\nSi creen que me falto algo, tienen dudas o quejas, no duden en contactarme para ampliar este post."
  },
  {
    "objectID": "posts/dias-sin-ti/index.html",
    "href": "posts/dias-sin-ti/index.html",
    "title": "‘Días sin ti’",
    "section": "",
    "text": "En esta ocasión sigo investigando hacer cosas interesantes de análisis de texto, pero voy a aprovechar para practicar como sacar información de archivos pdf. Esta es una gran herramienta porque en el mundo real los gobiernos nos mandan información pública en pdf y muchas veces pasarlos a mano no es una opción viable…\nBueno, regresando al tema, hoy voy a analizar una novela que acabo de terminar: Días sin ti, de Elvira Sastre. Una novela de corazones rotos a través de la perspectiva de una abuela que perdió a su esposo durante la guerra civil española, y su nieto a quien su pareja lo deja. Son doce capítulos que representan las fases del enamoramiento, y si no la han leído, háganlo, es hermosa.\nNo saben cómo me emociona la posibilidad de hacer este análisis.\n\nDías sin ti es una historia de complicidad a través del tiempo, la de una abuela y su nieto. Dora, maestra en tiempos de la República, comparte con Gael la historia que la ha llevado a ser quien es. Con ternura, pero con crudeza, confiesa sus emociones a su nieto escultor, un joven con una sensibilidad especial, y le brinda, sin que éste lo sepa todavía, las claves para reponerse de las heridas causadas por un amor truncado.\nA través de la reflexión y de lo que enseña la melancolía, esta novela transita esos caminos por los que todos, en algún momento, tenemos que pasar para comprender que la vida y el amor son sublimes precisamente porque tienen un final.\n\nPara realizar este análisis, es necesario que utilicen su copia de la novela en pdf.\n\nlibrary(stringr)\n\nWarning: package 'stringr' was built under R version 4.2.3\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyr)\n\nWarning: package 'tidyr' was built under R version 4.2.3\n\nlibrary(ggplot2)\nlibrary(tidytext)\n\nWarning: package 'tidytext' was built under R version 4.2.3\n\nlibrary(pdftools)\n\nWarning: package 'pdftools' was built under R version 4.2.3\n\n\nUsing poppler version 22.04.0\n\nlibrary(tm)\n\nWarning: package 'tm' was built under R version 4.2.3\n\n\nLoading required package: NLP\n\n\n\nAttaching package: 'NLP'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    annotate\n\nlibrary(syuzhet)\n\nWarning: package 'syuzhet' was built under R version 4.2.3\n\nlibrary(plotly)\n\nWarning: package 'plotly' was built under R version 4.2.3\n\n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\nlibrary(forcats)\nlibrary(wordcloud2)\n\nWarning: package 'wordcloud2' was built under R version 4.2.3\n\n\nHay 2 paquetes nuevos: pdftools y syuzhet. El primero, sirve para extraer texto, adjuntos y metadata de los pdf (ojo, yo personalmente no recomiendo este paquete para extraer tablas/bases de datos, para eso yo recomiendo usar tabulizer).\nEl segundo, es un paquete que tiene cuatro diccionarios de sentimientos. En otras palabras, gente muy chingona está alimentando este paquete constantemente con palabras y sentimientos de diversas fuentes.\n\ninp &lt;- \"D:/dhumb/Documents/projects/data_blog\"\npdf &lt;- paste(inp, \"dias_sin_ti.pdf\", sep = \"/\")\n\n\ndias_pdf &lt;- pdf_text(pdf) %&gt;%\n    as_tibble() %&gt;%\n    mutate(\n        capitulo = cumsum(str_detect(value, \"SIN TI\")),\n        value = str_remove_all(value, paste(\"Página\", \"[:digit:]\", sep = \" \"))\n    )\ndias &lt;- dias_pdf %&gt;%\n    unnest_tokens(Palabra, value) %&gt;%\n    filter(!Palabra %in% stopwords(\"es\"))\n\nHasta aquí, el proceso es el mismo: leemos nuestra copia de “Días sin ti” (que no sale en el código), y luego lo convertimos en data frame (as_tibble), creo una variable para dividir el libro en capítulos y le quito el número de página a todos las páginas. Por último, convertimos todo a tidy text y quitamos las stop words.\n\ndias %&gt;%\n    count(Palabra, sort = T) %&gt;%\n    filter(n &gt;= 99) %&gt;%\n    mutate(Palabra = reorder(Palabra, n)) %&gt;%\n    ggplot(aes(x = n, y = Palabra)) +\n    geom_bar(stat = \"identity\") +\n    labs(\n        x = \"\", y = \"\",\n        title = \"Palabras más frecuentes\",\n        subtitle = \"En todo el libro\"\n    )\n\n\n\n\n\n\n\n\n\n\nAhora, vamos a realizar el análisis de sentimientos como la vez anterior y con otra función para comparar resultados.\n\nafinn &lt;- read.csv(\"https://raw.githubusercontent.com/jboscomendoza/rpubs/master/sentimientos_afinn/lexico_afinn.en.es.csv\")\ninner_join(dias, afinn, by = \"Palabra\") %&gt;%\n    mutate(tipo = ifelse(Puntuacion &gt; 0, \"Positiva\", \"Negativa\")) %&gt;%\n    group_by(tipo) %&gt;%\n    count(Palabra, sort = T) %&gt;%\n    filter(n &gt;= 30) %&gt;%\n    mutate(Palabra = reorder(Palabra, n)) %&gt;%\n    ggplot(aes(x = n, y = Palabra, fill = tipo)) +\n    geom_bar(stat = \"identity\", position = \"dodge\") +\n    labs(\n        title = \"Análisis de sentimientos\",\n        subtitle = \"Dataset Afinn\",\n        x = \"\", y = \"\",\n        fill = \"Tipo de emoción\"\n    ) +\n    theme_classic() +\n    theme(legend.position = \"bottom\")\n\nWarning in inner_join(dias, afinn, by = \"Palabra\"): Each row in `x` is expected to match at most 1 row in `y`.\nℹ Row 49 of `x` matches multiple rows.\nℹ If multiple matches are expected, set `multiple = \"all\"` to silence this\n  warning.\n\n\n\n\n\n\n\n\n\nAhora, vamos a utilizar el paquete syuzhet. Ojo, esta función tarda un rato en correr.\nNos va a devolver un data frame con los resultados por palabra en 8 categorías diferentes: - anger - anticipation - disgust - fear - joy - sadness - surprise - trust\n\ndias_nrc &lt;- get_nrc_sentiment(char_v = dias$Palabra, language = \"spanish\")\ndias_final &lt;- bind_cols(dias, dias_nrc)\n\nPosteriormente, hay que unir este data frame por emociones con nuestro data frame original. Le hice una transformación con tidyr para poder gráficar, y así debe de quedar:\n\ndias_final %&gt;%\n    pivot_longer(\n        cols = 3:12\n    ) %&gt;%\n    group_by(name) %&gt;%\n    summarise(total = sum(value)) %&gt;%\n    ungroup() %&gt;%\n    mutate(name = reorder(name, total)) %&gt;%\n    ggplot(aes(x = name, y = total, fill = name)) +\n    geom_bar(stat = \"identity\") +\n    scale_fill_manual(\n        breaks = c(\"disgust\", \"surprise\", \"anger\", \"joy\", \"anticipation\", \"fear\", \"sadness\", \"trust\", \"positive\", \"negative\"),\n        values = c(\"#24D204\", \"#06CBBE\", \"#CB0606\", \"#FBFE00\", \"#FF9200\", \"#46BF5F\", \"#5479C3\", \"#01FF4C\", \"#FF00DC\", \"#000000\")\n    ) +\n    theme_classic() +\n    labs(\n        title = \"Análisis de sentimientos en todo el libro\",\n        subtitle = \"Syuzhet\",\n        x = \"\", y = \"\"\n    ) +\n    theme(legend.position = \"blank\")\n\n\n\n\n\n\n\n\nClaramente syuzhet es superior a afinn. Pero requiere mucho más tiempo de procesamiento, y por lo tanto si te equivocas vas a darte de topes, pero creo que lo vale.\nRecapitulemos un poco: afinn clasifica las palabras y nosotros le asignamos una intención positica o negativa en función de su signo distinto a cero. Mientras que syuzhet te devuelve un data frame con 10 categorías, ya que una sola palabra puede tener multiples intenciones. Además, te indica si la intención de esta es positiva o negativa.\nLeí en la documentación, que hay diversas metodologías para realizar el procesamiento de texto. Pero eso es material para otro post. Ahora quiero aprovechar esta claificación para revisar los sentimientos por capitulo :D\n\nplot_chapter_all &lt;- dias_final %&gt;%\n    pivot_longer(\n        cols = 3:12\n    ) %&gt;%\n    filter(name != \"positive\" & name != \"negative\") %&gt;%\n    group_by(capitulo, name) %&gt;%\n    summarise(value = sum(value)) %&gt;%\n    mutate(\n        total = sum(value),\n        porcentaje = round((value * 100) / total, 2)\n    ) %&gt;%\n    ungroup() %&gt;%\n    ggplot(aes(x = name, y = porcentaje, fill = name)) +\n    geom_bar(stat = \"identity\") +\n    scale_fill_manual(\n        breaks = c(\"disgust\", \"surprise\", \"anger\", \"joy\", \"anticipation\", \"fear\", \"sadness\", \"trust\"),\n        values = c(\"#24D204\", \"#06CBBE\", \"#CB0606\", \"#FBFE00\", \"#FF9200\", \"#46BF5F\", \"#5479C3\", \"#01FF4C\")\n    ) +\n    coord_flip() +\n    theme_classic() +\n    theme(\n        legend.position = \"blank\",\n        axis.text.x = element_blank()\n    ) +\n    facet_grid(cols = vars(capitulo)) +\n    labs(\n        title = \"Proporción de sentimientos\",\n        subtitle = \"Por capítulo\",\n        x = \"\", y = \"\"\n    )\n\n`summarise()` has grouped output by 'capitulo'. You can override using the\n`.groups` argument.\n\nggplotly(plot_chapter_all) %&gt;%\n    layout(showlegend = F)\n\n\n\n\n\nAún tengo problemas con plotly, pero con esto ustedes pueden ver el porcentaje de los sentimientos por capítulos. Este cálculo es la suma de todas las observaciones por capítulo. Es decir, si hay 10 puntos de ira, y en el capitulo hay 100 puntos, esto implica que el 10% de texto del capítulo tiene la emoción del enojo (ira).\nAhora, solo veamos las emociones negativas y positivas por capítulo.\n\nplot_chapter &lt;- dias_final %&gt;%\n    select(-c(3:10)) %&gt;%\n    pivot_longer(\n        cols = 3:4\n    ) %&gt;%\n    group_by(capitulo, name) %&gt;%\n    summarise(value = sum(value)) %&gt;%\n    mutate(\n        total = sum(value),\n        porcentaje = round((value * 100) / total, 2)\n    ) %&gt;%\n    ungroup() %&gt;%\n    ggplot(aes(x = name, y = porcentaje, fill = name)) +\n    geom_bar(stat = \"identity\") +\n    scale_fill_manual(\n        breaks = c(\"positive\", \"negative\"),\n        values = c(\"#FF00DC\", \"#000000\")\n    ) +\n    theme_classic() +\n    theme(\n        axis.text.x = element_blank(),\n        legend.position = \"bottom\"\n    ) +\n    facet_grid(cols = vars(capitulo)) +\n    labs(\n        title = \"Emociones positivas y negativas\",\n        x = \"\", y = \"\", fill = \"Emoción\"\n    )\n\n`summarise()` has grouped output by 'capitulo'. You can override using the\n`.groups` argument.\n\nggplotly(plot_chapter) %&gt;%\n    layout(showlegend = F)\n\n\n\n\n\nCon esto tenemos una aproximación más clara sobre lo que trata el libro, o mejor dicho, de lo que vamos a sentir. Sin embargo, no solo se trata de eso. Continuando con el texto de Julia Silge, podemos hacer una matriz tf-idf (Term Frequency - Inverse Document Frequency). Este análisis muestra la frecuencia de una palabra ajustada por su uso (una multiplicación). Afortunadamente,tidytext ya tiene una función para esto.\n\n\n\n\ndias %&gt;%\n    group_by(capitulo) %&gt;%\n    count(Palabra, sort = T) %&gt;%\n    mutate(\n        total = sum(n)\n    ) %&gt;%\n    bind_tf_idf(Palabra, capitulo, n) %&gt;%\n    ungroup() %&gt;%\n    filter(tf_idf &gt; 0.015) %&gt;%\n    ggplot(aes(x = tf_idf, y = fct_reorder(Palabra, tf_idf), fill = Palabra)) +\n    geom_bar(stat = \"identity\") +\n    scale_x_continuous(labels = scales::percent) +\n    theme_classic() +\n    theme(legend.position = \"blank\") +\n    labs(\n        title = \"Matriz tf-idf\",\n        subtitle = \"Importancia relativa de las palabras\",\n        x = \"\", y = \"\"\n    )\n\n\n\n\n\n\n\n\nCon esto, es evidente que las palabras más utilizadas en un texto (usualmente conectores) no son tan importantes. La intuición es que la importancia de una palabra es inversamente proporcional a su frecuencia.Pero, algo que ya habíamos empezado a explorar en el primer post de esta serie es entender que a veces una palabra no tiene significado por sí misma, sino que su significado lo obtiene en función de las otras palabras a su alrededor. ¡Vamos a regresar con los n-gramas!\n\nbigramas &lt;- dias_pdf %&gt;%\n    unnest_tokens(bigrama, value, token = \"ngrams\", n = 2) %&gt;%\n    separate(bigrama, c(\"palabra1\", \"palabra2\"), sep = \" \") %&gt;%\n    filter(!palabra1 %in% stopwords(\"es\")) %&gt;%\n    filter(!palabra2 %in% stopwords(\"es\"))\n\nbigramas %&gt;%\n    count(palabra1, palabra2, sort = T)\n\n# A tibble: 7,671 × 3\n   palabra1 palabra2      n\n   &lt;chr&gt;    &lt;chr&gt;     &lt;int&gt;\n 1 primera  vez          27\n 2 cada     vez          14\n 3 di       cuenta       13\n 4 mismo    tiempo       11\n 5 voz      alta         10\n 6 siento   orgulloso     9\n 7 todas    partes        9\n 8 cada     día           8\n 9 primer   día           8\n10 santa    clara         8\n# ℹ 7,661 more rows\n\n\nCon los n-gramas también se puede hacer la matriz tf-idf\n\nbigramas %&gt;%\n    unite(bigrama, palabra1, palabra2, sep = \" \") %&gt;%\n    count(capitulo, bigrama, sort = T) %&gt;%\n    bind_tf_idf(bigrama, capitulo, n) %&gt;%\n    arrange(desc(tf_idf))\n\n# A tibble: 8,196 × 6\n   capitulo bigrama                n    tf   idf tf_idf\n      &lt;int&gt; &lt;chr&gt;              &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1        0 agujero inmenso        1 0.025  2.56 0.0641\n 2        0 alguien falta          1 0.025  2.56 0.0641\n 3        0 aquella felicidad      1 0.025  2.56 0.0641\n 4        0 arrebatado hoy         1 0.025  2.56 0.0641\n 5        0 ausencias elegidas     1 0.025  2.56 0.0641\n 6        0 cada persona           1 0.025  2.56 0.0641\n 7        0 celebre aquella        1 0.025  2.56 0.0641\n 8        0 consiguen llenarlo     1 0.025  2.56 0.0641\n 9        0 damos cuenta           1 0.025  2.56 0.0641\n10        0 debemos forzar         1 0.025  2.56 0.0641\n# ℹ 8,186 more rows\n\n\n\n# dias_topic &lt;- dias %&gt;%\n#   count(capitulo, Palabra, sort = T)\n#\n# dias_dtm &lt;- dias_topic %&gt;%\n#   cast_dtm(capitulo, Palabra, n)\n#\n# topic &lt;- LDA(dias_dtm, k = 4, control = list(seed = 1234))\n\nY con esto, ya casi terminamos de revisar todo lo que se puede hacer con análisis de texto. El único tema faltante es topic modeling, pero, aún no lo entiendo bien. De verdad, lean Días sin ti, es una gran novela. Disfruté mucho hacer este post. Si quieren revisar temas de topic modeling denle clic al link de la Universidad de Valladolid.\n\nset.seed(123)\ndias %&gt;%\n    count(Palabra, sort = T) %&gt;%\n    wordcloud2()"
  },
  {
    "objectID": "posts/dias-sin-ti/index.html#sentiment-analysis",
    "href": "posts/dias-sin-ti/index.html#sentiment-analysis",
    "title": "‘Días sin ti’",
    "section": "",
    "text": "Ahora, vamos a realizar el análisis de sentimientos como la vez anterior y con otra función para comparar resultados.\n\nafinn &lt;- read.csv(\"https://raw.githubusercontent.com/jboscomendoza/rpubs/master/sentimientos_afinn/lexico_afinn.en.es.csv\")\ninner_join(dias, afinn, by = \"Palabra\") %&gt;%\n    mutate(tipo = ifelse(Puntuacion &gt; 0, \"Positiva\", \"Negativa\")) %&gt;%\n    group_by(tipo) %&gt;%\n    count(Palabra, sort = T) %&gt;%\n    filter(n &gt;= 30) %&gt;%\n    mutate(Palabra = reorder(Palabra, n)) %&gt;%\n    ggplot(aes(x = n, y = Palabra, fill = tipo)) +\n    geom_bar(stat = \"identity\", position = \"dodge\") +\n    labs(\n        title = \"Análisis de sentimientos\",\n        subtitle = \"Dataset Afinn\",\n        x = \"\", y = \"\",\n        fill = \"Tipo de emoción\"\n    ) +\n    theme_classic() +\n    theme(legend.position = \"bottom\")\n\nWarning in inner_join(dias, afinn, by = \"Palabra\"): Each row in `x` is expected to match at most 1 row in `y`.\nℹ Row 49 of `x` matches multiple rows.\nℹ If multiple matches are expected, set `multiple = \"all\"` to silence this\n  warning.\n\n\n\n\n\n\n\n\n\nAhora, vamos a utilizar el paquete syuzhet. Ojo, esta función tarda un rato en correr.\nNos va a devolver un data frame con los resultados por palabra en 8 categorías diferentes: - anger - anticipation - disgust - fear - joy - sadness - surprise - trust\n\ndias_nrc &lt;- get_nrc_sentiment(char_v = dias$Palabra, language = \"spanish\")\ndias_final &lt;- bind_cols(dias, dias_nrc)\n\nPosteriormente, hay que unir este data frame por emociones con nuestro data frame original. Le hice una transformación con tidyr para poder gráficar, y así debe de quedar:\n\ndias_final %&gt;%\n    pivot_longer(\n        cols = 3:12\n    ) %&gt;%\n    group_by(name) %&gt;%\n    summarise(total = sum(value)) %&gt;%\n    ungroup() %&gt;%\n    mutate(name = reorder(name, total)) %&gt;%\n    ggplot(aes(x = name, y = total, fill = name)) +\n    geom_bar(stat = \"identity\") +\n    scale_fill_manual(\n        breaks = c(\"disgust\", \"surprise\", \"anger\", \"joy\", \"anticipation\", \"fear\", \"sadness\", \"trust\", \"positive\", \"negative\"),\n        values = c(\"#24D204\", \"#06CBBE\", \"#CB0606\", \"#FBFE00\", \"#FF9200\", \"#46BF5F\", \"#5479C3\", \"#01FF4C\", \"#FF00DC\", \"#000000\")\n    ) +\n    theme_classic() +\n    labs(\n        title = \"Análisis de sentimientos en todo el libro\",\n        subtitle = \"Syuzhet\",\n        x = \"\", y = \"\"\n    ) +\n    theme(legend.position = \"blank\")\n\n\n\n\n\n\n\n\nClaramente syuzhet es superior a afinn. Pero requiere mucho más tiempo de procesamiento, y por lo tanto si te equivocas vas a darte de topes, pero creo que lo vale.\nRecapitulemos un poco: afinn clasifica las palabras y nosotros le asignamos una intención positica o negativa en función de su signo distinto a cero. Mientras que syuzhet te devuelve un data frame con 10 categorías, ya que una sola palabra puede tener multiples intenciones. Además, te indica si la intención de esta es positiva o negativa.\nLeí en la documentación, que hay diversas metodologías para realizar el procesamiento de texto. Pero eso es material para otro post. Ahora quiero aprovechar esta claificación para revisar los sentimientos por capitulo :D\n\nplot_chapter_all &lt;- dias_final %&gt;%\n    pivot_longer(\n        cols = 3:12\n    ) %&gt;%\n    filter(name != \"positive\" & name != \"negative\") %&gt;%\n    group_by(capitulo, name) %&gt;%\n    summarise(value = sum(value)) %&gt;%\n    mutate(\n        total = sum(value),\n        porcentaje = round((value * 100) / total, 2)\n    ) %&gt;%\n    ungroup() %&gt;%\n    ggplot(aes(x = name, y = porcentaje, fill = name)) +\n    geom_bar(stat = \"identity\") +\n    scale_fill_manual(\n        breaks = c(\"disgust\", \"surprise\", \"anger\", \"joy\", \"anticipation\", \"fear\", \"sadness\", \"trust\"),\n        values = c(\"#24D204\", \"#06CBBE\", \"#CB0606\", \"#FBFE00\", \"#FF9200\", \"#46BF5F\", \"#5479C3\", \"#01FF4C\")\n    ) +\n    coord_flip() +\n    theme_classic() +\n    theme(\n        legend.position = \"blank\",\n        axis.text.x = element_blank()\n    ) +\n    facet_grid(cols = vars(capitulo)) +\n    labs(\n        title = \"Proporción de sentimientos\",\n        subtitle = \"Por capítulo\",\n        x = \"\", y = \"\"\n    )\n\n`summarise()` has grouped output by 'capitulo'. You can override using the\n`.groups` argument.\n\nggplotly(plot_chapter_all) %&gt;%\n    layout(showlegend = F)\n\n\n\n\n\nAún tengo problemas con plotly, pero con esto ustedes pueden ver el porcentaje de los sentimientos por capítulos. Este cálculo es la suma de todas las observaciones por capítulo. Es decir, si hay 10 puntos de ira, y en el capitulo hay 100 puntos, esto implica que el 10% de texto del capítulo tiene la emoción del enojo (ira).\nAhora, solo veamos las emociones negativas y positivas por capítulo.\n\nplot_chapter &lt;- dias_final %&gt;%\n    select(-c(3:10)) %&gt;%\n    pivot_longer(\n        cols = 3:4\n    ) %&gt;%\n    group_by(capitulo, name) %&gt;%\n    summarise(value = sum(value)) %&gt;%\n    mutate(\n        total = sum(value),\n        porcentaje = round((value * 100) / total, 2)\n    ) %&gt;%\n    ungroup() %&gt;%\n    ggplot(aes(x = name, y = porcentaje, fill = name)) +\n    geom_bar(stat = \"identity\") +\n    scale_fill_manual(\n        breaks = c(\"positive\", \"negative\"),\n        values = c(\"#FF00DC\", \"#000000\")\n    ) +\n    theme_classic() +\n    theme(\n        axis.text.x = element_blank(),\n        legend.position = \"bottom\"\n    ) +\n    facet_grid(cols = vars(capitulo)) +\n    labs(\n        title = \"Emociones positivas y negativas\",\n        x = \"\", y = \"\", fill = \"Emoción\"\n    )\n\n`summarise()` has grouped output by 'capitulo'. You can override using the\n`.groups` argument.\n\nggplotly(plot_chapter) %&gt;%\n    layout(showlegend = F)\n\n\n\n\n\nCon esto tenemos una aproximación más clara sobre lo que trata el libro, o mejor dicho, de lo que vamos a sentir. Sin embargo, no solo se trata de eso. Continuando con el texto de Julia Silge, podemos hacer una matriz tf-idf (Term Frequency - Inverse Document Frequency). Este análisis muestra la frecuencia de una palabra ajustada por su uso (una multiplicación). Afortunadamente,tidytext ya tiene una función para esto."
  },
  {
    "objectID": "posts/dias-sin-ti/index.html#matriz-tf-df",
    "href": "posts/dias-sin-ti/index.html#matriz-tf-df",
    "title": "‘Días sin ti’",
    "section": "",
    "text": "dias %&gt;%\n    group_by(capitulo) %&gt;%\n    count(Palabra, sort = T) %&gt;%\n    mutate(\n        total = sum(n)\n    ) %&gt;%\n    bind_tf_idf(Palabra, capitulo, n) %&gt;%\n    ungroup() %&gt;%\n    filter(tf_idf &gt; 0.015) %&gt;%\n    ggplot(aes(x = tf_idf, y = fct_reorder(Palabra, tf_idf), fill = Palabra)) +\n    geom_bar(stat = \"identity\") +\n    scale_x_continuous(labels = scales::percent) +\n    theme_classic() +\n    theme(legend.position = \"blank\") +\n    labs(\n        title = \"Matriz tf-idf\",\n        subtitle = \"Importancia relativa de las palabras\",\n        x = \"\", y = \"\"\n    )\n\n\n\n\n\n\n\n\nCon esto, es evidente que las palabras más utilizadas en un texto (usualmente conectores) no son tan importantes. La intuición es que la importancia de una palabra es inversamente proporcional a su frecuencia.Pero, algo que ya habíamos empezado a explorar en el primer post de esta serie es entender que a veces una palabra no tiene significado por sí misma, sino que su significado lo obtiene en función de las otras palabras a su alrededor. ¡Vamos a regresar con los n-gramas!\n\nbigramas &lt;- dias_pdf %&gt;%\n    unnest_tokens(bigrama, value, token = \"ngrams\", n = 2) %&gt;%\n    separate(bigrama, c(\"palabra1\", \"palabra2\"), sep = \" \") %&gt;%\n    filter(!palabra1 %in% stopwords(\"es\")) %&gt;%\n    filter(!palabra2 %in% stopwords(\"es\"))\n\nbigramas %&gt;%\n    count(palabra1, palabra2, sort = T)\n\n# A tibble: 7,671 × 3\n   palabra1 palabra2      n\n   &lt;chr&gt;    &lt;chr&gt;     &lt;int&gt;\n 1 primera  vez          27\n 2 cada     vez          14\n 3 di       cuenta       13\n 4 mismo    tiempo       11\n 5 voz      alta         10\n 6 siento   orgulloso     9\n 7 todas    partes        9\n 8 cada     día           8\n 9 primer   día           8\n10 santa    clara         8\n# ℹ 7,661 more rows\n\n\nCon los n-gramas también se puede hacer la matriz tf-idf\n\nbigramas %&gt;%\n    unite(bigrama, palabra1, palabra2, sep = \" \") %&gt;%\n    count(capitulo, bigrama, sort = T) %&gt;%\n    bind_tf_idf(bigrama, capitulo, n) %&gt;%\n    arrange(desc(tf_idf))\n\n# A tibble: 8,196 × 6\n   capitulo bigrama                n    tf   idf tf_idf\n      &lt;int&gt; &lt;chr&gt;              &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1        0 agujero inmenso        1 0.025  2.56 0.0641\n 2        0 alguien falta          1 0.025  2.56 0.0641\n 3        0 aquella felicidad      1 0.025  2.56 0.0641\n 4        0 arrebatado hoy         1 0.025  2.56 0.0641\n 5        0 ausencias elegidas     1 0.025  2.56 0.0641\n 6        0 cada persona           1 0.025  2.56 0.0641\n 7        0 celebre aquella        1 0.025  2.56 0.0641\n 8        0 consiguen llenarlo     1 0.025  2.56 0.0641\n 9        0 damos cuenta           1 0.025  2.56 0.0641\n10        0 debemos forzar         1 0.025  2.56 0.0641\n# ℹ 8,186 more rows\n\n\n\n# dias_topic &lt;- dias %&gt;%\n#   count(capitulo, Palabra, sort = T)\n#\n# dias_dtm &lt;- dias_topic %&gt;%\n#   cast_dtm(capitulo, Palabra, n)\n#\n# topic &lt;- LDA(dias_dtm, k = 4, control = list(seed = 1234))\n\nY con esto, ya casi terminamos de revisar todo lo que se puede hacer con análisis de texto. El único tema faltante es topic modeling, pero, aún no lo entiendo bien. De verdad, lean Días sin ti, es una gran novela. Disfruté mucho hacer este post. Si quieren revisar temas de topic modeling denle clic al link de la Universidad de Valladolid.\n\nset.seed(123)\ndias %&gt;%\n    count(Palabra, sort = T) %&gt;%\n    wordcloud2()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Workshop",
    "section": "",
    "text": "Mini intro a Chainy (Shiny)\n\n\n\n\n\n\nspanish\n\n\ninteractive\n\n\nshiny\n\n\n\nEjemplo de visualizacion interactiva sobre solicitudes de informacion\n\n\n\n\n\nMar 3, 2024\n\n\nDavid Humberto Jiménez S.\n\n\n\n\n\n\n\n\n\n\n\n\n¿Agua pasa por mi casa?\n\n\n\n\n\n\ncode\n\n\ntext-analysis\n\n\nvisualization\n\n\nspanish\n\n\nR\n\n\nPython\n\n\n\nAnálisis de Solicitudes de Información Pública (SIP) relacionadas al tema de agua potable en la Ciudad de México\n\n\n\n\n\nFeb 3, 2024\n\n\nDavid Humberto Jiménez S.\n\n\n\n\n\n\n\n\n\n\n\n\nA un año de la Línea 12 con la API del INFO\n\n\n\n\n\n\ncode\n\n\nvisualization\n\n\npolitics\n\n\nspanish\n\n\n\nA un año del trágico accidente de la línea 12 del metro el equipo de Estado Abierto del INFO CDMX elaboró un reporte con información pública. En este post vamos a aprende a usar las API de datos abiertos (de CKAN) y analizar las solicitudes de información pública.\n\n\n\n\n\nSep 13, 2022\n\n\nDavid Humberto Jiménez S.\n\n\n\n\n\n\n\n\n\n\n\n\nScrap! o como extraer info de páginas\n\n\n\n\n\n\ncode\n\n\nvisualization\n\n\npolitics\n\n\nanalysis\n\n\nmexican elections\n\n\nspanish\n\n\n\nNo quieres copiar y pegar páginas donde están los datos y luego pasar horas limpiandolos en excel? Copia y pega este script para automatizar aunque sea un poco el proceso\n\n\n\n\n\nNov 1, 2021\n\n\nDavid Humberto Jiménez S.\n\n\n\n\n\n\n\n\n\n\n\n\nElecciones 2021 - Diputaciones Federales\n\n\n\n\n\n\ncode\n\n\nvisualization\n\n\npolitics\n\n\nspanish\n\n\n\nEl próximo año hay elecciones federales (intermedias). ¿Qué significa esto?\n\n\n\n\n\nDec 22, 2020\n\n\nDavid Humberto Jiménez S.\n\n\n\n\n\n\n\n\n\n\n\n\n‘Días sin ti’\n\n\n\n\n\n\ncode\n\n\ntext-analysis\n\n\nvisualization\n\n\nspanish\n\n\nnovel\n\n\n\nAnálisis de sentimientos de la novela ‘Días sin ti’ de Elvira Sastre\n\n\n\n\n\nDec 9, 2020\n\n\nDavid Humberto Jiménez S.\n\n\n\n\n\n\n\n\n\n\n\n\nAnálisis de texto: sentimientos\n\n\n\n\n\n\ncode\n\n\ntext-analysis\n\n\nvisualization\n\n\nspanish\n\n\n\nPrimer acercamiento al análisis de sentimientos/emociones en textos \n\n\n\n\n\nNov 14, 2020\n\n\n\n\n\n\n\n\n\n\n\n\nA 3 años del sismo en la CDMX\n\n\n\n\n\n\ncode\n\n\ntext-analysis\n\n\nvisualization\n\n\npublic-information\n\n\nspanish\n\n\n\nBreve análisis de las solicitudes de información pública relacionadas con el sismo del 19S de 2017\n\n\n\n\n\nSep 24, 2020\n\n\n\n\n\n\n\n\n\n\n\n\nIntro a Tidyverse\n\n\n\n\n\n\ntutorial\n\n\ncode\n\n\nanalysis\n\n\nvisualization\n\n\n\nMini tutorial a la library más útil de R\n\n\n\n\n\nApr 18, 2020\n\n\nDavid Humberto Jiménez S.\n\n\n\n\n\n\n\n\n\n\n\n\nInterrupción Legal del Embarazo en la Ciudad de México\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\nvisualization\n\n\npro-choice\n\n\n\nMini tutorial de como utilizar datos cargados en un google drive en formato csv\n\n\n\n\n\nApr 18, 2018\n\n\nDavid Humberto Jiménez S.\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "This blog is more than just a collection of posts – it’s my data science portfolio, intended to showcase my projects, skills, and experiences. I believe in making the complex world of data science accessible, and here, I’ll be sharing insights, tricks, and real-world applications.\nI’m a driven and accomplished professional with a passion for data-driven insights and decision-making. Demonstrated expertise in utilizing advanced data analysis and visualization techniques across diverse roles, resulting in actionable insights and informed strategies. Proven track record of conducting in-depth statistical analysis, evaluating transparency obligations, and pioneering innovative data solutions to optimize operational efficiency. Deeply curious about the intersection of the digital world and its political implications. Proficient in R, Python, and GitHub, dedicated to research, teaching, and lifelong learning. Fluent in both Spanish and English, with a knack for thriving in dynamic, collaborative environments\n\n\nInternational University of La Rioja in Mexico (UNIR), Online - Master’s Degree in Big Data Analysis and Visualization\nMAY 2022 - SEPTEMBER 2023\nAutonomous Technological Institute of Mexico (ITAM), Mexico - Bachelor of Arts in Political Science AUGUST 2012 - DECEMBER 2018\n\n\n\nINFO CDMX, México\nHead of Open Government Unit\n\nMAY 2022 - FEB 2024\n\nConduct statistical analysis of surveys, studies, and reports from the Directorate of Open State, Studies, and Evaluation.\nMonitor Open Data projects.\n\n\nProject Lead “B”\n\nFEB 2020 - MAY 2022\n\nEvaluate transparency obligations of public institutions in Mexico City.\nOffer data solutions and tools to enhance daily operations of the open government direction, studies, and evaluation.\n\n\nCívica Digital, México - Data Associate\n\nMAY 2019 - AUG 2019\n\nReview Open Data sets for the Government of Chile and the Open Data Charter.\nData entry for training the chatbot’s Artificial Intelligence.\n\n\nUndersecretariat of Communications (SCT), México - Technology Advisor\n\nSEP 2015 - MAY 2019\n\nMonitor the “Mexico Conectado” project for reports and public information requests.\nManage correspondence for the Institutional Liaison Office.\n\n\n\n\n\nNational Electoral Institute (INE) - District 15 Electoral Councilor for the Federal Electoral Process 2023–2024.\n\nDEC 2023 - JUNE 2024\n\nCívica Digital - Data Analysis, Visualization, and Calculation of Care Indicators for the Gender Indicators System of Mexico City.\n\nSEP - OCT 2023\n\nInstitute of Legal Research (IIJ) - Associate Researcher for the project Electoral Analysis 2021.\n\nMAY - DEC 2021\n\nCívica Digital - Data Analysis and Visualization Consulting for the Institute for Women in Migration, A.C.\n\nDECEMBER 2020\n\nAutonomous University of Coahuila, Public Security Diploma - Instructor of Governance and Data Management Policies, Module.\n\nNOVEMBER 2020\n\nInstitute of Leadership Simone de Beauvoir - Data Analysis and Visualization Consulting for Policy Classification.\n\nMAY 2019\n\nInstitute of Legal Research (IIJ) - Associate Researcher for the Project Chronicle of Federal Elections 2018.\nJAN - SEP 2018\nAlonso Lujambio Study Center (CEAL) -\n\nGeneral Coordinator\n\nJAN - DEC 2018\n\nTransparency Coordinator\n\nJAN - DEC 2017\n\n\n\n\n\n\nMaster’s Graduation by Grade Point Average - 2023\nFinalist team member, Medchain, in Coding4Integrity Hackathon - 2023.\nHonors mention for B.A. thesis - 2021\n\n\n\n\n\nB.A. Thesis: Electoral Accountability Through Municipal Public Assets in Mexico: 1994 - 2015 - Advisor: Adrián Lucardi. ITAM. 2021\n“Internet, Gobierno y Sociedad en México” - in Buen Gobierno, México, No. 22, Enero-junio 2017."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About me",
    "section": "",
    "text": "International University of La Rioja in Mexico (UNIR), Online - Master’s Degree in Big Data Analysis and Visualization\nMAY 2022 - SEPTEMBER 2023\nAutonomous Technological Institute of Mexico (ITAM), Mexico - Bachelor of Arts in Political Science AUGUST 2012 - DECEMBER 2018"
  },
  {
    "objectID": "about.html#professional-experience",
    "href": "about.html#professional-experience",
    "title": "About me",
    "section": "",
    "text": "INFO CDMX, México\nHead of Open Government Unit\n\nMAY 2022 - FEB 2024\n\nConduct statistical analysis of surveys, studies, and reports from the Directorate of Open State, Studies, and Evaluation.\nMonitor Open Data projects.\n\n\nProject Lead “B”\n\nFEB 2020 - MAY 2022\n\nEvaluate transparency obligations of public institutions in Mexico City.\nOffer data solutions and tools to enhance daily operations of the open government direction, studies, and evaluation.\n\n\nCívica Digital, México - Data Associate\n\nMAY 2019 - AUG 2019\n\nReview Open Data sets for the Government of Chile and the Open Data Charter.\nData entry for training the chatbot’s Artificial Intelligence.\n\n\nUndersecretariat of Communications (SCT), México - Technology Advisor\n\nSEP 2015 - MAY 2019\n\nMonitor the “Mexico Conectado” project for reports and public information requests.\nManage correspondence for the Institutional Liaison Office."
  },
  {
    "objectID": "about.html#consulting-and-external-projects",
    "href": "about.html#consulting-and-external-projects",
    "title": "About me",
    "section": "",
    "text": "National Electoral Institute (INE) - District 15 Electoral Councilor for the Federal Electoral Process 2023–2024.\n\nDEC 2023 - JUNE 2024\n\nCívica Digital - Data Analysis, Visualization, and Calculation of Care Indicators for the Gender Indicators System of Mexico City.\n\nSEP - OCT 2023\n\nInstitute of Legal Research (IIJ) - Associate Researcher for the project Electoral Analysis 2021.\n\nMAY - DEC 2021\n\nCívica Digital - Data Analysis and Visualization Consulting for the Institute for Women in Migration, A.C.\n\nDECEMBER 2020\n\nAutonomous University of Coahuila, Public Security Diploma - Instructor of Governance and Data Management Policies, Module.\n\nNOVEMBER 2020\n\nInstitute of Leadership Simone de Beauvoir - Data Analysis and Visualization Consulting for Policy Classification.\n\nMAY 2019\n\nInstitute of Legal Research (IIJ) - Associate Researcher for the Project Chronicle of Federal Elections 2018.\nJAN - SEP 2018\nAlonso Lujambio Study Center (CEAL) -\n\nGeneral Coordinator\n\nJAN - DEC 2018\n\nTransparency Coordinator\n\nJAN - DEC 2017"
  },
  {
    "objectID": "about.html#distinctions",
    "href": "about.html#distinctions",
    "title": "About me",
    "section": "",
    "text": "Master’s Graduation by Grade Point Average - 2023\nFinalist team member, Medchain, in Coding4Integrity Hackathon - 2023.\nHonors mention for B.A. thesis - 2021"
  },
  {
    "objectID": "about.html#publications",
    "href": "about.html#publications",
    "title": "About me",
    "section": "",
    "text": "B.A. Thesis: Electoral Accountability Through Municipal Public Assets in Mexico: 1994 - 2015 - Advisor: Adrián Lucardi. ITAM. 2021\n“Internet, Gobierno y Sociedad en México” - in Buen Gobierno, México, No. 22, Enero-junio 2017."
  },
  {
    "objectID": "posts/agua-pasa-por-mi-casa/index.html",
    "href": "posts/agua-pasa-por-mi-casa/index.html",
    "title": "¿Agua pasa por mi casa?",
    "section": "",
    "text": "“Un mago nunca llega tarde, Frodo Bolsón. Ni pronto. Llega exactamente cuando se lo propone.” Gandalf\n¡Bienvenidxs! Sé que he tenido abandonado este proyecto durante algún tiempo. Pero, la verdad sea dicha, he tenido mucho trabajo.\nEste es el primer post de la nueva iteración del blog (la tercera) y ahora está montado sobre Quarto. ¿Que qué es quarto? Quarto es un sistema de código abierto (Open source) para la publicación técnica/científica. Esto quiere decir que un montón de personas brillantes estaban hartas de lidiar con varias herramientas al mismo tiempo para trabajar y poder publicar sus artículos, páginas, libros y blogs. La principal ventaja, para mí, es que puedes trabajar con python, R, Julia y Observable JS; dentro del mismo documento. Aunque nunca he utilizado Julia.\nAdemás, los documentos utilizan la misma estructura que un markdown lo que nos facilita la vida, ya que no hay que aprender sintaxis nueva. En fin, tal vez es la emoción hablando, así que vayan, revísenlo y si les convence úsenlo. Toda la información aquí."
  },
  {
    "objectID": "posts/agua-pasa-por-mi-casa/index.html#selección-de-sip",
    "href": "posts/agua-pasa-por-mi-casa/index.html#selección-de-sip",
    "title": "¿Agua pasa por mi casa?",
    "section": "Selección de SIP",
    "text": "Selección de SIP\nSe emplearon las siguientes palabras: “agua” (exacta); que empezará con “Hidri” o “hidrí” (por ejemplo, hídrico); “sequía” o “sequía”; “inundaciones”, “pozos” o “posos”; la combinación de las palabras “captador” y “lluvia” o “pluvial”; así como la combinación de “saneamiento”, “fuga”, “corte” y todas las anteriores. Al tratarse de una selección automatizada, existe la posibilidad de encontrar resoluciones o solicitudes que no pertenezcan a la temática planteada y contengan una o varias de las palabras listadas.\n\nlibrary(httr)\nlibrary(purrr)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(readxl)\nlibrary(stringr)\nlibrary(janitor)\nlibrary(writexl)\nlibrary(tidytext)\nlibrary(lubridate)\n\n# Datos -------------------------------------------------------------------\n\nurl &lt;- c(\n    \"https://datosabiertos.infocdmx.org.mx/dataset/6dda3a6f-4e2a-484c-9613-89899058f70d/resource/9c683caf-f559-462c-8e70-845c8902d7b4/download/_limpia_2022.xlsx\",\n    \"https://datosabiertos.infocdmx.org.mx/dataset/2e770767-dfe5-4ba2-9af3-61338cc6509b/resource/43f4549c-9cba-4737-b86b-f2ee4924ddf8/download/limpia_2021.xlsx\",\n    \"https://datosabiertos.infocdmx.org.mx/dataset/f8a7fab6-8466-4e1c-b3fb-b0d29afd2f83/resource/2a29d720-32bc-4268-90da-3b374aaa4379/download/limpia_2020.xlsx\",\n    \"https://datosabiertos.infocdmx.org.mx/dataset/f92cb601-9b13-4e58-9556-9810c5347e2b/resource/d7019dab-918c-41e9-ad6d-9fb9838c5021/download/limpia_2019.xlsx\",\n    \"https://datosabiertos.infocdmx.org.mx/dataset/29faea7e-4d34-4f5d-bdd4-50b61ace1f32/resource/074b6c4e-89fd-4119-a43a-69b1e007e1b3/download/limpia_2018.xlsx\",\n    \"https://datosabiertos.infocdmx.org.mx/dataset/e42ccdad-f383-485b-802f-9aba520df083/resource/e8b2d6d6-c4cf-4a49-ac2b-512ab3597283/download/limpia_2017.xlsx\",\n    \"https://datosabiertos.infocdmx.org.mx/dataset/017c49f8-39f7-4942-9408-728046586bc8/resource/5c68a7a5-be2d-4a4f-ad04-ff04a9ed2889/download/limpia_2016.xlsx\",\n    \"https://datosabiertos.infocdmx.org.mx/dataset/bdadb1ab-e476-4c47-95fb-4a2d4af9e2de/resource/540d06f9-b9a2-4f56-b23d-1e84e2ed85a2/download/limpia_2015.xlsx\",\n    \"https://datosabiertos.infocdmx.org.mx/dataset/e905654e-6a6a-4d0d-912f-17b5270aabf2/resource/d68925b2-fcd3-4676-b2c5-d73c3ac69d9a/download/limpia_2014.xlsx\",\n    \"https://datosabiertos.infocdmx.org.mx/dataset/69b31de6-3a7b-4892-ac2e-79c7043616b4/resource/52c81f47-214b-4888-9869-0b17b781ebb9/download/limpia_2013.xlsx\",\n    \"https://datosabiertos.infocdmx.org.mx/dataset/850fb128-2643-40b5-bbb4-f7a378494f90/resource/2bef2739-b570-4c80-afb2-e8ccb59e8f2c/download/limpia_2012.xlsx\",\n    \"https://datosabiertos.infocdmx.org.mx/dataset/f4842322-3068-475f-b8c0-9a65b0a011e6/resource/de055dd6-2eb2-4d75-adb9-2041b47fdb4e/download/limpia_2011.xlsx\",\n    \"https://datosabiertos.infocdmx.org.mx/dataset/7bdd86c0-93b9-4dd6-be66-a39ec814be1c/resource/5043bd4d-07bf-40db-a9df-8f2755aa36bc/download/limpia_2010.xlsx\",\n    \"https://datosabiertos.infocdmx.org.mx/dataset/4ef8d70d-21c9-427b-95c2-8c006f4fec16/resource/132a3785-c718-4122-96df-031437d2f289/download/limpia_2009.xlsx\",\n    \"https://datosabiertos.infocdmx.org.mx/dataset/1422cec6-f8e9-4715-bc49-ea66afff640a/resource/a27a3b30-b727-4650-896d-1258729e13ba/download/limpia_2008.xlsx\",\n    \"https://datosabiertos.infocdmx.org.mx/dataset/bad94346-71e9-438d-b026-689d228e2d33/resource/2eb8f23e-a098-4746-80ce-e52562bd1f11/download/limpia_2007.xlsx\",\n    \"https://datosabiertos.infocdmx.org.mx/dataset/17b24af2-4950-4476-91a1-d934fd4d7c68/resource/e0d70ebb-7c16-46c7-8865-c537df8ff637/download/limpia_2006.xlsx\"\n)\n\ntemp_files &lt;- map(url, ~ {\n    temp_file &lt;- tempfile()\n    GET(.x, write_disk(temp_file))\n    temp_file\n})\n\nlista &lt;- map(temp_files, ~ {\n    read_excel(.x) %&gt;%\n        clean_names() %&gt;%\n        mutate_all(as.character)\n})\n\nlista &lt;- bind_rows(lista)\nmap(temp_files, unlink)\n\n[[1]]\n[1] 0\n\n[[2]]\n[1] 0\n\n[[3]]\n[1] 0\n\n[[4]]\n[1] 0\n\n[[5]]\n[1] 0\n\n[[6]]\n[1] 0\n\n[[7]]\n[1] 0\n\n[[8]]\n[1] 0\n\n[[9]]\n[1] 0\n\n[[10]]\n[1] 0\n\n[[11]]\n[1] 0\n\n[[12]]\n[1] 0\n\n[[13]]\n[1] 0\n\n[[14]]\n[1] 0\n\n[[15]]\n[1] 0\n\n[[16]]\n[1] 0\n\n[[17]]\n[1] 0\n\n# Filtro ------------------------------------------------------------------\n\nfiltro &lt;- lista %&gt;%\n    mutate(\n        awa = ifelse(str_detect(\n            descripcion_solicitud,\n            regex(\"\\\\bagua\\\\b\", ignore_case = T)\n        ), 1, 0),\n        fug = ifelse(str_detect(\n            descripcion_solicitud,\n            regex(\"fuga\", ignore_case = T)\n        ), 1, 0),\n        corte = ifelse(str_detect(\n            descripcion_solicitud,\n            regex(\"\\\\bcorte|\\\\bcorta\", ignore_case = T)\n        ), 1, 0),\n        esc = ifelse(str_detect(\n            descripcion_solicitud,\n            regex(\"\\\\besca\", ignore_case = T)\n        ), 1, 0),\n        h = ifelse(str_detect(\n            descripcion_solicitud,\n            regex(\"hidrí|hidri\", ignore_case = T)\n        ), 1, 0),\n        f1 = ifelse(str_detect(\n            descripcion_solicitud,\n            regex(\"sequía|sequia\", ignore_case = T)\n        ), 1, 0),\n        f2 = ifelse(str_detect(\n            descripcion_solicitud,\n            regex(\"inundaciones\", ignore_case = T)\n        ), 1, 0),\n        f3 = ifelse(str_detect(\n            descripcion_solicitud,\n            regex(\"saneamiento\", ignore_case = T)\n        ), 1, 0),\n        f4 = ifelse(str_detect(\n            descripcion_solicitud,\n            regex(\"pozos|posos\", ignore_case = T)\n        ), 1, 0),\n        f5 = ifelse(str_detect(\n            descripcion_solicitud,\n            regex(\"captador\", ignore_case = T)\n        ), 1, 0),\n        f6 = ifelse(str_detect(\n            descripcion_solicitud,\n            regex(\"humedal\", ignore_case = T)\n        ), 1, 0),\n        f7 = ifelse(str_detect(\n            descripcion_solicitud,\n            regex(\"pluvial|lluvia\", ignore_case = T)\n        ), 1, 0)\n    ) %&gt;%\n    mutate(f7 = ifelse(f5 == 1 & f7 == 1, 1, 0)) %&gt;%\n    rowwise() %&gt;%\n    mutate(\n        f3 = ifelse(f3 == 1, sum(awa, fug, corte, esc, h, f1, f2, f3, f4, f5, f6, f7), 0)\n    )\n\nver &lt;- filtro %&gt;%\n    filter(awa == 1 | h == 1 | f1 == 1 | f2 == 1 | f3 &gt; 1 | f4 == 1 | f7 == 1) %&gt;%\n    mutate(\n        organo_de_gobierno = case_when(\n            str_detect(dependencia, \"Alcal\") ~ \"Alcaldías\",\n            str_detect(dependencia, \"Dele\") ~ \"Alcaldías\",\n            str_detect(dependencia, \"Agua\") ~ \"Organismos desconcentrados, descentralizados, paraestatales y auxiliares\",\n            str_detect(dependencia, \"Ambiental y\") ~ \"Organismos desconcentrados, descentralizados, paraestatales y auxiliares\",\n            str_detect(dependencia, \"Medio A\") ~ \"Administración Pública Central\",\n            str_detect(dependencia, \"Obras\") ~ \"Administración Pública Central\",\n            str_detect(dependencia, \"Protección Civil\") ~ \"Administración Pública Central\",\n            str_detect(dependencia, \"Planeación\") ~ \"Organismos desconcentrados, descentralizados, paraestatales y auxiliares\",\n            str_detect(dependencia, \"Jefatura\") ~ \"Administración Pública Central\",\n            str_detect(dependencia, \"Secretaría de Desarrollo Urbano y Vivienda\") ~ \"Administración Pública Central\",\n            T ~ organo_de_gobierno\n        ),\n        organo_de_gobierno = str_replace_all(\n            organo_de_gobierno, \"Administración Pública Centralizada\",\n            \"Administración Pública Central\"\n        ),\n        organo_de_gobierno = str_remove_all(organo_de_gobierno, \"\\\\(baja 10-06-2019\\\\)\"),\n        organo_de_gobierno = str_trim(organo_de_gobierno, \"both\"),\n        organo_de_gobierno = str_replace_all(\n            organo_de_gobierno, \"Instituto para la Atención de los Adultos Mayores en el Distrito Federal \\\\(17/02/2010\\\\)\",\n            \"Organismos desconcentrados, descentralizados, paraestatales y auxiliares\"\n        ),\n        organo_de_gobierno = str_replace_all(\n            organo_de_gobierno, \"Desconcentrados, Descentralizados, Paraestatales y Auxiliares\",\n            \"Organismos desconcentrados, descentralizados, paraestatales y auxiliares\"\n        ),\n        organo_de_gobierno = str_replace_all(\n            organo_de_gobierno, \"Descentralizados\",\n            \"Organismos desconcentrados, descentralizados, paraestatales y auxiliares\"\n        ),\n        organo_de_gobierno = str_replace_all(\n            organo_de_gobierno, \"Fondos y fideicomisos públicos\",\n            \"Fideicomisos y fondos públicos\"\n        ),\n        organo_de_gobierno = str_replace_all(\n            organo_de_gobierno, \"Organismos Autónomos\",\n            \"Órganos Autónomos\"\n        ),\n        organo_de_gobierno = str_replace_all(\n            organo_de_gobierno, \"Órgano Autónomo\",\n            \"Órganos Autónomos\"\n        ),\n        organo_de_gobierno = str_replace_all(\n            organo_de_gobierno, \"Órgano Autónomo\",\n            \"Órganos Autónomos\"\n        ),\n        organo_de_gobierno = str_replace_all(\n            organo_de_gobierno, \"Tribunales Administrativos\",\n            \"Órganos Autónomos\"\n        ),\n        organo_de_gobierno = str_replace_all(\n            organo_de_gobierno, \"Órgano político administrativos\",\n            \"Organismos desconcentrados, descentralizados, paraestatales y auxiliares\"\n        ),\n        organo_de_gobierno = str_replace_all(\n            organo_de_gobierno, \"\\\\bÓrgano\\\\b\",\n            \"Poder\"\n        ),\n        organo_de_gobierno = str_remove_all(organo_de_gobierno, \"en el Distrito Federal\"),\n        organo_de_gobierno = str_trim(organo_de_gobierno, \"both\"),\n        organo_de_gobierno = str_replace_all(\n            organo_de_gobierno, \"Entidades Paramunicipales\",\n            \"Organismos desconcentrados, descentralizados, paraestatales y auxiliares\"\n        )\n    ) %&gt;%\n    filter(organo_de_gobierno != \"Sindicatos\") %&gt;%\n    select(-c(18:29))\n\nver &lt;- ver %&gt;%\n    unite(fecha_de_ingreso, fecha_de_ingreso, fecha_ingreso) %&gt;%\n    unite(otros_datos, otros_datos, otro_datos) %&gt;%\n    mutate(\n        otros_datos = str_remove_all(otros_datos, \"_NA\"),\n        otros_datos = str_remove_all(otros_datos, \"NA_\")\n    ) %&gt;%\n    mutate(\n        fecha_de_ingreso = str_remove_all(fecha_de_ingreso, \"_NA\"),\n        fecha_de_ingreso = str_remove_all(fecha_de_ingreso, \"NA_\"),\n        fecha_de_ingreso = as_datetime(fecha_de_ingreso)\n    ) %&gt;%\n    mutate(\n        dependencia = str_remove_all(dependencia, \"Alcaldía \"),\n        dependencia = str_remove_all(dependencia, \"Delegación \"),\n        dependencia = str_remove_all(dependencia, \"[.]$\"),\n        dependencia = str_remove_all(dependencia, \"de la Ciudad de México\"),\n        dependencia = str_remove_all(dependencia, \"del Distrito Federal\"),\n        dependencia = str_trim(dependencia, \"both\"),\n        dependencia = str_replace_all(dependencia, \"Gustavo A Madero\", \"Gustavo A. Madero\")\n    ) %&gt;%\n    mutate(\n        dependencia = str_trim(dependencia, \"both\")\n    ) %&gt;%\n    arrange(desc(fecha_de_ingreso)) %&gt;%\n    group_by(as.character(folio)) %&gt;%\n    slice(1) %&gt;%\n    ungroup() %&gt;%\n    select(-16)\n# write_xlsx(ver, \"SIP_agua.xlsx\")\n\nLos datos de la APi tienen 14 variables:\n\nfolio: Identificador único de la solicitud.\nfecha_de_ingreso: Fecha y hora en la que se ingresó la solicitud.\ndependencia: nombre de la institución pública a la que se realizó la solicitud\norgano_de_gobierno: ámbito al que pertenece la dependencia (alcaldías, administración pública central, fondos y fideicomisos, etc.).\ndescripcion_solicitud: texto de la solicitud realizada por la persona solicitante.\nestatus: Estado actual de la solicitud (pendiente, desechada, en proceso, terminada, etc.).\nmedio_entrada: Medio por el cual se ingresó la solicitud (telefónico, presentada en la Unidad de Transparencia, por medio electrónicos, etc.)\notros_datos: Otros datos relevantes de la solicitud registrados por la persona solicitante, mismos que no son obligatorios.\nfecha_limite_de_respuesta: Fecha límite para la respuesta de la solicitud en función de la fecha de ingreso y alguno de los siguientes supuestos: si se determina competencia (3 días), prevención (10 días después de la notificación), si ya se encuentra publicada al ser una obligación de transparencia (5 días) o bien 9 días una vez aceptada la solicitud.\nrespuesta: variable categórica con una clasificación del tipo de respuesta de la dependencia (entrega de información, prevenida, improcedente, registro de pago, etc.).\ntexto_de_la_respuesta: Texto de la respuesta a la solicitud no disponible en todas las SIP, ya que en muchos casos se remite al oficio de respuesta enviado a través del sistema INFOMEX o de la PNT.\npais: País de origen de la solicitud (en su mayoría México) y no obligatorio.\nestado: Estado de origen de la solicitud (en su mayoría Ciudad de México) y no obligatorio.\nfecha_respuesta: Fecha en la que la dependencia dio la respuesta a la solicitud."
  },
  {
    "objectID": "posts/agua-pasa-por-mi-casa/index.html#k---means",
    "href": "posts/agua-pasa-por-mi-casa/index.html#k---means",
    "title": "¿Agua pasa por mi casa?",
    "section": "K - means",
    "text": "K - means\nPara hacer un análisis más detallado, utilicé un algoritmo de clasificación no supervisada k-means con 6 clusters. De ahí tomé una muestra de 300 solicitudes, 50 por cada grupo. Con un análisis de palabras frecuentes y lectura de las SIP en la muestra, etiqueté y filtré manualmente (en caso de que hubiera solicitudes que no tuvieran relación con el tema, por ejemplo:solicitudes relacionadas con una calle llamada lluvia), hasta contar con un subconjunto de 273 SIP, mismo que se empleó para ejecutar un algoritmo de clasificación supervisada, en donde esta muestra funcionó como base de datos de entrenamiento, para etiquetar las 40,269 solicitudes.\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import adjusted_rand_score\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import silhouette_score\nimport nltk\nfrom nltk.corpus import stopwords\nimport openpyxl\nimport matplotlib.pyplot as plt\n\ndf = pd.read_excel(\"D:/dhumb/Documents/projects/data_blog/agua/SIP_agua.xlsx\")\ndata = df\n\nvectorizer = TfidfVectorizer()\nX = vectorizer.fit_transform(data['descripcion_solicitud'])\n\n# Aplicar k-means\nkmeans = KMeans(n_clusters=6, random_state=0, n_init=10)\nclusters = kmeans.fit_predict(X)\n\n# Agregar los resultados al DataFrame\ndata['cluster'] = clusters"
  },
  {
    "objectID": "posts/agua-pasa-por-mi-casa/index.html#ensamble-learning",
    "href": "posts/agua-pasa-por-mi-casa/index.html#ensamble-learning",
    "title": "¿Agua pasa por mi casa?",
    "section": "Ensamble learning",
    "text": "Ensamble learning\nPara este último paso, la clasificación supervisada de textos, es necesario entrenar un modelo de aprendizaje automático con una muestra de datos ya etiquetados, con el objetivo de que el modelo aprenda a clasificar datos nuevos. Se aplicó un preprocesamiento de los textos para convertirlos en vectores numéricos, y se entrenó un modelo de ensamble que combina diferentes clasificadores (SVM, regresión logística y Naive Bayes) utilizando validación cruzada estratificada para encontrar los mejores hiperparámetros a través de GridSearchCV. Una vez que el modelo se entrenó, se usó para predecir las etiquetas de la descripción de las solicitudes.\n\n# | warning: false\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV, StratifiedKFold\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report\n\n# Cargar datos de muestra etiquetados\ndf_labeled = pd.read_excel(\n    \"D:/dhumb/Documents/projects/data_blog/agua/Muestra.xlsx\")\n\n# Separar datos de muestra en características y etiquetas\nX_train = df_labeled['descripcion_solicitud']\ny_train = df_labeled['label']\n\n# Vectorizar datos de muestra y conjunto de datos original\nvectorizer = TfidfVectorizer(max_features=4500)\nX_train_vectorized = vectorizer.fit_transform(X_train)\n\n# Definir modelos\nnb_model = MultinomialNB()\nsvm_model = SVC(probability=True)\nlr_model = LogisticRegression()\n\n# Definir ensamble de modelos con GridSearchCV\nestimators = [('nb', nb_model), ('svm', svm_model), ('lr', lr_model)]\nvoting_model = VotingClassifier(estimators=estimators, voting='soft')\n\n# Definir parámetros para GridSearchCV\nparams = {\n    'nb__alpha': [0.5, 1, 2],\n    'svm__C': [0.1, 1, 10],\n    'lr__C': [0.1, 1, 10]\n}\n\n# Definir validación cruzada estratificada con 5 particiones\ncv = StratifiedKFold(n_splits=5)\n\n# Ajustar ensamble de modelos utilizando GridSearchCV y validación cruzada estratificada\ngrid_search = GridSearchCV(voting_model, params, cv=cv)\ngrid_search.fit(X_train_vectorized, y_train)\n\nGridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n             estimator=VotingClassifier(estimators=[('nb', MultinomialNB()),\n                                                    ('svm',\n                                                     SVC(probability=True)),\n                                                    ('lr',\n                                                     LogisticRegression())],\n                                        voting='soft'),\n             param_grid={'lr__C': [0.1, 1, 10], 'nb__alpha': [0.5, 1, 2],\n                         'svm__C': [0.1, 1, 10]})In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.GridSearchCVGridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n             estimator=VotingClassifier(estimators=[('nb', MultinomialNB()),\n                                                    ('svm',\n                                                     SVC(probability=True)),\n                                                    ('lr',\n                                                     LogisticRegression())],\n                                        voting='soft'),\n             param_grid={'lr__C': [0.1, 1, 10], 'nb__alpha': [0.5, 1, 2],\n                         'svm__C': [0.1, 1, 10]})estimator: VotingClassifierVotingClassifier(estimators=[('nb', MultinomialNB()),\n                             ('svm', SVC(probability=True)),\n                             ('lr', LogisticRegression())],\n                 voting='soft')nbMultinomialNBMultinomialNB()svmSVCSVC(probability=True)lrLogisticRegressionLogisticRegression()\n\n# Imprimir mejores hiperparámetros encontrados por GridSearchCV\nprint(\"Mejores hiperparámetros encontrados por GridSearchCV:\")\n\nMejores hiperparámetros encontrados por GridSearchCV:\n\nprint(grid_search.best_params_)\n\n{'lr__C': 10, 'nb__alpha': 2, 'svm__C': 10}\n\n# Cargar datos del conjunto de datos original\ndf_unlabeled = pd.read_excel(\n    \"D:/dhumb/Documents/projects/data_blog/agua/SIP_agua.xlsx\")\n# Quitar los datos etiquetados de la muestra\ndf_unlabeled = df_unlabeled[~df_unlabeled['folio'].isin(df_labeled['folio'])]\n\n# Vectorizar datos del conjunto de datos original\nX_unlabeled = df_unlabeled['descripcion_solicitud']\nX_unlabeled_vectorized = vectorizer.transform(X_unlabeled)\n\n# Predecir etiquetas para el conjunto de datos original\ny_pred = grid_search.predict(X_unlabeled_vectorized)\n\n# Agregar etiquetas al conjunto de datos original\ndf_unlabeled['etiqueta'] = y_pred\n\n# Imprimir reporte de clasificación\nprint(classification_report(y_train, grid_search.predict(X_train_vectorized)))\n\n                                                      precision    recall  f1-score   support\n\n                                      Abastecimiento       1.00      1.00      1.00        26\nDiagnósticos, informes, reportes, opiniones técnicas       1.00      1.00      1.00        18\n                                   Impacto ambiental       1.00      1.00      1.00         5\n                             Infraestructura y obras       1.00      1.00      1.00        34\n                      Mantenimiento y rehabilitación       1.00      0.94      0.97        18\n                                    Pago de derechos       0.95      1.00      0.98        60\n                                Permisos y contratos       0.98      1.00      0.99        42\n                                               Pipas       1.00      1.00      1.00        62\n                                         Presupuesto       1.00      0.62      0.77         8\n\n                                            accuracy                           0.99       273\n                                           macro avg       0.99      0.95      0.97       273\n                                        weighted avg       0.99      0.99      0.98       273\n\n\n# Une los datos\ndf_labeled = df_labeled.rename(columns={'label': 'etiqueta'})\ndata = pd.concat([df_unlabeled, df_labeled])\n\ndata.to_excel(\n    'D:/dhumb/Documents/projects/data_blog/agua/ensamble_2.xlsx', index=False)\n\nEn total se definieron nueve categorías que se listan a continuación:\n\nAbastecimiento. Se refiere a la distribución de agua en la CDMX, extracción de esta y prestación del servicio.\nDiagnósticos, informes, reportes, opiniones técnicas. Sobre los estudios, diagnósticos o informes generados sobre el agua.\nImpacto ambiental. Los estudios de impacto ambiental solicitados por las personas.\nInfraestructura y obras. Se refiere a las solicitudes del mapa de distribución, ubicación de pozos, proyectos de obras hidráulicas.\nMantenimiento y rehabilitación. En esta categoría se encuentran los trabajos de rehabilitación, reparación de fugas y mantenimiento de la red hidráulica.\nPago de derechos. Se refiere a las tarifas, pago de las mismas o explicación de estas.\nPermisos y contratos. Estas solicitudes se refieren a los permisos otorgados a obras, por ejemplo departamentos o plazas comerciales.\nPipas. Se refiere a aquellas solicitudes donde se solicita información sobre las pipas de agua (horarios, costos, etc.).\nPresupuesto. En esta categoría se encuentran las solicitudes que preguntan por los presupuestos para el pago de agua (garrafones, botellas, tarifas, etc.)."
  },
  {
    "objectID": "posts/agua-pasa-por-mi-casa/index.html#visualizaciones",
    "href": "posts/agua-pasa-por-mi-casa/index.html#visualizaciones",
    "title": "¿Agua pasa por mi casa?",
    "section": "Visualizaciones",
    "text": "Visualizaciones\nY después de tirar código es moemnto de… tirar más código :D Pero esta vez para poder sacar conclusiones de los datos que ya se han trabajado. Estas gráficas son propuestas que están en el reporte ya mencionado, así como otras que no quedaron por falta de espacio y detalle para explicarlas.\n\nlibrary(tm)\nlibrary(scales)\nlibrary(viridis)\nlibrary(ggplot2)\nlibrary(ggrepel)\nlibrary(SnowballC)\n\n## Conteo ------------------------------------------------------------------\n\ndata &lt;- read_excel(\"D:/dhumb/Documents/projects/data_blog/agua/ensamble_2.xlsx\") %&gt;%\n    mutate(\n        folio = as.character(folio),\n        folio = paste0(\"0\", folio),\n        anio = year(fecha_de_ingreso),\n        dependencia = str_remove_all(dependencia, \"P - \"),\n        dependencia = str_remove_all(dependencia, \"\\\\(RTP\\\\)\"),\n        dependencia = str_remove_all(dependencia, \"\\\\(FONDECO\\\\)\"),\n        dependencia = str_remove_all(dependencia, \"\\\\(PGJDF\\\\)\"),\n        dependencia = str_remove_all(dependencia, \"\\\\(FIDERE III\\\\)\"),\n        dependencia = str_remove_all(dependencia, \"en el Distrito Federal\"),\n        dependencia = str_remove_all(dependencia, \"en la Ciudad de México\"),\n        dependencia = str_replace_all(dependencia, \"SA de CV\", \"S.A. de C.V\"),\n        dependencia = str_replace_all(dependencia, \"Generar\", \"General\"),\n        dependencia = str_replace_all(dependencia, \"DF\", \"D.F\"),\n        dependencia = str_replace_all(\n            dependencia, \"Corporación Mexicana de Impresión, S.A. de C.V\",\n            \"Corporación Mexicana de Impresión S.A. de C.V\"\n        ),\n        dependencia = str_replace_all(dependencia, \"Policia\", \"Policía\"),\n        dependencia = str_replace_all(dependencia, \"\\\\bEncuentro Social\\\\b\", \"Partido Encuentro Solidario\"),\n        dependencia = str_trim(dependencia, \"both\"),\n        organo_de_gobierno = str_replace_all(\n            organo_de_gobierno,\n            \"Organismos desconcentrados, descentralizados, paraestatales y auxiliares\",\n            \"Organismos desconcentrados,\\ndescentralizados, paraestatales\\ny auxiliares\"\n        ),\n        organo_de_gobierno = str_replace_all(\n            organo_de_gobierno,\n            \"Fideicomisos y fondos públicos\",\n            \"Fideicomisos y\\nfondos públicos\"\n        ),\n        etiqueta = str_replace_all(\n            etiqueta, \"Diagnósticos, informes, reportes, opiniones técnicas\",\n            \"Diagnósticos, informes, \\nreportes, opiniones técnicas\"\n        ),\n        estatus = str_to_sentence(estatus),\n        estatus = ifelse(estatus == \"Proceso\", \"En proceso\", estatus),\n        respuesta = str_remove_all(respuesta, \"\\\\bA[.]\"),\n        respuesta = str_remove_all(respuesta, \"\\\\bB[.]\"),\n        respuesta = str_remove_all(respuesta, \"\\\\bC[.]\"),\n        respuesta = str_remove_all(respuesta, \"\\\\bD[.]\"),\n        respuesta = str_remove_all(respuesta, \"\\\\bE[.]\"),\n        respuesta = str_remove_all(respuesta, \"\\\\bF[.]\"),\n        respuesta = str_remove_all(respuesta, \"\\\\bG[.]\"),\n        respuesta = str_remove_all(respuesta, \"\\\\bH[.]\"),\n        respuesta = str_replace_all(respuesta, \"\\\\bRR\\\\b\", \"Recurso de Revisión\"),\n        respuesta = str_trim(respuesta, \"both\"),\n        respuesta = str_replace_all(respuesta, \"à\", \"á\"),\n        respuesta = str_remove_all(respuesta, \"[.]$\"),\n        respuesta = case_when(\n            str_detect(respuesta, regex(\"entrega|información\", ignore_case = T)) ~ \"Entrega de información solicitada\",\n            T ~ respuesta\n        ),\n        respuesta = str_to_sentence(respuesta)\n    )\n\nEl código de arriba es solo un preprocesamiento/limpieza de la última base de datos.\n\ndata %&gt;%\n    group_by(dependencia) %&gt;%\n    count(sort = T) %&gt;%\n    ungroup() %&gt;%\n    filter(n &gt; 1000) %&gt;%\n    mutate(\n        dependencia = str_replace(\n            dependencia, \"Secretaría de Desarrollo Urbano y Vivienda\",\n            \"Secretaría de Desarrollo\\nUrbano y Vivienda\"\n        ),\n        dependencia = str_replace(\n            dependencia, \"Secretaría de Obras y Servicios\",\n            \"Secretaría de Obras\\ny Servicios\"\n        )\n    ) %&gt;%\n    ggplot(aes(x = reorder(dependencia, n), y = n, fill = \"pink\")) +\n    geom_bar(stat = \"identity\") +\n    geom_text(aes(label = comma(n), vjust = 0.5, hjust = 1),\n        position = position_dodge(0.9)\n    ) +\n    coord_flip() +\n    theme_bw() +\n    theme(\n        legend.position = \"none\"\n    ) +\n    labs(\n        title = \"Instituciones con más de 1,000 SIP\",\n        #     subtitle = \"\",\n        x = \"\", y = \"\"\n    )\n\n\n\n\n\n\n\n\nEra evidente que al tratarse de un tema sobre agua en la Ciudad de México, la institución con mayor número de solicitudes al respecto iba a ser el Sistema de Aguas (SACMEX pa lxs cuates). Sin embargo, también es interesante ver que hay 7 alcaldías (antes delegaciones).\n\naniomes &lt;- data %&gt;%\n    group_by(anio) %&gt;%\n    count() %&gt;%\n    ungroup()\n\nggplot(aniomes, aes(x = anio, y = n)) +\n    geom_point(size = 4) +\n    geom_line(linewidth = 1) +\n    geom_text(aes(label = comma(n), vjust = -.7),\n        position = position_dodge(1)\n    ) +\n    theme_bw() +\n    scale_x_continuous(breaks = seq(2006, 2022, by = 1)) +\n    labs(\n        title = \"Solicitudes por año\",\n        x = \"\", y = \"\"\n    )\n\n\n\n\n\n\n\n\nSi vemos el número de solicitudes a lo largo del tiempo, en 2017 se registró el mayor número de solicitudes. En la siguiente gráfica, interactiva, se puede observar la desagregación por mes de cada año. Esto porque creo que hay un efecto de estacionalidad: es decir, si bien un año puede ser particularmente seco, como este 2024, pudo haber meses en los que el desabasto fue mayor.\n\nxmes &lt;- data %&gt;%\n    mutate(mes = month(fecha_de_ingreso)) %&gt;%\n    group_by(anio, mes) %&gt;%\n    count() %&gt;%\n    ungroup() %&gt;%\n    mutate(\n        grupo = as.Date(paste(anio, mes, \"01\", sep = \"-\"))\n    ) %&gt;%\n    ggplot(aes(x = grupo, y = n)) +\n    geom_line() +\n    geom_point() +\n    scale_x_date(NULL,\n        breaks = breaks_width(\"1 year\"),\n        labels = label_date(\"%Y\")\n    ) +\n    scale_y_continuous(breaks = seq(0, 1500, by = 100)) +\n    theme_bw() +\n    theme(\n        axis.text.x = element_text(angle = 45, hjust = 0.9)\n    ) +\n    labs(\n        title = \"SIP por mes y año\",\n        x = \"\", y = \"\"\n    )\n\nplotly::ggplotly(xmes)\n\n\n\n\n\nDe las nueve categorías la que tuvo mayor número de solicitudes fue la de “pago de derechos”, seguida de “permisos y contratos” y “abastecimiento”. Las cifras varían con las del reporte porque se clasificó sin filtrar las solicitudes de la muestra.\n\nggplot(data, aes(x = forcats::fct_infreq(as.factor(etiqueta)))) +\n    geom_bar(aes(fill = organo_de_gobierno)) +\n    geom_text(aes(label = comma(after_stat(count))),\n        stat = \"count\",\n        vjust = 0.5, hjust = 1,\n        position = position_dodge(0.9)\n    ) +\n    theme_bw() +\n    theme(\n        legend.position = \"bottom\"\n    ) +\n    coord_flip() +\n    labs(\n        x = \"\", y = \"\",\n        fill = \"\",\n        title = \"Ámbito y grupos\"\n    )\n\n\n\n\n\n\n\n\n\nd1 &lt;- data %&gt;%\n    mutate(\n        estatus = case_when(\n            str_detect(estatus, regex(\"desechada\", ignore_case = T)) ~ \"Desechada\",\n            T ~ estatus\n        ),\n        estatus = case_when(\n            str_detect(estatus, regex(\"proceso|pendiente|espera\", ignore_case = T)) ~ \"En proceso\",\n            T ~ estatus\n        )\n    )\n\nggplot(d1, aes(x = forcats::fct_infreq(etiqueta))) +\n    geom_bar(aes(fill = estatus)) +\n    geom_text(aes(label = comma(after_stat(count))),\n        stat = \"count\",\n        vjust = 0.5, hjust = 1,\n        position = position_dodge(0.9)\n    ) +\n    theme_bw() +\n    theme(\n        legend.position = \"bottom\"\n    ) +\n    coord_flip() +\n    labs(\n        x = \"\", y = \"\",\n        fill = \"Estatus\",\n        title = \"Estatus\"\n    )\n\n\n\n\n\n\n\n\nPor último, se observa que practicamente todas las solicitudes fueron respondidas, o estaban en proceso de. Sin embargo, esto no significa que las respuestas sean útiles para las personas. O bien, que respondan de manera satisfactoria de acuerdo a las personas solicitantes."
  },
  {
    "objectID": "posts/agua-pasa-por-mi-casa/index.html#y-qué-más",
    "href": "posts/agua-pasa-por-mi-casa/index.html#y-qué-más",
    "title": "¿Agua pasa por mi casa?",
    "section": "¿Y qué más?",
    "text": "¿Y qué más?\nPara rematar este post, que me ha tomado desde el año pasado (2023), pensé en hacer un análisis de sentimientos en R como en entradas anteriores (“Días sin ti” y “Línea 12”). Pero el lexicon utilizado, syuzhet, es muy grande y utilizarlo es exageradamente tardado. Estoy escribiendo esto 3 horas después de intentar un preview de esta entrada antes de montarlo.\nPor esa razón, siguiendo a Julia Silge & David Robinson vamos a revisar la estadística tf-idf. Gracias a Daniela por la inspiración con su trabajo del parlamento Uruguayo.\nDe manera resumida, la estadística tf-idf muestra la “importancia” relativa de una palabra en relación a un documento. Esto permite observar palabras “raras”, es decir que tienen una menor ocurrencia en general.\n\ntexto &lt;- data %&gt;%\n    select(organo_de_gobierno, etiqueta, descripcion_solicitud) %&gt;%\n    unnest_tokens(palabra, descripcion_solicitud) %&gt;%\n    mutate(\n        palabra = str_replace_all(palabra, c(\"á\" = \"a\", \"é\" = \"e\", \"í\" = \"i\", \"ó\" = \"o\", \"è\" = \"e\", \"à\" = \"a\")),\n        palabra = str_remove_all(palabra, \"[:punct:]\"),\n        palabra = str_remove_all(palabra, \"[:digit:]\")\n    ) %&gt;%\n    filter(!palabra %in% stopwords(\"es\")) %&gt;%\n    filter(!palabra %in% c(\"ciudad\", \"mexico\", \"solicito\", \"cdmx\", \"distrito\", \"federal\", \"diga\")) %&gt;%\n    filter(palabra &gt; nchar(2))\n\n\ntexto_ambito &lt;- texto %&gt;%\n    count(organo_de_gobierno, palabra)\n\ntotal_texto &lt;- texto_ambito %&gt;%\n    group_by(organo_de_gobierno) %&gt;%\n    summarize(total = sum(n))\n\ntexto_ambito &lt;- left_join(texto_ambito, total_texto)\n\ntexto_tfidf &lt;- texto_ambito %&gt;%\n    bind_tf_idf(palabra, organo_de_gobierno, n)\n\n\ntexto_tfidf %&gt;%\n    group_by(organo_de_gobierno) %&gt;%\n    slice_max(tf_idf, n = 15) %&gt;%\n    ungroup() %&gt;%\n    ggplot(aes(x = tf_idf, y = forcats::fct_reorder(palabra, tf_idf), fill = organo_de_gobierno)) +\n    geom_col(show.legend = FALSE) +\n    facet_wrap(. ~ organo_de_gobierno, ncol = 2, scales = \"free\")\n\n\n\n\n\n\n\n\nSi se realiza el análisis por ámbito de los sujetos obligados (alcaldías, poder legislativo, judicial, ejecutivo, etc.) No se logra apreciar alguna palabra “relevante” respecto al tema del agua.\nSin embargo, en el caso del poder judicial las palabras carpetas (asumo que de carpetas de investigación), dolosos, culposos, judicatura y delito son palabras importantes. De manera similar, en el caso del poder legislativo con las palabras legislatura, diputada y aldf (Asamblea Legislativa del Distrito Federal). Lo cual da cuenta de su importancia para realizar análisis.\n\ntexto_etiqueta &lt;- texto %&gt;%\n    count(etiqueta, palabra)\n\ntotal_etiqueta &lt;- texto_etiqueta %&gt;%\n    group_by(etiqueta) %&gt;%\n    summarize(total = sum(n))\n\ntexto_etiqueta &lt;- left_join(texto_etiqueta, total_etiqueta)\n\netiqueta_tfidf &lt;- texto_etiqueta %&gt;%\n    bind_tf_idf(palabra, etiqueta, n)\n\n\netiqueta_tfidf %&gt;%\n    group_by(etiqueta) %&gt;%\n    slice_max(tf_idf, n = 15) %&gt;%\n    ungroup() %&gt;%\n    ggplot(aes(x = tf_idf, y = palabra, fill = etiqueta)) +\n    geom_col(show.legend = FALSE) +\n    facet_wrap(. ~ etiqueta, ncol = 2, scales = \"free\")\n\n\n\n\n\n\n\n\nEn esta gráfica, ustedes disculparan que no esté más desordenada que la anterior, pero no sé cual era el error.\nHay un par de cosas que quiero destacar sobre las palabras que aparecen en cada categoría:\n\nAbastecimiento: “tandeosolicito”, gasta y derrama.\nImpacto ambiental: acuaticos, ecosistemas y desequilibrio.\nInfraestructura y obras: “highparksur”, inmobiliario y colpasarse.\nMantenimiento y rehabilitación: derrumbar, trazadas y colación.\nPago de derechos: albercas, electropura y bonafont.\nPipas: asentamiento, presupuesto y posesionario.\nPresupuesto: reasignación, finanzas y presupuestarios.\n\nEn los casos de diagnósticos, informes, reportes y opiniones técnicas, y permisos y contratos tienen pocas palabras “importantes” sobre el tema. Especialmente esta última, en donde por alguna razón aparece la palabra “rubi”…\nY bueno, con esto podemos imaginar otras posibilidades para realizar análisis más complicados y detallados de datos reales."
  },
  {
    "objectID": "posts/agua-pasa-por-mi-casa/index.html#y-fin",
    "href": "posts/agua-pasa-por-mi-casa/index.html#y-fin",
    "title": "¿Agua pasa por mi casa?",
    "section": "Y fin",
    "text": "Y fin\nCon esto se termina el primer análisis del año. Cada vez trato de incorporar nuevas herrameintas que permitan obtener nuevas ideas sobre que hacer con la información disponible. Si alguna de ustedes tiene alguna sugerencia siempre estoy dispuesto a colaborar. Estoy a un DM de distancia.\nSalu2."
  },
  {
    "objectID": "posts/eleccciones-federales-2021/index.html",
    "href": "posts/eleccciones-federales-2021/index.html",
    "title": "Elecciones 2021 - Diputaciones Federales",
    "section": "",
    "text": "¡Bienvenidas! Espero que estén muy bien, que se estén quedando en casa y que sus seres queridos estén sanas y salvas.\nSi me conocen, saben que estudié Ciencia Política y creo que todo es conflicto y caos en la vida. Las elecciones son esos pequeños eventos que nos dan rienda suelta para criticar todo y empezar a inventarnos historias y escenarios plausibles y posibles.\nPero, lo más importante es como afecta la política en nuestra vida diaria. En primer lugar, la política es esa profesión en la que unas personas deciden la distribución de bienes y servicios públicos, mientras otro grupo (mucho mayor) evalúa a los primeros y decide si estas deben continuar en el puesto. En otras palabras, la política es un trabajo.\nAhora, el mundo se ha vuelto cada vez más complejo, y nunca tenemos tiempo para ocuparnos de todas las cosas que deberían importarnos. Una de esas cosas es la política, y cómo es un trabajo, pues, habrá gente dispuesta a hacerlo. Además, hay distintos tipos de trabajo en el mundo de la política, pero concentrémonos en lo que va a pasar el próximo año.\n\n\nEn 2021 hay una elección federal: diputaciones. Hay 3 tipos de trabajos en la política federal: Presidenta de la República, senadora y diputada (a estos últimos dos también se les llama legisladoras). Los primeros dos puestos, Presidencia y Senadurías, duran 6 años y el último, diputaciones, 3 años. Pero, los últimos dos, Senadurías y Diputaciones, pueden reelegirse hasta por 12 años.\nEsto significa que: 1. Las senadoras pueden competir y ganar en dos elecciones. 2. Las diputadas pueden hacer esto en cuatro elecciones.\nAhora, en la Cámara de Diputados hay 500 puestos de trabajo que se compiten por las elecciones. Pero, solo 300 se eligen directamente, y el resto, 200, se eligen de manera indirecta. Y ustedes me dirán, y ¿cómo voy a meter código aquí? Pues, grafiquemos la actual composición de la Cámara de Diputados\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\nlibrary(ggparliament)\n\nWarning: package 'ggparliament' was built under R version 4.2.3\n\ninp &lt;- \"D:/dhumb/Documents/projects/data_blog/elecciones\"\n\nAquí agregué el paquete ggparliament, que nos ayuda a visualizar la composición de los congresos, solo hay que ajustar nuestros datos. Si le dan clic viene un vignette con ejemplos de cómo transformar los datos.\n\ndip &lt;- read.csv(paste(inp, \"integracion_diputados(2000_2018) - Hoja1.csv\", sep = \"/\"), encoding = \"UTF-8\") %&gt;%\n  filter(year==2018) %&gt;%\n  mutate(\n    oficialismo = case_when(\n      GP == \"Morena\" ~ 1,\n      GP == \"PES\" ~ 1,\n      GP == \"PT\" ~ 1,\n      T ~ 0\n    )\n  )\n\ndip18 &lt;- dip %&gt;%\n  parliament_data(\n    #election_data = .,\n    party_seats = .$Total,\n    group = .$oficialismo,\n    parl_rows = 20,\n    type = \"opposing_benches\"\n  )\n\nLos datos que ocupé son del Centro de Estudios Alonso Lujambio y el proyecto de su director, el Dr. Horacio Vives Segl. En este caso, para la gráfica hay que poner una variable de oficialismo (es decir, el partido o partidos en el gobierno). Como es una variable dicotómica, solo puede tener dos valores: que el partido sí pertenezca a la coalición gobernante (Morena, PES y PT), o que no pertenezca. Esto se representa usualmente con valores de 1 (oficialismo) o 0.\n\npartidos &lt;- c(\n  \"Morena\" = \"#b30000\",\n  \"PAN\" = \"#005ce6\",\n  \"PRI\" = \"#ff0000\",\n  \"PES\" = \"#8701F7\",\n  \"PT\" = \"#DD0FB4\",\n  \"MC\" = \"#ff8300\",\n  \"PRD\" = \"#ffff00\",\n  \"PVEM\" = \"#00cc44\",\n  \"Sin_Grupo\" = \"#8f1e64\"\n)\n\nggplot(dip18, aes(x, y, colour = GP)) +\n  scale_color_manual(values = partidos, name = \"Partidos\") +\n  geom_parliament_seats() +\n  theme_ggparliament()\n\n\n\n\n\n\n\n\nEn el vector “partidos” viene relacionado el nombre, el partido con su color correspondiente, luego en una de las capas de ggplot lo colocamos de manera manual. Lo que resulta evidente es que alrededor de 2/3 de la cámara de diputados está en manos del oficialismo. Y ustedes dirán, ¿y eso qué tiene que ver con la navidad?\nPues, no mucho realmente, peeeero, la cámara de diputados tiene actividades que impactan en nuestra vida diaria: 1. Aprueban el presupuesto del gobierno federal: las estancias infantiles, la guardia nacional, los programas de liconsa, los apoyos de agricultores (PROCAMPO), el gasto de gran parte de a educación, todo eso lo aprueban esas personas. 2. Aprueban leyes que posibilitan nuevas actividades para el gobierno. Esto lo hacen junto con la Cámara de senadores, pero a ellas les faltan otros 3 años en el cargo.\nY aquí salen más dudas: ¿No es mejor que pocos partidos tengan control de gobierno? Y puede ser que sí, si no te interesa la transparencia (saber qué y por qué un gobierno hace las cosas) y si no te interesa la rendición de cuentas (si se equivocan, saber a quién echarle la culpa y pensar en como solucionarlo).\nY puede que hoy no te importe, pero, ¿qué pasa si durante este año te fue mal y no hubo manera de agarrar alguna ayuda del gobierno? Yo no votaría por ellos de nuevo.\n\n\n\nBueno, ya vimos que Morena y sus compinches tienen la cámara de diputados. Y uno creería que desde el PRI este tipo de cosas no debería pasar. ¡Y tienen razón!! Pero, “hecha la ley, hecha la trampa”. No hemos hablado de los mecanismos de elección.\nSe mencionó que hay 500 puestos de trabajo como diputada federal, pero solo 300 son por elección directa. Esto significa que el país está dividido en 300 pedacitos (llamados distritos electorales federales) y gana la persona que tiene más votos en el distrito.\n¿Y los otros 200? En ese caso el país se divide en 5 listas donde están apuntadas todas las personas que NO compiten. ¿Se acuerdan de Carmen Salinas, flamante diputada federal por el PRI? ¿Recuerdan haber votado por ella? Claro, es porque ella fue diputada de representación proporcional (RP de ahora en adelante).\nEsto no quiere decir que deberíamos quitar las diputaciones de RP. Veamos la composición actual y juzguen ustedes:\n\ndip\n\n         GP  MR RP Total Legislatura year oficialismo\n1    Morena 168 91   259        LXIV 2018           1\n2       PAN  39 39    78        LXIV 2018           0\n3       PRI   9 38    47        LXIV 2018           0\n4       PES  29 NA    29        LXIV 2018           1\n5        PT  25  3    28        LXIV 2018           1\n6        MC  17 11    28        LXIV 2018           0\n7       PRD   6  5    11        LXIV 2018           0\n8      PVEM   4  7    11        LXIV 2018           0\n9 Sin_Grupo   3  6     9        LXIV 2018           0\n\n\n\ndip %&gt;%\n  group_by(oficialismo) %&gt;%\n  summarise(total = sum(Total)) %&gt;%\n  mutate(porcentaje = total*100/500)\n\n# A tibble: 2 × 3\n  oficialismo total porcentaje\n        &lt;dbl&gt; &lt;int&gt;      &lt;dbl&gt;\n1           0   184       36.8\n2           1   316       63.2\n\n\nSi nos concentramos solo en la columna de Mayoría Relativa (MR), es decir, los 300 de elección directa, vemos que, aun así, se llevan al baile a todos los partidos y prácticamente no necesitan negociar para sacar sus temas. Actualmente, tienen 63.2% de la cámara, lo que facilita mucho sus decisiones. Pero como muestra la tabla de abajo, si nos quedamos solo con los de MR, solo necesitan convencer a 3 diputadas para tener mayoría calificada (75% de las legisladoras presentes). Con esa mayoría podrían cambiar lo que quieran de la constitución.\n\ndip %&gt;%\n  group_by(oficialismo) %&gt;%\n  summarise(total = sum(MR)) %&gt;%\n  mutate(porcentaje = total*100/300)\n\n# A tibble: 2 × 3\n  oficialismo total porcentaje\n        &lt;dbl&gt; &lt;int&gt;      &lt;dbl&gt;\n1           0    78         26\n2           1   222         74\n\n\nPero esta es una discusión para otro post.\nEl objetivo de este es recordarles que voten el próximo año. Que estén al pendiente, y que la política es una cosa que afecta nuestras vidas día a día. Tal vez no parece importante ahora, pero es nuestro derecho (votar) y si nos es posible hay que hacerlo."
  },
  {
    "objectID": "posts/eleccciones-federales-2021/index.html#cámara-de-diputados",
    "href": "posts/eleccciones-federales-2021/index.html#cámara-de-diputados",
    "title": "Elecciones 2021 - Diputaciones Federales",
    "section": "",
    "text": "En 2021 hay una elección federal: diputaciones. Hay 3 tipos de trabajos en la política federal: Presidenta de la República, senadora y diputada (a estos últimos dos también se les llama legisladoras). Los primeros dos puestos, Presidencia y Senadurías, duran 6 años y el último, diputaciones, 3 años. Pero, los últimos dos, Senadurías y Diputaciones, pueden reelegirse hasta por 12 años.\nEsto significa que: 1. Las senadoras pueden competir y ganar en dos elecciones. 2. Las diputadas pueden hacer esto en cuatro elecciones.\nAhora, en la Cámara de Diputados hay 500 puestos de trabajo que se compiten por las elecciones. Pero, solo 300 se eligen directamente, y el resto, 200, se eligen de manera indirecta. Y ustedes me dirán, y ¿cómo voy a meter código aquí? Pues, grafiquemos la actual composición de la Cámara de Diputados\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\nlibrary(ggparliament)\n\nWarning: package 'ggparliament' was built under R version 4.2.3\n\ninp &lt;- \"D:/dhumb/Documents/projects/data_blog/elecciones\"\n\nAquí agregué el paquete ggparliament, que nos ayuda a visualizar la composición de los congresos, solo hay que ajustar nuestros datos. Si le dan clic viene un vignette con ejemplos de cómo transformar los datos.\n\ndip &lt;- read.csv(paste(inp, \"integracion_diputados(2000_2018) - Hoja1.csv\", sep = \"/\"), encoding = \"UTF-8\") %&gt;%\n  filter(year==2018) %&gt;%\n  mutate(\n    oficialismo = case_when(\n      GP == \"Morena\" ~ 1,\n      GP == \"PES\" ~ 1,\n      GP == \"PT\" ~ 1,\n      T ~ 0\n    )\n  )\n\ndip18 &lt;- dip %&gt;%\n  parliament_data(\n    #election_data = .,\n    party_seats = .$Total,\n    group = .$oficialismo,\n    parl_rows = 20,\n    type = \"opposing_benches\"\n  )\n\nLos datos que ocupé son del Centro de Estudios Alonso Lujambio y el proyecto de su director, el Dr. Horacio Vives Segl. En este caso, para la gráfica hay que poner una variable de oficialismo (es decir, el partido o partidos en el gobierno). Como es una variable dicotómica, solo puede tener dos valores: que el partido sí pertenezca a la coalición gobernante (Morena, PES y PT), o que no pertenezca. Esto se representa usualmente con valores de 1 (oficialismo) o 0.\n\npartidos &lt;- c(\n  \"Morena\" = \"#b30000\",\n  \"PAN\" = \"#005ce6\",\n  \"PRI\" = \"#ff0000\",\n  \"PES\" = \"#8701F7\",\n  \"PT\" = \"#DD0FB4\",\n  \"MC\" = \"#ff8300\",\n  \"PRD\" = \"#ffff00\",\n  \"PVEM\" = \"#00cc44\",\n  \"Sin_Grupo\" = \"#8f1e64\"\n)\n\nggplot(dip18, aes(x, y, colour = GP)) +\n  scale_color_manual(values = partidos, name = \"Partidos\") +\n  geom_parliament_seats() +\n  theme_ggparliament()\n\n\n\n\n\n\n\n\nEn el vector “partidos” viene relacionado el nombre, el partido con su color correspondiente, luego en una de las capas de ggplot lo colocamos de manera manual. Lo que resulta evidente es que alrededor de 2/3 de la cámara de diputados está en manos del oficialismo. Y ustedes dirán, ¿y eso qué tiene que ver con la navidad?\nPues, no mucho realmente, peeeero, la cámara de diputados tiene actividades que impactan en nuestra vida diaria: 1. Aprueban el presupuesto del gobierno federal: las estancias infantiles, la guardia nacional, los programas de liconsa, los apoyos de agricultores (PROCAMPO), el gasto de gran parte de a educación, todo eso lo aprueban esas personas. 2. Aprueban leyes que posibilitan nuevas actividades para el gobierno. Esto lo hacen junto con la Cámara de senadores, pero a ellas les faltan otros 3 años en el cargo.\nY aquí salen más dudas: ¿No es mejor que pocos partidos tengan control de gobierno? Y puede ser que sí, si no te interesa la transparencia (saber qué y por qué un gobierno hace las cosas) y si no te interesa la rendición de cuentas (si se equivocan, saber a quién echarle la culpa y pensar en como solucionarlo).\nY puede que hoy no te importe, pero, ¿qué pasa si durante este año te fue mal y no hubo manera de agarrar alguna ayuda del gobierno? Yo no votaría por ellos de nuevo."
  },
  {
    "objectID": "posts/eleccciones-federales-2021/index.html#mayoría-relativa-y-representación-proporcional",
    "href": "posts/eleccciones-federales-2021/index.html#mayoría-relativa-y-representación-proporcional",
    "title": "Elecciones 2021 - Diputaciones Federales",
    "section": "",
    "text": "Bueno, ya vimos que Morena y sus compinches tienen la cámara de diputados. Y uno creería que desde el PRI este tipo de cosas no debería pasar. ¡Y tienen razón!! Pero, “hecha la ley, hecha la trampa”. No hemos hablado de los mecanismos de elección.\nSe mencionó que hay 500 puestos de trabajo como diputada federal, pero solo 300 son por elección directa. Esto significa que el país está dividido en 300 pedacitos (llamados distritos electorales federales) y gana la persona que tiene más votos en el distrito.\n¿Y los otros 200? En ese caso el país se divide en 5 listas donde están apuntadas todas las personas que NO compiten. ¿Se acuerdan de Carmen Salinas, flamante diputada federal por el PRI? ¿Recuerdan haber votado por ella? Claro, es porque ella fue diputada de representación proporcional (RP de ahora en adelante).\nEsto no quiere decir que deberíamos quitar las diputaciones de RP. Veamos la composición actual y juzguen ustedes:\n\ndip\n\n         GP  MR RP Total Legislatura year oficialismo\n1    Morena 168 91   259        LXIV 2018           1\n2       PAN  39 39    78        LXIV 2018           0\n3       PRI   9 38    47        LXIV 2018           0\n4       PES  29 NA    29        LXIV 2018           1\n5        PT  25  3    28        LXIV 2018           1\n6        MC  17 11    28        LXIV 2018           0\n7       PRD   6  5    11        LXIV 2018           0\n8      PVEM   4  7    11        LXIV 2018           0\n9 Sin_Grupo   3  6     9        LXIV 2018           0\n\n\n\ndip %&gt;%\n  group_by(oficialismo) %&gt;%\n  summarise(total = sum(Total)) %&gt;%\n  mutate(porcentaje = total*100/500)\n\n# A tibble: 2 × 3\n  oficialismo total porcentaje\n        &lt;dbl&gt; &lt;int&gt;      &lt;dbl&gt;\n1           0   184       36.8\n2           1   316       63.2\n\n\nSi nos concentramos solo en la columna de Mayoría Relativa (MR), es decir, los 300 de elección directa, vemos que, aun así, se llevan al baile a todos los partidos y prácticamente no necesitan negociar para sacar sus temas. Actualmente, tienen 63.2% de la cámara, lo que facilita mucho sus decisiones. Pero como muestra la tabla de abajo, si nos quedamos solo con los de MR, solo necesitan convencer a 3 diputadas para tener mayoría calificada (75% de las legisladoras presentes). Con esa mayoría podrían cambiar lo que quieran de la constitución.\n\ndip %&gt;%\n  group_by(oficialismo) %&gt;%\n  summarise(total = sum(MR)) %&gt;%\n  mutate(porcentaje = total*100/300)\n\n# A tibble: 2 × 3\n  oficialismo total porcentaje\n        &lt;dbl&gt; &lt;int&gt;      &lt;dbl&gt;\n1           0    78         26\n2           1   222         74\n\n\nPero esta es una discusión para otro post.\nEl objetivo de este es recordarles que voten el próximo año. Que estén al pendiente, y que la política es una cosa que afecta nuestras vidas día a día. Tal vez no parece importante ahora, pero es nuestro derecho (votar) y si nos es posible hay que hacerlo."
  },
  {
    "objectID": "posts/eleccciones-federales-2021/index.html#en-resumen",
    "href": "posts/eleccciones-federales-2021/index.html#en-resumen",
    "title": "Elecciones 2021 - Diputaciones Federales",
    "section": "En resumen:",
    "text": "En resumen:\nPara buscar la reelección, las diputadas deben enviar una carta al INE, a la Cámara de Diputados y al Partido Político al cual pertenecen. Y ya conocemos la lista de diputadas y diputados que buscan reelegirse. ¿Se acuerdan que hay 500 escaños/curules?\nBueno, pues 89.6% (448) quieren reelegirse.\nAhora, ya que dijeron que sí quieren, hay una serie de condiciones que deben cumplir.\n\nPueden escoger el principio por el cual quieren ser electas. Directamente (Mayoría Relativa) o indirectamente (Representación Proporcional)\n\nSi escogen ser electas por el mismo principio, deben competir en el mismo distrito (MR) o en la misma circunscripción (RP).\n\nPero deben ser postulados por el mismo partido, o un partido de la coalición original. Esto significa que, por ejemplo, una diputada postulada por la coalición “Juntos Haremos Historia” (Morena-PT-PES) puede ser postulada por Morena o el Partido del Trabajo. Pero no por el Partido Encuentro Social, ya que perdió el registro.\n\nA menos que la diputada haya renunciado al partido, o haya perdido la pertenencia antes de la mitad del mandato (antes del 20 de febrero del 2020).\n\nExcepto en el caso de diputadas plurinominales o de Representación Proporcional. (Aquí, si son abogadas, díganme que procede).\nLas legisladoras pueden decidir si se separan o no del cargo durante el proceso. Lo que significa que si no dejan su curul, tienen que asistir a trabajar, no pueden utilizar recursos de la cámara de diputados y no pueden ocupar su posición como legisladora para hacer campaña electoral a su favor.\n\nPor último, los partidos están obligados a garantizar paridad en las candidaturas, contemplando a las legisladoras que buscan la reelección. Asimismo, ningún candidato puede ser postulado si está inscrito en el registro nacional de personas sancionadas en materia de violencia política en razón de género."
  },
  {
    "objectID": "posts/eleccciones-federales-2021/index.html#quienes-son",
    "href": "posts/eleccciones-federales-2021/index.html#quienes-son",
    "title": "Elecciones 2021 - Diputaciones Federales",
    "section": "¿Quienes son?",
    "text": "¿Quienes son?\nY a todo esto, ¿quiénes son las legisladoras que buscan la reelección? La lista original pueden consultarla aquí."
  },
  {
    "objectID": "posts/intro-to-tidyverse/index.html",
    "href": "posts/intro-to-tidyverse/index.html",
    "title": "Intro a Tidyverse",
    "section": "",
    "text": "R es un lenguaje de programación pensado para profesionales de las matemáticas y de la estadística. En este sentido, es un software con mucha historia (desde los 70’s aproximadamente). Por esta razón se ha tenido que actualizar y mejorar. Esto se ha debido, principalmente, a la gran comunidad de usuarios y a que es un software gratuito y de código abierto. Esto quiere decir que todas lo pueden modificar y adaptar de acuerdo a sus necesidades.\nPor esta razón, se han creado herramientas para el análisis de datos: Tidyverse\nR tiene una sintaxis base (a partir de ahora, R base). Sin embargo, como cualquier otro lenguaje, las palabras, cosas y significados cambian a lo largo del tiempo. Tidyverse nos permite realizar distintas operaciones sobre bases de datos (además de que me parece más amigable que R base).\nA estar herramientas adicionales se les llama paquetes (packages) y deben ser instaladas. Una vez instaladas, solo deben “activarse” cada vez que serán utilizadas (library).\nEn este caso, tidyverse es un conjunto de paquetes: - ggplot (visualización/gráficas) - dplyr (manipulación de bases de datos) - tidyr (arreglo/acomodar bases de datos) - readr (importar “leer” archivos) - tibble (creación de bases de datos, data frames) - stringr (funciones para textos, strings) - forcats (funciones para factores)\nBueno, esto ya fue mucho choro. Vamos a jugar un rato. Para ejecutar el código abajo debes tener instalado R, R studio, así como tidyverse install.packages(“tidyverse”) en tu script."
  },
  {
    "objectID": "posts/intro-to-tidyverse/index.html#pequeña-intro",
    "href": "posts/intro-to-tidyverse/index.html#pequeña-intro",
    "title": "Intro a Tidyverse",
    "section": "",
    "text": "R es un lenguaje de programación pensado para profesionales de las matemáticas y de la estadística. En este sentido, es un software con mucha historia (desde los 70’s aproximadamente). Por esta razón se ha tenido que actualizar y mejorar. Esto se ha debido, principalmente, a la gran comunidad de usuarios y a que es un software gratuito y de código abierto. Esto quiere decir que todas lo pueden modificar y adaptar de acuerdo a sus necesidades.\nPor esta razón, se han creado herramientas para el análisis de datos: Tidyverse\nR tiene una sintaxis base (a partir de ahora, R base). Sin embargo, como cualquier otro lenguaje, las palabras, cosas y significados cambian a lo largo del tiempo. Tidyverse nos permite realizar distintas operaciones sobre bases de datos (además de que me parece más amigable que R base).\nA estar herramientas adicionales se les llama paquetes (packages) y deben ser instaladas. Una vez instaladas, solo deben “activarse” cada vez que serán utilizadas (library).\nEn este caso, tidyverse es un conjunto de paquetes: - ggplot (visualización/gráficas) - dplyr (manipulación de bases de datos) - tidyr (arreglo/acomodar bases de datos) - readr (importar “leer” archivos) - tibble (creación de bases de datos, data frames) - stringr (funciones para textos, strings) - forcats (funciones para factores)\nBueno, esto ya fue mucho choro. Vamos a jugar un rato. Para ejecutar el código abajo debes tener instalado R, R studio, así como tidyverse install.packages(“tidyverse”) en tu script."
  },
  {
    "objectID": "posts/intro-to-tidyverse/index.html#dplyr-y-ggplot",
    "href": "posts/intro-to-tidyverse/index.html#dplyr-y-ggplot",
    "title": "Intro a Tidyverse",
    "section": "dplyr y ggplot",
    "text": "dplyr y ggplot\nEn este caso, vamos a utilizar las bases de datos que vienen por default en ggplot. Por lo que no tendrás que descargar nada (por ahora). Una forma de presentar nuestros resultados es a través de tablas y gráficas. Empezaremos con cosas sencillas, hasta hacerlas complejas y bonitas.\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\n\nPara mi, me funciona colocar las libraries al principio del script. Esto me ayuda a tener claridad de que paquetes estoy utilizando.\n\ndatos &lt;- diamonds\n\ndim(datos)\n\n[1] 53940    10\n\n\n“datos” es el nombre que le puse a la base de datos (si lo nombramos existe :D). “diamonds” es la base de datos dentro del paquete ggplot2. Contiene información de precios, calidad y quilates de 53,940 diamantes, en 10 columnas. ¿Qué cómo sé eso? por la función dim: número de renglones y número de columnas. Para información adicional, pueden revisar la página de Kaggle sobre este dataset\n\nsummary(datos)\n\n     carat               cut        color        clarity          depth      \n Min.   :0.2000   Fair     : 1610   D: 6775   SI1    :13065   Min.   :43.00  \n 1st Qu.:0.4000   Good     : 4906   E: 9797   VS2    :12258   1st Qu.:61.00  \n Median :0.7000   Very Good:12082   F: 9542   SI2    : 9194   Median :61.80  \n Mean   :0.7979   Premium  :13791   G:11292   VS1    : 8171   Mean   :61.75  \n 3rd Qu.:1.0400   Ideal    :21551   H: 8304   VVS2   : 5066   3rd Qu.:62.50  \n Max.   :5.0100                     I: 5422   VVS1   : 3655   Max.   :79.00  \n                                    J: 2808   (Other): 2531                  \n     table           price             x                y         \n Min.   :43.00   Min.   :  326   Min.   : 0.000   Min.   : 0.000  \n 1st Qu.:56.00   1st Qu.:  950   1st Qu.: 4.710   1st Qu.: 4.720  \n Median :57.00   Median : 2401   Median : 5.700   Median : 5.710  \n Mean   :57.46   Mean   : 3933   Mean   : 5.731   Mean   : 5.735  \n 3rd Qu.:59.00   3rd Qu.: 5324   3rd Qu.: 6.540   3rd Qu.: 6.540  \n Max.   :95.00   Max.   :18823   Max.   :10.740   Max.   :58.900  \n                                                                  \n       z         \n Min.   : 0.000  \n 1st Qu.: 2.910  \n Median : 3.530  \n Mean   : 3.539  \n 3rd Qu.: 4.040  \n Max.   :31.800  \n                 \n\ndatos &lt;- datos %&gt;%\n    select(-c(x, y, z)) %&gt;%\n    filter(price &gt;= 1000)\n\nEn este chunk, o pedazo de código, la función summary nos da un resumen de como están distribuidas las variables. Mientras que %&gt;% es un operador llamado pipe que funciona con dplyr y nos permite realizar operaciones secuenciales; esto significa que va a ser como una cascada: del conjunto de datos ejecuta la operación select y luego la operación filter.\nAsí pues, select nos permite mantener o eliminar columnas de una base de datos. La parte c() es para indicar una selección de columnas, en este caso las columnas llamadas “x”, “y” y “z”. Mientras que el signo negativo - que le antecede indica que esa selección se va a eliminar. Por último, la función filter es un filtro para quedarnos solo con los datos que cumplan la condición: que el preció sea mayor o igual a mil dólares.\n\nggplot(datos, aes(x = cut)) +\n    geom_bar()\n\n\n\n\n\n\n\n\nUna gráfica de barras es, originalmente, una gráfica de una sola variable.\nIgual que en dplyr, ggplot ejecuta operaciones secuenciales: primero necesita la base de datos a graficar (datos), luego en aes (aesthetics) van las variables principales a graficar. Es decir, el “eje x” y “eje y”. Este tipo de gráficas sencillas son muy útiles para explorar los datos. Y por lo tanto se pueden complejizar para obtener mejores lecturas, intuiciones y llegar a conocimiento. Pero vamos paso a paso.\n\nggplot(datos, aes(x = cut, fill = color)) +\n    geom_bar()\n\n\n\n\n\n\n\n\nEn este chunk¨la el parametro fill* nos permite incluir variables categóricas dentro de las barras. Esto quiere decir, aquellas categorías que son mutuamente excluyentes, en este caso si un diamante es color “D”, no puede ser al mismo tiempo de color “J”.\n\nggplot(datos, aes(x = cut, fill = color)) +\n    geom_bar(position = \"dodge\")\n\n\n\n\n\n\n\n\nComo ya separamos cada barra en categorías, separarlas a lo largo del eje puede ser una buena opción.\n\nggplot(datos, aes(x = cut, fill = color)) +\n    geom_bar(position = \"dodge\") +\n    labs(\n        title = \"Mi primera gráfica\",\n        subtitle = \"Datos de diamantes\",\n        y = \"\", x = \"Corte\",\n        caption = \"Fuente: Kaggle\",\n        fill = \"Colores\"\n    )\n\n\n\n\n\n\n\n\nLa función labs es muy útil para modificar las gráficas y es bastante intuitiva. En este caso, todo lo que está en comillas son textos (strings). Y en el caso del eje Y se elimina la etiqueta del conteo.\n\nggplot(datos, aes(x = cut, fill = color)) +\n    geom_bar(position = \"dodge\") +\n    labs(\n        title = \"Mi primera gráfica\",\n        subtitle = \"Datos de diamantes\",\n        y = \"\", x = \"corte\",\n        caption = \"Fuente: Kaggle\",\n        fill = \"Colores\"\n    ) +\n    coord_flip() +\n    theme_classic()\n\n\n\n\n\n\n\n\nLa función coord flip nos permite girar a la izquierda nuestra gráfica, mientras que la función theme_classic() cambia como se ve la gráfica final.\nEste post es una versión revisada de la primera iteración de este blog y tiene como intención servir de tutorial para el análisis de datos."
  },
  {
    "objectID": "posts/scrap/index.html",
    "href": "posts/scrap/index.html",
    "title": "Scrap! o como extraer info de páginas",
    "section": "",
    "text": "He estado perdido, igual y no lo notaron, pero estoy vivo. Dos borradores de post, que están pendientes, un montón de trabajo, trámites de la escuela y demás cosas en el camino, I’m back.\nEl otro día me pidieron hacer una relación de otro proyecto en el que estaba colaborando Análisis de las elecciones federales 2021 y pensé: “a, pues eso sale en chinga con R”, pero hace mucho no hago scraping, no pude y terminé haciéndolo a mano.\nPara que no les pase lo que a mí, voy a explicarles todo lo que sé esperando que no vuelvan a cambiar la library y lo que vean aquí no funcione (como me pasó en los 3 tutoriales de hace menos de 2 años que revisé).\n\nlibrary(purrr)\n\nWarning: package 'purrr' was built under R version 4.2.3\n\nlibrary(rvest)\n\nWarning: package 'rvest' was built under R version 4.2.3\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(stringr)\n\nWarning: package 'stringr' was built under R version 4.2.3\n\n\nEntonces, lo primero siempre es cargar las libraries que vamos a utilizar. El paquete nuevo es rvest que literalmente se llama así por harvest para “cosechar” los datos de una página web. Todos los paquetes de R son superñoños, por si no se habían dado cuenta.\n\n\n\nurl &lt;- \"https://analisiselectoral2021.juridicas.unam.mx/publicaciones?page=\"\n\ndada &lt;- paste0(url, \"0\") # enlace con las publicciones más recientes\n\nComo ya revisé cuántas páginas había en ese portal, sé que van del 0 al 6. Sigo buscando un método para no tener que contarlo a mano, así que avísenme.\nAhora, lo que hay que hacer es entender cómo se organiza una página web. Hay personas mucho más hábiles que yo para eso, yo solo les sugiero que en la página que seleccionen den clic derecho en cualquier lado y seleccionen inspeccionar. Esto funciona si utilizas chrome.\nAhora, si ustedes como yo no tienen idea de páginas web, html y CSS… solo tienen que buscar lo que diga class y probar.\n\ntitulos &lt;- read_html(dada) %&gt;% # Con esta función hacemos que R \"lea\" la página\n    html_nodes(\".titulo-publicacion-l\") %&gt;% # Aquí seleccionamos el \"nodo\" o clase que queremos recuperar\n    html_text() %&gt;% # y con esto lo convertimos a texto\n    as_tibble() %&gt;%\n    rename(titulo = value)\n\nEste es un vector de texto, ¿se acuerdan de las primeras entradas y como una serie de vectores acomodados crean un dataframe? Pues aquí es donde rinde sus frutos entender la diferencia. Además, el scrapping funciona por posiciones, así que si la página está lógicamente construida podemos extraer sin problemas la información necesaria\n\nautor &lt;- read_html(dada) %&gt;%\n    html_nodes(\".autores\") %&gt;%\n    html_text() %&gt;%\n    as_tibble() %&gt;%\n    rename(autor = value)\n\nEntonces los títulos ya están, los autores ya están, pero qué pasa si quiero los enlaces a las notas? Bueno, es un poco más complicado, y no es tan general, pero puedes seleccionar más de un nodo y en lugar del texto, los atributos.\nAdemás, no podemos olvidar las fechas.\n\nenlaces &lt;- read_html(dada) %&gt;%\n    html_nodes(\".views-field-title-1 a\") %&gt;%\n    html_attr(\"href\") %&gt;%\n    as_tibble() %&gt;%\n    rename(enlaces = value)\n\nfechas &lt;- read_html(dada) %&gt;%\n    html_nodes(\".fuente-1 time\") %&gt;%\n    html_text() %&gt;%\n    as_tibble() %&gt;%\n    rename(fecha = value)\n\nVamos a tener todo en un olo data frame para poder consultarlo.\n\ndetalle &lt;- \"https://analisiselectoral2021.juridicas.unam.mx\"\n\ntabla &lt;- bind_cols(titulos, autor, enlaces) %&gt;%\n    mutate(\n        enlaces = paste0(detalle, enlaces)\n    )\n\nTachán!! Listo, un scrap sencillo pero poderoso. Sin embargo, hay muchas páginas. Cómo aún no me sé una manera de contarlas automáticamente, pero sé que son 7 páginas de publicaciones, pues vamos a hacer un loop, o mejor dicho un map.\n\nlista &lt;- map(\n    url,\n    ~ paste0(.x, seq(0, 6, by = 1))\n) %&gt;%\n    unlist()\nlista\n\n[1] \"https://analisiselectoral2021.juridicas.unam.mx/publicaciones?page=0\"\n[2] \"https://analisiselectoral2021.juridicas.unam.mx/publicaciones?page=1\"\n[3] \"https://analisiselectoral2021.juridicas.unam.mx/publicaciones?page=2\"\n[4] \"https://analisiselectoral2021.juridicas.unam.mx/publicaciones?page=3\"\n[5] \"https://analisiselectoral2021.juridicas.unam.mx/publicaciones?page=4\"\n[6] \"https://analisiselectoral2021.juridicas.unam.mx/publicaciones?page=5\"\n[7] \"https://analisiselectoral2021.juridicas.unam.mx/publicaciones?page=6\"\n\n\nEl primero que necesitamos es bastante sencillo, tenemos la dirección lista para pegarle los números. Como no la vamos a hacer a mano, hay que hacer algo. Yo opté por crearlo con un map, para que luego se convierta en lista y al momento de hacerle el unlist se convierte en caracteres. La otra opción sería crear un data frame con una columna de número de 0 al 6, luego pegar la columna url, pegar ambas, quitar lo que no sirve o seleccionar la nueva columna y transformarla a vector o en su defecto, utilizar dataframe$columna.\nSi se les ocurre otra manera, avísenme, que siempre se aprende algo nuevo.\n\ntitulos &lt;- map(\n    lista,\n    ~ read_html(.x) %&gt;%\n        html_nodes(\".titulo-publicacion-l\") %&gt;%\n        html_text() %&gt;%\n        as_tibble() %&gt;%\n        rename(titulo = value)\n) %&gt;%\n    bind_rows()\n\nautores &lt;- map(\n    lista,\n    ~ read_html(.x) %&gt;%\n        html_nodes(\".autores\") %&gt;%\n        html_text() %&gt;%\n        as_tibble() %&gt;%\n        rename(autor = value)\n) %&gt;%\n    bind_rows()\n\nenlaces &lt;- map(\n    lista,\n    ~ read_html(.x) %&gt;%\n        html_nodes(\".views-field-title-1 a\") %&gt;%\n        html_attr(\"href\") %&gt;%\n        as_tibble() %&gt;%\n        rename(enlaces = value)\n) %&gt;%\n    bind_rows()\n\nfechas &lt;- map(\n    lista,\n    ~ read_html(.x) %&gt;%\n        html_nodes(\".fuente-1 time\") %&gt;%\n        html_text() %&gt;%\n        as_tibble() %&gt;%\n        rename(fecha = value)\n) %&gt;%\n    bind_rows()\n\n\nfinal &lt;- cbind(titulos, autores, fechas, enlaces) %&gt;%\n    mutate(\n        enlaces = paste0(detalle, enlaces)\n    )\nhead(final)\n\n                                                                              titulo\n1                 La forma de una tensión: democracia directa, ciudadanos y partidos\n2     La crisis del modelo de comunicación política propiciada desde la presidencia.\n3                                                                    Estudia, macho…\n4                      Aprobación de los Lineamientos para la Revocatoria de Mandato\n5                                                             El “diezmo” de Texcoco\n6 La complejidad de la paridad en la integración del Congreso de la Ciudad de México\n                      autor      fecha\n1              Nicolás Loza 2021-10-14\n2      María Marván Laborde 2021-10-11\n3              Nicolás Loza 2021-10-07\n4        Flavia Freidenberg 2021-10-05\n5 Guadalupe Salmorán Villar 2021-10-04\n6            Karolina Gilas 2021-10-04\n                                                                  enlaces\n1 https://analisiselectoral2021.juridicas.unam.mx/detalle-publicacion/157\n2 https://analisiselectoral2021.juridicas.unam.mx/detalle-publicacion/155\n3 https://analisiselectoral2021.juridicas.unam.mx/detalle-publicacion/153\n4 https://analisiselectoral2021.juridicas.unam.mx/detalle-publicacion/151\n5 https://analisiselectoral2021.juridicas.unam.mx/detalle-publicacion/149\n6 https://analisiselectoral2021.juridicas.unam.mx/detalle-publicacion/147\n\n\nY listo!!! Tenemos una base de datos con los nombres de las publicaciones, autores, fechas y enlaces.\nPero… creo que le podemos sacar más jugo a esto… Por ejemplo, que tal si de una vez recuperamos los textos de las publicaciones? Que por qué? Por la gloria de Satán! Digo, porque podemos utilizar nuestras herramientas de análisis de texto y ver si hay cosas interesantes de esta manera, o hay que leer todo el texto para entenderlo.\n\n\n\nEntonces, ¿cómo le hacemos? Ya tenemos la lista de enlaces\n\npublicaciones &lt;- map(\n    final$enlaces,\n    ~ read_html(.x) %&gt;%\n        html_nodes(\".col-12\") %&gt;% # Esta es la clase que buscamos\n        html_text() %&gt;%\n        .[2] %&gt;% # solo necesitamos el segundo elemento de la lista que arroja\n        as_tibble() %&gt;%\n        rename(texto = value) %&gt;%\n        mutate(enlaces = .x)\n) %&gt;% # aunque el scrapping funciona por posiciones, a veces me da miedo y le genero identificadores para unir los DF\n    bind_rows()\n\nfinal &lt;- left_join(final, publicaciones)\n\nJoining with `by = join_by(enlaces)`\n\n\nY con eso, hemos leído las 70 publicaciones. Pero, hay un pequeño problema: aparece el título, tema, autor, fecha, un disclaimer y una leyenda para descargar un archivo. Esto porque el scrapping depende mucho de como esté armada la página. Como utilizamos una clase que agrupa todo el texto, se incluyen estos elementos.\n\nlibrary(tm)\n\nWarning: package 'tm' was built under R version 4.2.3\n\n\nLoading required package: NLP\n\nlibrary(tidyr)\n\nWarning: package 'tidyr' was built under R version 4.2.3\n\nlibrary(ggplot2)\n\n\nAttaching package: 'ggplot2'\n\n\nThe following object is masked from 'package:NLP':\n\n    annotate\n\nlibrary(syuzhet)\n\nWarning: package 'syuzhet' was built under R version 4.2.3\n\nlibrary(tidytext)\n\nWarning: package 'tidytext' was built under R version 4.2.3\n\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\n\nIgual que en un par de post anteriores, este, este y este, necesitamos estas dos libraries para analizar los textos.\n\nfinal %&gt;%\n    unnest_tokens(palabra, texto) %&gt;%\n    filter(!palabra %in% stopwords(\"es\")) %&gt;%\n    count(palabra, sort = T) %&gt;%\n    mutate(palabra = reorder(palabra, n)) %&gt;%\n    top_n(20) %&gt;%\n    ggplot(aes(x = n, y = palabra)) +\n    geom_bar(stat = \"identity\") +\n    theme_classic() +\n    labs(\n        x = \"\", y = \"\",\n        title = \"Palabras más frecuentes\",\n        subtitle = \"En todas las publicaciones\"\n    )\n\nSelecting by n\n\n\n\n\n\n\n\n\n\nComo no es ninguna sorpresa, “INE” y “electoral” son las palabras más frecuentes en todas las publicaciones. Pero, tenemos manera de revisar el top 10 de cada autor. Sin embargo, antes, vamos a ver cuantas publicaciones tiene cada autor y las publicaciones por mes, nomás porque sí.\n\nfinal %&gt;%\n    count(autor, sort = T)\n\n                         autor n\n1               Karolina Gilas 9\n2           Flavia Freidenberg 8\n3      Juan Jesús Garza Onofre 8\n4       Luz María Cruz Parcero 7\n5                 Nicolás Loza 7\n6        Roberto Lara Chagoyán 7\n7    Guadalupe Salmorán Villar 6\n8         María Marván Laborde 6\n9  Hugo Alejandro Concha Cantú 4\n10             Ximena Medellín 4\n11          Horacio Vives Segl 3\n12         Javier Martín Reyes 1\n\n\n\nfinal %&gt;%\n    mutate(fecha = as_date(fecha)) %&gt;%\n    group_by(mes = month(fecha)) %&gt;%\n    count()\n\n# A tibble: 8 × 2\n# Groups:   mes [8]\n    mes     n\n  &lt;dbl&gt; &lt;int&gt;\n1     3     5\n2     4    12\n3     5     8\n4     6    16\n5     7     7\n6     8    11\n7     9     5\n8    10     6\n\n\nResulta interesante que el máximo de publicaciones es 9 y el mínimo es 1. Además, el mes con mayor número de notas fue junio.\n\nfinal %&gt;%\n    unnest_tokens(palabra, texto) %&gt;%\n    filter(!palabra %in% stopwords(\"es\")) %&gt;%\n    count(autor, palabra, sort = T) %&gt;%\n    group_by(autor) %&gt;%\n    mutate(prop = n / sum(n)) %&gt;%\n    top_n(7) %&gt;%\n    ggplot(aes(x = prop, y = palabra, fill = autor)) +\n    facet_wrap(. ~ autor, scales = \"free_y\") +\n    geom_bar(stat = \"identity\") +\n    theme_classic() +\n    theme(legend.position = \"blank\") +\n    labs(\n        x = \"\", y = \"\",\n        title = \"Proporción de palabras más frecuentes\",\n        subtitle = \"por autor\"\n    )\n\nSelecting by prop\n\n\n\n\n\n\n\n\n\nAhora bien, la gráfica anterior era solo por palabras más frecuentes. Pero, como sabemos hay autoras que tuvieron más publicaciones. Por esta razón utilicé el top 10 de palabras más frecuentes como proporción del total de palabras de cada autora. El outlier es Javier Martín Reyes porque tiene una sola publicación.\nY estas son las cosas sencillas que podemos lograr con un web scrapping y las herramientas que vamos acumulando. Por ejemplo, análisis de sentimientos! No hay que olvidar que la función para esto tarda más de lo normal. Entonces no desesperen.\n\ntext &lt;- final %&gt;%\n    unnest_tokens(palabra, texto) %&gt;%\n    filter(!palabra %in% stopwords(\"es\"))\n\ntext_nrc &lt;- get_nrc_sentiment(char_v = text$palabra, language = \"spanish\")\n\nbind_cols(text, text_nrc) %&gt;%\n    pivot_longer(\n        cols = 6:15\n    ) %&gt;%\n    group_by(name) %&gt;%\n    summarise(total = sum(value)) %&gt;%\n    ungroup() %&gt;%\n    mutate(name = reorder(name, total)) %&gt;%\n    ggplot(aes(x = name, y = total, fill = name)) +\n    geom_bar(stat = \"identity\") +\n    scale_fill_manual(\n        breaks = c(\"disgust\", \"surprise\", \"anger\", \"joy\", \"anticipation\", \"fear\", \"sadness\", \"trust\", \"positive\", \"negative\"),\n        values = c(\"#24D204\", \"#06CBBE\", \"#CB0606\", \"#FBFE00\", \"#FF9200\", \"#46BF5F\", \"#5479C3\", \"#01FF4C\", \"#FF00DC\", \"#000000\")\n    ) +\n    theme_classic() +\n    labs(\n        title = \"Análisis de sentimientos en todas las publicaciones\",\n        subtitle = \"Syuzhet\",\n        x = \"\", y = \"\"\n    ) +\n    theme(legend.position = \"blank\")\n\n\n\n\n\n\n\n\nTodo apunta a que las investigadoras involucradas en este proyecto confían en las decisiones tomadas por el Tribunal Electoral y el INE. Después de todo, son los organismos que deciden la política electoral en la práctica. A pesar de todo, aún hay confianza en las instituciones. Cualquier cosa mándenme un DM"
  },
  {
    "objectID": "posts/scrap/index.html#scrapping",
    "href": "posts/scrap/index.html#scrapping",
    "title": "Scrap! o como extraer info de páginas",
    "section": "",
    "text": "url &lt;- \"https://analisiselectoral2021.juridicas.unam.mx/publicaciones?page=\"\n\ndada &lt;- paste0(url, \"0\") # enlace con las publicciones más recientes\n\nComo ya revisé cuántas páginas había en ese portal, sé que van del 0 al 6. Sigo buscando un método para no tener que contarlo a mano, así que avísenme.\nAhora, lo que hay que hacer es entender cómo se organiza una página web. Hay personas mucho más hábiles que yo para eso, yo solo les sugiero que en la página que seleccionen den clic derecho en cualquier lado y seleccionen inspeccionar. Esto funciona si utilizas chrome.\nAhora, si ustedes como yo no tienen idea de páginas web, html y CSS… solo tienen que buscar lo que diga class y probar.\n\ntitulos &lt;- read_html(dada) %&gt;% # Con esta función hacemos que R \"lea\" la página\n    html_nodes(\".titulo-publicacion-l\") %&gt;% # Aquí seleccionamos el \"nodo\" o clase que queremos recuperar\n    html_text() %&gt;% # y con esto lo convertimos a texto\n    as_tibble() %&gt;%\n    rename(titulo = value)\n\nEste es un vector de texto, ¿se acuerdan de las primeras entradas y como una serie de vectores acomodados crean un dataframe? Pues aquí es donde rinde sus frutos entender la diferencia. Además, el scrapping funciona por posiciones, así que si la página está lógicamente construida podemos extraer sin problemas la información necesaria\n\nautor &lt;- read_html(dada) %&gt;%\n    html_nodes(\".autores\") %&gt;%\n    html_text() %&gt;%\n    as_tibble() %&gt;%\n    rename(autor = value)\n\nEntonces los títulos ya están, los autores ya están, pero qué pasa si quiero los enlaces a las notas? Bueno, es un poco más complicado, y no es tan general, pero puedes seleccionar más de un nodo y en lugar del texto, los atributos.\nAdemás, no podemos olvidar las fechas.\n\nenlaces &lt;- read_html(dada) %&gt;%\n    html_nodes(\".views-field-title-1 a\") %&gt;%\n    html_attr(\"href\") %&gt;%\n    as_tibble() %&gt;%\n    rename(enlaces = value)\n\nfechas &lt;- read_html(dada) %&gt;%\n    html_nodes(\".fuente-1 time\") %&gt;%\n    html_text() %&gt;%\n    as_tibble() %&gt;%\n    rename(fecha = value)\n\nVamos a tener todo en un olo data frame para poder consultarlo.\n\ndetalle &lt;- \"https://analisiselectoral2021.juridicas.unam.mx\"\n\ntabla &lt;- bind_cols(titulos, autor, enlaces) %&gt;%\n    mutate(\n        enlaces = paste0(detalle, enlaces)\n    )\n\nTachán!! Listo, un scrap sencillo pero poderoso. Sin embargo, hay muchas páginas. Cómo aún no me sé una manera de contarlas automáticamente, pero sé que son 7 páginas de publicaciones, pues vamos a hacer un loop, o mejor dicho un map.\n\nlista &lt;- map(\n    url,\n    ~ paste0(.x, seq(0, 6, by = 1))\n) %&gt;%\n    unlist()\nlista\n\n[1] \"https://analisiselectoral2021.juridicas.unam.mx/publicaciones?page=0\"\n[2] \"https://analisiselectoral2021.juridicas.unam.mx/publicaciones?page=1\"\n[3] \"https://analisiselectoral2021.juridicas.unam.mx/publicaciones?page=2\"\n[4] \"https://analisiselectoral2021.juridicas.unam.mx/publicaciones?page=3\"\n[5] \"https://analisiselectoral2021.juridicas.unam.mx/publicaciones?page=4\"\n[6] \"https://analisiselectoral2021.juridicas.unam.mx/publicaciones?page=5\"\n[7] \"https://analisiselectoral2021.juridicas.unam.mx/publicaciones?page=6\"\n\n\nEl primero que necesitamos es bastante sencillo, tenemos la dirección lista para pegarle los números. Como no la vamos a hacer a mano, hay que hacer algo. Yo opté por crearlo con un map, para que luego se convierta en lista y al momento de hacerle el unlist se convierte en caracteres. La otra opción sería crear un data frame con una columna de número de 0 al 6, luego pegar la columna url, pegar ambas, quitar lo que no sirve o seleccionar la nueva columna y transformarla a vector o en su defecto, utilizar dataframe$columna.\nSi se les ocurre otra manera, avísenme, que siempre se aprende algo nuevo.\n\ntitulos &lt;- map(\n    lista,\n    ~ read_html(.x) %&gt;%\n        html_nodes(\".titulo-publicacion-l\") %&gt;%\n        html_text() %&gt;%\n        as_tibble() %&gt;%\n        rename(titulo = value)\n) %&gt;%\n    bind_rows()\n\nautores &lt;- map(\n    lista,\n    ~ read_html(.x) %&gt;%\n        html_nodes(\".autores\") %&gt;%\n        html_text() %&gt;%\n        as_tibble() %&gt;%\n        rename(autor = value)\n) %&gt;%\n    bind_rows()\n\nenlaces &lt;- map(\n    lista,\n    ~ read_html(.x) %&gt;%\n        html_nodes(\".views-field-title-1 a\") %&gt;%\n        html_attr(\"href\") %&gt;%\n        as_tibble() %&gt;%\n        rename(enlaces = value)\n) %&gt;%\n    bind_rows()\n\nfechas &lt;- map(\n    lista,\n    ~ read_html(.x) %&gt;%\n        html_nodes(\".fuente-1 time\") %&gt;%\n        html_text() %&gt;%\n        as_tibble() %&gt;%\n        rename(fecha = value)\n) %&gt;%\n    bind_rows()\n\n\nfinal &lt;- cbind(titulos, autores, fechas, enlaces) %&gt;%\n    mutate(\n        enlaces = paste0(detalle, enlaces)\n    )\nhead(final)\n\n                                                                              titulo\n1                 La forma de una tensión: democracia directa, ciudadanos y partidos\n2     La crisis del modelo de comunicación política propiciada desde la presidencia.\n3                                                                    Estudia, macho…\n4                      Aprobación de los Lineamientos para la Revocatoria de Mandato\n5                                                             El “diezmo” de Texcoco\n6 La complejidad de la paridad en la integración del Congreso de la Ciudad de México\n                      autor      fecha\n1              Nicolás Loza 2021-10-14\n2      María Marván Laborde 2021-10-11\n3              Nicolás Loza 2021-10-07\n4        Flavia Freidenberg 2021-10-05\n5 Guadalupe Salmorán Villar 2021-10-04\n6            Karolina Gilas 2021-10-04\n                                                                  enlaces\n1 https://analisiselectoral2021.juridicas.unam.mx/detalle-publicacion/157\n2 https://analisiselectoral2021.juridicas.unam.mx/detalle-publicacion/155\n3 https://analisiselectoral2021.juridicas.unam.mx/detalle-publicacion/153\n4 https://analisiselectoral2021.juridicas.unam.mx/detalle-publicacion/151\n5 https://analisiselectoral2021.juridicas.unam.mx/detalle-publicacion/149\n6 https://analisiselectoral2021.juridicas.unam.mx/detalle-publicacion/147\n\n\nY listo!!! Tenemos una base de datos con los nombres de las publicaciones, autores, fechas y enlaces.\nPero… creo que le podemos sacar más jugo a esto… Por ejemplo, que tal si de una vez recuperamos los textos de las publicaciones? Que por qué? Por la gloria de Satán! Digo, porque podemos utilizar nuestras herramientas de análisis de texto y ver si hay cosas interesantes de esta manera, o hay que leer todo el texto para entenderlo."
  },
  {
    "objectID": "posts/scrap/index.html#scrapping-y-textos",
    "href": "posts/scrap/index.html#scrapping-y-textos",
    "title": "Scrap! o como extraer info de páginas",
    "section": "",
    "text": "Entonces, ¿cómo le hacemos? Ya tenemos la lista de enlaces\n\npublicaciones &lt;- map(\n    final$enlaces,\n    ~ read_html(.x) %&gt;%\n        html_nodes(\".col-12\") %&gt;% # Esta es la clase que buscamos\n        html_text() %&gt;%\n        .[2] %&gt;% # solo necesitamos el segundo elemento de la lista que arroja\n        as_tibble() %&gt;%\n        rename(texto = value) %&gt;%\n        mutate(enlaces = .x)\n) %&gt;% # aunque el scrapping funciona por posiciones, a veces me da miedo y le genero identificadores para unir los DF\n    bind_rows()\n\nfinal &lt;- left_join(final, publicaciones)\n\nJoining with `by = join_by(enlaces)`\n\n\nY con eso, hemos leído las 70 publicaciones. Pero, hay un pequeño problema: aparece el título, tema, autor, fecha, un disclaimer y una leyenda para descargar un archivo. Esto porque el scrapping depende mucho de como esté armada la página. Como utilizamos una clase que agrupa todo el texto, se incluyen estos elementos.\n\nlibrary(tm)\n\nWarning: package 'tm' was built under R version 4.2.3\n\n\nLoading required package: NLP\n\nlibrary(tidyr)\n\nWarning: package 'tidyr' was built under R version 4.2.3\n\nlibrary(ggplot2)\n\n\nAttaching package: 'ggplot2'\n\n\nThe following object is masked from 'package:NLP':\n\n    annotate\n\nlibrary(syuzhet)\n\nWarning: package 'syuzhet' was built under R version 4.2.3\n\nlibrary(tidytext)\n\nWarning: package 'tidytext' was built under R version 4.2.3\n\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\n\nIgual que en un par de post anteriores, este, este y este, necesitamos estas dos libraries para analizar los textos.\n\nfinal %&gt;%\n    unnest_tokens(palabra, texto) %&gt;%\n    filter(!palabra %in% stopwords(\"es\")) %&gt;%\n    count(palabra, sort = T) %&gt;%\n    mutate(palabra = reorder(palabra, n)) %&gt;%\n    top_n(20) %&gt;%\n    ggplot(aes(x = n, y = palabra)) +\n    geom_bar(stat = \"identity\") +\n    theme_classic() +\n    labs(\n        x = \"\", y = \"\",\n        title = \"Palabras más frecuentes\",\n        subtitle = \"En todas las publicaciones\"\n    )\n\nSelecting by n\n\n\n\n\n\n\n\n\n\nComo no es ninguna sorpresa, “INE” y “electoral” son las palabras más frecuentes en todas las publicaciones. Pero, tenemos manera de revisar el top 10 de cada autor. Sin embargo, antes, vamos a ver cuantas publicaciones tiene cada autor y las publicaciones por mes, nomás porque sí.\n\nfinal %&gt;%\n    count(autor, sort = T)\n\n                         autor n\n1               Karolina Gilas 9\n2           Flavia Freidenberg 8\n3      Juan Jesús Garza Onofre 8\n4       Luz María Cruz Parcero 7\n5                 Nicolás Loza 7\n6        Roberto Lara Chagoyán 7\n7    Guadalupe Salmorán Villar 6\n8         María Marván Laborde 6\n9  Hugo Alejandro Concha Cantú 4\n10             Ximena Medellín 4\n11          Horacio Vives Segl 3\n12         Javier Martín Reyes 1\n\n\n\nfinal %&gt;%\n    mutate(fecha = as_date(fecha)) %&gt;%\n    group_by(mes = month(fecha)) %&gt;%\n    count()\n\n# A tibble: 8 × 2\n# Groups:   mes [8]\n    mes     n\n  &lt;dbl&gt; &lt;int&gt;\n1     3     5\n2     4    12\n3     5     8\n4     6    16\n5     7     7\n6     8    11\n7     9     5\n8    10     6\n\n\nResulta interesante que el máximo de publicaciones es 9 y el mínimo es 1. Además, el mes con mayor número de notas fue junio.\n\nfinal %&gt;%\n    unnest_tokens(palabra, texto) %&gt;%\n    filter(!palabra %in% stopwords(\"es\")) %&gt;%\n    count(autor, palabra, sort = T) %&gt;%\n    group_by(autor) %&gt;%\n    mutate(prop = n / sum(n)) %&gt;%\n    top_n(7) %&gt;%\n    ggplot(aes(x = prop, y = palabra, fill = autor)) +\n    facet_wrap(. ~ autor, scales = \"free_y\") +\n    geom_bar(stat = \"identity\") +\n    theme_classic() +\n    theme(legend.position = \"blank\") +\n    labs(\n        x = \"\", y = \"\",\n        title = \"Proporción de palabras más frecuentes\",\n        subtitle = \"por autor\"\n    )\n\nSelecting by prop\n\n\n\n\n\n\n\n\n\nAhora bien, la gráfica anterior era solo por palabras más frecuentes. Pero, como sabemos hay autoras que tuvieron más publicaciones. Por esta razón utilicé el top 10 de palabras más frecuentes como proporción del total de palabras de cada autora. El outlier es Javier Martín Reyes porque tiene una sola publicación.\nY estas son las cosas sencillas que podemos lograr con un web scrapping y las herramientas que vamos acumulando. Por ejemplo, análisis de sentimientos! No hay que olvidar que la función para esto tarda más de lo normal. Entonces no desesperen.\n\ntext &lt;- final %&gt;%\n    unnest_tokens(palabra, texto) %&gt;%\n    filter(!palabra %in% stopwords(\"es\"))\n\ntext_nrc &lt;- get_nrc_sentiment(char_v = text$palabra, language = \"spanish\")\n\nbind_cols(text, text_nrc) %&gt;%\n    pivot_longer(\n        cols = 6:15\n    ) %&gt;%\n    group_by(name) %&gt;%\n    summarise(total = sum(value)) %&gt;%\n    ungroup() %&gt;%\n    mutate(name = reorder(name, total)) %&gt;%\n    ggplot(aes(x = name, y = total, fill = name)) +\n    geom_bar(stat = \"identity\") +\n    scale_fill_manual(\n        breaks = c(\"disgust\", \"surprise\", \"anger\", \"joy\", \"anticipation\", \"fear\", \"sadness\", \"trust\", \"positive\", \"negative\"),\n        values = c(\"#24D204\", \"#06CBBE\", \"#CB0606\", \"#FBFE00\", \"#FF9200\", \"#46BF5F\", \"#5479C3\", \"#01FF4C\", \"#FF00DC\", \"#000000\")\n    ) +\n    theme_classic() +\n    labs(\n        title = \"Análisis de sentimientos en todas las publicaciones\",\n        subtitle = \"Syuzhet\",\n        x = \"\", y = \"\"\n    ) +\n    theme(legend.position = \"blank\")\n\n\n\n\n\n\n\n\nTodo apunta a que las investigadoras involucradas en este proyecto confían en las decisiones tomadas por el Tribunal Electoral y el INE. Después de todo, son los organismos que deciden la política electoral en la práctica. A pesar de todo, aún hay confianza en las instituciones. Cualquier cosa mándenme un DM"
  },
  {
    "objectID": "posts/sip-3-anios-reconstruccion/index.html",
    "href": "posts/sip-3-anios-reconstruccion/index.html",
    "title": "A 3 años del sismo en la CDMX",
    "section": "",
    "text": "¡Bienvenidas! Dejé esto abandonado por algún tiempo, la pandemia me dejo todo revuelto y apenas he retomado muchas de las actividades que mantenían mi cordura. Ahora, quiero escribir sobre algo que hice en el trabajo, y un par de trucos para empezar a usar purrr::map() y facilitarse la vida con tareas repetitivas.\nActualmente, trabajo en el Instituto de Transparencia, Acceso a la Información Pública, Protección de Datos Personales y Rendición de Cuentas de la Ciudad de México (INFO CDMX). Una de mis tareas es procesar datos estadísticos de las solicitudes, y a principios de este mes (septiembre) se realizó el 2° Coloquio Internacional por una reconstrucción abierta en la CDMX en donde se abrieron datos sobre solicitudes referentes al sismo del 19 de septiembre de 2017.\nEntonces, vamos a utilizar las bases de datos disponibles. Van a la sección de multimedia y van a descargar el archivo zip que dice repositorio y lo van a descomprimir. Como es un archivo zip, no deberían tener ningún problema, si no pueden descargar winrar (esto no es un comercial, pero me parece el más útil).\nEn el archivo van a encontrar:\n\nUn archivo con todas las solicitudes.\nTres archivos con las solicitudes por año. Es decir, un archivo con todas las solicitudes de 2017, 2018 y 2019.\nTres carpetas con los archivos individuales por año. En este caso, cada carpeta tiene los archivos de las dependencias e instituciones que recibieron solicitudes. Por ejemplo, Delegación Benito Juárez-2017.xlsx.\n\nEl origen de estos datos es de las solicitudes de información realizadas durante el periodo registrado, así como la integración de la información por los sujetos obligados (nombre para las instituciones que reciben y ejercen recursos públicos de manera sistemática, desde secretarías hasta sindicatos). Entonces, además de poder observar los textos de las solicitudes, podemos acceder a algunos datos socio demográficos. Y ahora sí, con el código :D\n\n\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(purrr)\n\nWarning: package 'purrr' was built under R version 4.2.3\n\nlibrary(scales)\n\n\nAttaching package: 'scales'\n\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nlibrary(readxl)\nlibrary(stringr)\n\nWarning: package 'stringr' was built under R version 4.2.3\n\nlibrary(ggplot2)\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\n\nComo siempre, lo primero es “llamar” los paquetes. Y luego, definir los “directorios”, es decir las carpetas donde tenemos los archivos que vamos a trabajar. Por eso es muy importante que tengan orden en sus carpetas, sino puede ser muy complicado trabajar.\nIntenté hacerlo con setwd(), que es la manera base, pero la verdad era demasiado escribir y copiar. Si quieren intentarlo tendrían que poner algo así: setwd(“/Users/equipo/carpeta/Bases de SIP sobre reconstrucción en la CDMX”).\nPero yo, como siempre, haré que mis directorios sean objetos de r:\n\ninput &lt;- \"D:/dhumb/Documents/projects/data_blog/Bases de SIP sobre reconstrucción en la CDMX\"\nlist.files(input)\n\n[1] \"2017\"                                                                \n[2] \"2017 final.xlsx\"                                                     \n[3] \"2018\"                                                                \n[4] \"2018 final.xlsx\"                                                     \n[5] \"2019\"                                                                \n[6] \"2019 final.xlsx\"                                                     \n[7] \"2020.09.03_Nota-Criterios de_Bases SIP-Reconstrucción 2017-2019.docx\"\n[8] \"Bases de SIP sobre reconstrucción en la CDMX.rar\"                    \n[9] \"Reconstruccion consolidada.xlsx\"                                     \n\n\nPuse un punto “.” porque para publicar esto r siempre me pone un directorio default, entonces el punto significa lo mismo que copiar este directorio. Y quiero que exploremos esta manera de utilizar directorios.\nAhora, podemos hacer varias cosas: dado que en la carpeta que descomprimimos viene un único archivo con todas las solicitudes de información, obviamente sería más fácil trabajar así. Pero, no aprenderíamos a trabajar con múltiples archivos al mismo tiempo.\nEntonces, vamos a utilizar las carpetas con los archivos individuales. De este modo, podríamos “leer” cada archivo de manera individual de la siguiente manera:\n\narchivo1 &lt;- read_excel(path = paste0(input, \"/2017/Delegación Álvaro Obregón-2017.xlsx\"))\nlist.files(paste(input, \"2017\", sep = \"/\"))\n\n [1] \"Delegación Álvaro Obregón-2017.xlsx\"                                                  \n [2] \"Delegación Azcapotzalco-2017.xlsx\"                                                    \n [3] \"Delegación Benito Juárez-2017.xlsx\"                                                   \n [4] \"Delegación Coyoacán-2017.xlsx\"                                                        \n [5] \"Delegación Cuajimalpa de Morelos-2017.xlsx\"                                           \n [6] \"Delegación Cuauhtémoc-2017.xlsx\"                                                      \n [7] \"Delegación Gustavo A. Madero-2017.xlsx\"                                               \n [8] \"Delegación Iztacalco-2017.xlsx\"                                                       \n [9] \"Delegación Iztapalapa-2017.xlsx\"                                                      \n[10] \"Delegación La Magdalena Contreras-2017.xlsx\"                                          \n[11] \"Delegación Miguel Hidalgo-2017.xlsx\"                                                  \n[12] \"Delegación Milpa Alta-2017.xlsx\"                                                      \n[13] \"Delegación Tláhuac-2017.xlsx\"                                                         \n[14] \"Delegación Tlalpan-2017.xlsx\"                                                         \n[15] \"Delegación Venustiano Carranza-2017.xlsx\"                                             \n[16] \"Delegación Xochimilco-2017.xlsx\"                                                      \n[17] \"Instituto de Vivienda del Distrito Federal-2017.xlsx\"                                 \n[18] \"Instituto Local de la Infraestructura Física Educativa del Distrito Federal-2017.xlsx\"\n[19] \"Instituto para la Seguridad de las Construcciones en el Distrito Federal-2017.xlsx\"   \n[20] \"Jefatura de Gobierno del Distrito Federal-2017.xlsx\"                                  \n[21] \"Secretaría de Desarrollo Urbano y Vivienda-2017.xlsx\"                                 \n[22] \"Secretaría de Educación-2017.xlsx\"                                                    \n[23] \"Secretaría de Obras y Servicios-2017.xlsx\"                                            \n\n\nLo primero que podemos notar es que son 23 archivos para el año 2017… Entonces, cargar cada archivo, sabiendo que tienen la misma estructura, es poco eficiente, especialmente si pensamos que todavía nos faltan los datos de 2018 y 2019.\n\nlist.files(paste(input, \"2018\", sep = \"/\"))\n\n [1] \"Comisión para la Reconstrucción-2018.xlsx\"                                                                                           \n [2] \"Comisión para la Reconstrucción, Recuperación y Transformación de la Ciudad de México, en una CDMX cada vez más resiliente-2018.xlsx\"\n [3] \"Delegación Álvaro Obregón-2018.xlsx\"                                                                                                 \n [4] \"Delegación Azcapotzalco-2018.xlsx\"                                                                                                   \n [5] \"Delegación Benito Juárez-2018.xlsx\"                                                                                                  \n [6] \"Delegación Coyoacán-2018.xlsx\"                                                                                                       \n [7] \"Delegación Cuajimalpa de Morelos-2018.xlsx\"                                                                                          \n [8] \"Delegación Cuauhtémoc-2018.xlsx\"                                                                                                     \n [9] \"Delegación Gustavo A. Madero-2018.xlsx\"                                                                                              \n[10] \"Delegación Iztacalco-2018.xlsx\"                                                                                                      \n[11] \"Delegación Iztapalapa-2018.xlsx\"                                                                                                     \n[12] \"Delegación La Magdalena Contreras-2018.xlsx\"                                                                                         \n[13] \"Delegación Miguel Hidalgo-2018.xlsx\"                                                                                                 \n[14] \"Delegación Milpa Alta-2018.xlsx\"                                                                                                     \n[15] \"Delegación Tláhuac-2018.xlsx\"                                                                                                        \n[16] \"Delegación Tlalpan-2018.xlsx\"                                                                                                        \n[17] \"Delegación Venustiano Carranza-2018.xlsx\"                                                                                            \n[18] \"Delegación Xochimilco-2018.xlsx\"                                                                                                     \n[19] \"Instituto de Vivienda del Distrito Federal-2018.xlsx\"                                                                                \n[20] \"Instituto Local de la Infraestructura Física Educativa del Distrito Federal-2018.xlsx\"                                               \n[21] \"Instituto para la Seguridad de las Construcciones en el Distrito Federal-2018.xlsx\"                                                  \n[22] \"Jefatura de Gobierno del Distrito Federal-2018.xlsx\"                                                                                 \n[23] \"Secretaría de Desarrollo Urbano y Vivienda-2018.xlsx\"                                                                                \n[24] \"Secretaría de Educación-2018.xlsx\"                                                                                                   \n[25] \"Secretaría de Obras y Servicios-2018.xlsx\"                                                                                           \n\n\n\nlist.files(paste(input, \"2019\", sep = \"/\"))\n\n [1] \"Alcaldía Álvaro Obregón-2019.xlsx\"                                                                                                   \n [2] \"Alcaldía Azcapotzalco-2019.xlsx\"                                                                                                     \n [3] \"Alcaldía Benito Juárez-2019.xlsx\"                                                                                                    \n [4] \"Alcaldía Coyoacán-2019.xlsx\"                                                                                                         \n [5] \"Alcaldía Cuajimalpa de Morelos-2019.xlsx\"                                                                                            \n [6] \"Alcaldía Cuauhtémoc-2019.xlsx\"                                                                                                       \n [7] \"Alcaldía Gustavo A. Madero-2019.xlsx\"                                                                                                \n [8] \"Alcaldía Iztacalco-2019.xlsx\"                                                                                                        \n [9] \"Alcaldía Iztapalapa-2019.xlsx\"                                                                                                       \n[10] \"Alcaldía La Magdalena Contreras-2019.xlsx\"                                                                                           \n[11] \"Alcaldía Miguel Hidalgo-2019.xlsx\"                                                                                                   \n[12] \"Alcaldía Milpa Alta-2019.xlsx\"                                                                                                       \n[13] \"Alcaldía Tláhuac-2019.xlsx\"                                                                                                          \n[14] \"Alcaldía Tlalpan-2019.xlsx\"                                                                                                          \n[15] \"Alcaldía Venustiano Carranza-2019.xlsx\"                                                                                              \n[16] \"Alcaldía Xochimilco-2019.xlsx\"                                                                                                       \n[17] \"Comisión para la Reconstrucción-2019.xlsx\"                                                                                           \n[18] \"Comisión para la Reconstrucción, Recuperación y Transformación de la Ciudad de México, en una CDMX cada vez más resiliente-2019.xlsx\"\n[19] \"Instituto de Vivienda de la Ciudad de México-2019.xlsx\"                                                                              \n[20] \"Instituto Local de la Infraestructura Física Educativa de la Ciudad de México-2019.xlsx\"                                             \n[21] \"Instituto para la Seguridad de las Construcciones en la Ciudad de México-2019.xlsx\"                                                  \n[22] \"Jefatura de Gobierno de la Ciudad de México-2019.xlsx\"                                                                               \n[23] \"Secretaría de Administración y Finanzas-2019.xlsx\"                                                                                   \n[24] \"Secretaría de Desarrollo Urbano y Vivienda-2019.xlsx\"                                                                                \n[25] \"Secretaría de Educación, Ciencia, Tecnología e Innovación-2019.xlsx\"                                                                 \n[26] \"Secretaría de Gestión Integral de Riesgos y Protección Civil-2019.xlsx\"                                                              \n[27] \"Secretaría de Inclusión y Bienestar Social-2019.xlsx\"                                                                                \n[28] \"Secretaría de Obras y Servicios-2019.xlsx\"                                                                                           \n\n\nParece intimidante, ¿no? Leer 74 archivos para empezar a trabajar… Pero para eso tenemos purrr.\n\n\n\nEste paquete nos permite realizar tareas de Functional programming una palabra elegante para decir realizar tareas repetitivas de manera más rápida y eficiente. Pueden consultar la documentación aquí.\n\nprimer &lt;- list.files(paste(input, \"2017\", sep = \"/\"))\n\nprimer_e &lt;- map(\n    primer,\n    ~ read_excel(path = paste(input, \"2017\", .x, sep = \"/\"))\n)\n# View(primer_e)\n\nCon este código ya abrimos los 23 archivos de excel :D\nPero, aún no podemos usarlos como base de datos :(\nEsto se debe a que map es una función especial de purrr. Ya vimos lo que hace, pero no sabemos por qué.\nmap nos permite aplicar una función a todos los elementos de una lista o vector que nosotros le proporcionemos. En este caso, utilicé list.files para crear un objeto llamado primer.\nLuego, le decimos que función queremos que aplique. Como queremos que learchivos en formato xlsx (exceles), le ponemos read_excel. Y aquí vamos a repasar todo. Esta función tiene un montón de parámetros para leer exceles. Pero por ahora nos importa uno: donde está el archivo path = . Aquí utilicé una función paste que sirve para pegar strings lo que nos permite abrir los archivos de Excel.\n\ninput, como mencioné, es la carpeta con todos los datos descomprimidos.\n2017 es la carpeta del año con los archivos individuales\n.x es un argumento de la función map es el i-esímo objeto al que le aplicaremos la función. Como espero hayas notado, primer es el objeto con la lista de archivos excel dentro de la carpeta, por eso necesito el paste para que vaya cambiando. En otras palabras, el .x es la variable que irá cambiando hasta que termine de leer los archivos.\n\nAhora lo que queremos es poder utilizar los datos como siempre, en un data frame.\n\nprimer_f &lt;- bind_rows(primer_e)\n\ndim(primer_f)\n\n[1] 2541   40\n\n\nComo sabemos que todo tiene la misma estructura, podemos combinar los archivos por renglones. Estamos pegando un archivo debajo de otro, debajo de otro y así, siempre y cuando tengan los mismos encabezados. Esto último es fundamental porque bind_rows es un función de dplyr y si no tienen los mismos encabezados y dimensiones no podríamos hacerlo. No es como su “primo” cbind de r base, que solo necesita que tenga el mismo número de columnas y lo une como esté. A veces la utilizaremos, pero necesitamos estar seguras de cómo y cuándo.\nSólo falta hacer lo mismo para los otros años:\n\nsegundo &lt;- list.files(paste(input, \"2018\", sep = \"/\"))\n\nsegundo_e &lt;- map(\n    segundo,\n    ~ read_excel(path = paste(input, \"2018\", .x, sep = \"/\"))\n)\n\nsegundo_f &lt;- bind_rows(segundo_e)\n\ndim(segundo_f)\n\n[1] 3241   40\n\ntercer &lt;- list.files(paste(input, \"2019\", sep = \"/\"))\n\ntercer_e &lt;- map(\n    tercer,\n    ~ read_excel(path = paste(input, \"2019\", .x, sep = \"/\"))\n)\n\ntercer_f &lt;- bind_rows(tercer_e)\n\ndim(tercer_f)\n\n[1] 1717   40\n\n\nEn el caso de 2018, les va a salir un error, y es que el nombre del primer archivo es exageradamente largo: “Comisión para la Reconstrucción, Recuperación y Transformación de la Ciudad de México, en una CDMX cada vez más resiliente-2018.xlsx” por eso hay que cambiarlo a mano en nuestra carpeta. A map no le importa los nombres de los archivos, pero sí la longitud de los strings. Si creen que el nombre es demasiado largo, tal vez tengan razón. Porque lo mismo pasa para el 2019: “Comisión para la Reconstrucción, Recuperación y Transformación de la Ciudad de México, en una CDMX cada vez más resiliente-2019.xlsx”\nY todas tienen 40 columnas, entonces, el siguiente paso es más fácil. Ahora tenemos 3 archivos, uno correspondiente a cada año. Pero, generalmente, es más fácil tener todo dentro de una sola base de datos.\n\ndata &lt;- bind_rows(primer_f, segundo_f, tercer_f)\n\ndim(data)\n\n[1] 7499   40\n\n\n\n\n\nAhora tenemos una base de datos con 6,819 renglones y 40 columnas. Y con esto podemos ponernos a hacer algunas gráficas.\nPero, hay un pequeño, pequeñísimo problema… Los nombres de las columnas.\n\nnames(data)\n\n [1] \"No.\"                                                                                                                  \n [2] \"Sujeto_N\"                                                                                                             \n [3] \"Sujeto\"                                                                                                               \n [4] \"Organo_N\"                                                                                                             \n [5] \"Clave\"                                                                                                                \n [6] \"Propio\"                                                                                                               \n [7] \"( A )\\r\\n\\r\\nFolio\"                                                                                                   \n [8] \"( B )\\r\\n\\r\\nFecha de presentación de la solicitud\\r\\n\\r\\ndd/mm/aaaa\"                                                 \n [9] \"( C )\\r\\n\\r\\nMedio por el que se presentó la solicitud\"                                                               \n[10] \"( D )\\r\\n\\r\\nInformación objeto de la solicitud \\r\\n\\r\\n(PROTEGER EN TODO MOMENTO LOS DATOS PERSONALES)\"              \n[11] \"( E )\\r\\n\\r\\nN° de preguntas que comprende la solicitud\"                                                              \n[12] \"( F )\\r\\n\\r\\nTemática de la información requerida\"                                                                    \n[13] \"( F_1 )\\r\\n\\r\\nÁrea de interés del Solictante\"                                                                        \n[14] \"( G )\\r\\n\\r\\nLa información solicitada fue de oficio\"                                                                 \n[15] \"( H )\\r\\n\\r\\nEstado en que se encontraba la solicitud\"                                                                \n[16] \"prevencion_solicitante\"                                                                                               \n[17] \"( I_1 )\\r\\n\\r\\nFecha en la que el solicitante atendió la prevención\"                                                  \n[18] \"( I_2 )\\r\\n\\r\\n¿La solicitud de información pública fue prevenida total o parcialmente?\"                              \n[19] \"( I_3 )\\r\\n\\r\\nNúmero de preguntas fueron prevenidas\"                                                                 \n[20] \"( J )\\r\\n\\r\\n¿Se notificó al solicitante ampliación de plazo para entregar la información?\"                           \n[21] \"( K )\\r\\n\\r\\nModalidad de repuesta\"                                                                                   \n[22] \"( L_1 ) \\r\\n\\r\\nTotal de Entes públicos a los que se turnó la solicitud\"                                              \n[23] \"( L_2 ) \\r\\n\\r\\nEnte Público al \\r\\nque se turnó la solicitud\"                                                        \n[24] \"( M )\\r\\n\\r\\n¿Se entregó o se envió por algún medio la información al solicitante?\"                                   \n[25] \"( N )\\r\\n\\r\\nPara la entrega de información, ¿se le requirió al solicitante algún monto por concepto de reproducción?\"\n[26] \"( O )\\r\\n\\r\\nMonto total requerido por concepto de reproducción\"                                                      \n[27] \"( P )\\r\\n\\r\\nMedio por el que se puso a disposición la información solicitada\"                                        \n[28] \"( Q )\\r\\n\\r\\nFecha en que se notificó la respuesta o se turnó la solicitud\\r\\n\\r\\ndd/mm/aaaa\"                         \n[29] \"( R )\\r\\n\\r\\nMedio por el que se notificó la respuesta\"                                                               \n[30] \"( S )\\r\\n\\r\\nDías HÁBILES  transcurridos entre la recepción de la solicitud y la notificación de respuesta\"           \n[31] \"( T )\\r\\n\\r\\nNo. de Servidores Públicos directamente involucrados en la respuesta de la solicitud\"                    \n[32] \"( U )\\r\\n\\r\\nSexo del solicitante\"                                                                                    \n[33] \"( V )\\r\\n\\r\\nEdad del solicitante\"                                                                                    \n[34] \"( W )\\r\\n\\r\\nOcupación del solicitante\"                                                                               \n[35] \"( X )\\r\\n\\r\\nEscolaridad del solicitante\"                                                                             \n[36] \"( Y )\\r\\n\\r\\nEstado de la República Mexicana o país que corresponde a la dirección que registró el solicitante\"       \n[37] \"( Z )\\r\\n\\r\\nObservaciones\"                                                                                           \n[38] \"mes\"                                                                                                                  \n[39] \"year\"                                                                                                                 \n[40] \"clasificacion\"                                                                                                        \n\n\nAquí, sí se ven las diagonales inversas, si lo abren en excel verán que está en varios renglones, pero esto es muy difícil de trabajar en r. Para solucionar esto, vamos a cambiarle los nombres a todas las variables.\n\nnombres &lt;- c(\n    \"No.\",\n    \"Sujeto_N\",\n    \"Sujeto\",\n    \"Organo_N\",\n    \"clave\",\n    \"propio\",\n    \"Folio\",\n    \"fecha_presentacion\",\n    \"Medio_presento\",\n    \"Informacion_objeto\",\n    \"Preguntas_solicitud\",\n    \"Tematica_solicitud\",\n    \"Area_interes\",\n    \"info_de_oficio\",\n    \"Estado_info\",\n    \"prevencion_solicitante\",\n    \"fecha_prevencion\",\n    \"solicitud_prevenida\",\n    \"preguntas_prevenidas\",\n    \"notificar_ampliacion\",\n    \"modalidad_respuesta\",\n    \"total_entes_turnados\",\n    \"ente_turnado\",\n    \"info_entregada\",\n    \"costo_reproduccion\",\n    \"monto_reproduccion\",\n    \"medio_disposicion_info\",\n    \"fecha_notificacion\",\n    \"medio_notificacion\",\n    \"dias_transcurridos_recepcion_notificacion\",\n    \"Servidores_publicos_involucrados\",\n    \"sexo\",\n    \"edad\",\n    \"ocupacion\",\n    \"escolaridad\",\n    \"entidad_federativa\",\n    \"observaciones\",\n    \"mes\",\n    \"year\",\n    \"clasificacion\"\n)\n\nnames(data) &lt;- nombres\n\nPuse cada nombre en un reglón y un espacio cada 5 nombres, para no perderme, si se saben otra manera avísenme :P\nAdemás de cambiarle el nombre, vamos a utilizar la forma en que se procesan los datos: cambiar categorías, agrupar, crear nuevas variables, etc. Esto lo voy a hacer porque estoy familiarizado con este procesamiento. Creo que el código es autoexplicativo, pero si tienen alguna duda mandenme un DM en twitter.\n\ndata &lt;- data %&gt;%\n    mutate(semana = week(fecha_presentacion)) %&gt;%\n    group_by(year, Sujeto_N, semana) %&gt;%\n    distinct(Informacion_objeto, .keep_all = T) %&gt;%\n    ungroup() %&gt;%\n    mutate(\n        clasificacion = str_replace_all(\n            clasificacion,\n            c(\n                \"daños\" = \"Daños\", \"evaluacion\" = \"Evaluación\",\n                \"fondos\" = \"Fondos\", \"legalidad\" = \"Legalidad\",\n                \"prevencion\" = \"Prevención\", \"reconstruccion\" = \"Reconstrucción\",\n                \"respuesta al sismo\" = \"Respuesta al sismo\"\n            )\n        ),\n        Tematica_solicitud = ifelse(str_detect(Tematica_solicitud, \"Otros\") == T,\n            \"Otros\",\n            ifelse(Tematica_solicitud == \"Datos Personales\",\n                \"Otros\", Tematica_solicitud\n            )\n        ),\n        modalidad_respuesta_2 = ifelse(str_detect(modalidad_respuesta, \"Aceptada\") == T,\n            \"Aceptada\",\n            ifelse(str_detect(modalidad_respuesta, \"restringido\") == T,\n                \"Acceso restringido\", modalidad_respuesta\n            )\n        ),\n        edad = as.numeric(edad),\n        grupo_edad = ifelse(edad &lt;= 19, \"Hasta 19 años\",\n            ifelse(edad &gt; 19 & edad &lt; 30, \"De 20 a 29 años\",\n                ifelse(edad &gt;= 30 & edad &lt; 40, \"De 30 a 39 años\",\n                    ifelse(edad &gt;= 40 & edad &lt; 50, \"De 40 a 49 años\",\n                        ifelse(edad &gt;= 50 & edad &lt; 60, \"De 50 a 59 años\",\n                            ifelse(edad &gt;= 60 & edad &lt; 70, \"De 60 a 69 años\",\n                                ifelse(edad &gt;= 70, \"70 o mas años\", edad)\n                            )\n                        )\n                    )\n                )\n            )\n        ),\n        grupo_edad = factor(grupo_edad, levels = c(\n            \"Hasta 19 años\", \"De 20 a 29 años\", \"De 30 a 39 años\",\n            \"De 40 a 49 años\", \"De 50 a 59 años\", \"De 60 a 69 años\",\n            \"70 o mas años\"\n        )),\n        escolaridad = str_replace_all(escolaridad, c(\n            \"Bachillerato o carrera técnica\" = \"Bachillerato\",\n            \"Bachillerato\" = \"Bachillerato o carrera técnica\",\n            \"Maestría o Doctorado\" = \"Maestría o doctorado\"\n        )),\n        ocupacion = str_replace_all(ocupacion, c(\n            \"Otros - Amas de Casa\" = \"Hogar\",\n            \"Otros - Organizaciones No Gubernamentales Internacionales\" = \"ONG\",\n            \"Otros - Organizaciones No Gubernamentales Nacionales\" = \"ONG\",\n            \"Otros - Asociación política\" = \"Asociación política\",\n            \"Servidor Público\" = \"Servicio público\",\n            \"Otros - Comerciante\" = \"Comercio\",\n            \"Otros - Empleado u obrero\" = \"Empleada/o u obrera/o\",\n            \"Empleado u obrero\" = \"Empleada/o u obrera/o\"\n        )),\n        ocupacion = ifelse(str_detect(ocupacion, \"Académico\") == T, \"Académico o estudiante\",\n            ifelse(str_detect(ocupacion, \"Empresarial\") == T, \"Empresa\",\n                ifelse(str_detect(ocupacion, \"Gubernamental\") == T, \"Servicio público\",\n                    ifelse(str_detect(ocupacion, \"omunicación\") == T, \"Medios de comunicación\",\n                        ifelse(str_detect(ocupacion, \"Otro\") == T, \"Otro\", ocupacion)\n                    )\n                )\n            )\n        ),\n        Organo_N = str_replace_all(Organo_N, c(\n            \"1\" = \"Administración Pública Central\",\n            \"2\" = \"Desconcentrados y Paraestales\",\n            \"3\" = \"Alcaldías\",\n            \"4\" = \"Judicial\",\n            \"5\" = \"Legislativo\",\n            \"6\" = \"Autónomo\",\n            \"7\" = \"Partidos Políticos\",\n            \"8\" = \"Sindicatos\"\n        )),\n        Preguntas_solicitud = as.numeric(Preguntas_solicitud),\n        preguntas_prevenidas = as.numeric(preguntas_prevenidas),\n        total_entes_turnados = as.numeric(total_entes_turnados),\n        info_entregada_2 = ifelse(str_detect(info_entregada, \"No\"), \"No\",\n            ifelse(str_detect(info_entregada, \"Si\"),\n                \"S?\", info_entregada\n            )\n        ),\n        dias_transcurridos_recepcion_notificacion =\n            as.numeric(dias_transcurridos_recepcion_notificacion),\n        Servidores_publicos_involucrados = as.numeric(Servidores_publicos_involucrados),\n        sexo = str_replace_all(sexo, c(\"Femenino\" = \"Mujeres\", \"Masculino\" = \"Hombres\"))\n    )\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `preguntas_prevenidas = as.numeric(preguntas_prevenidas)`.\nCaused by warning:\n! NAs introduced by coercion\n\ndim(data)\n\n[1] 5168   44\n\n\nLo que me gustaría enfatizar son las primeras 5 líneas de código. Yo revise esta base de datos y sé que hay muchas solicitudes repetidas. Pero, no puedo descartarlas solo por el hecho de estar repetidas. Quizás una persona estuvo realizando la misma solicitud sistemáticamente cada semana, o quizás a una persona se le fue el internet al terminar y realizó exactamente la misma solicitud. Por esa razón, y siguiendo los criterios del Natalia Torres y Guillermo Cejudo para que solo se quede una solicitud con el mismo texto a la semana. Es decir, si es idéntico el texto de dos solicitudes con folio diferentes, y se presentó en la misma semana, solo se contará la más antigua.\n\ncolores &lt;- c(\n    \"Daños\" = \"#ae3a3d\", \"Evaluación\" = \"#fc8d33\",\n    \"Fondos\" = \"#faef59\", \"Legalidad\" = \"#bcfa3d\",\n    \"Prevención\" = \"#4fc6c4\", \"Reconstrucción\" = \"#FF0066\",\n    \"Respuesta al sismo\" = \"#6600cc\"\n)\n\nCódigos de colores para que todas las gráficas estén uniformes.\n\ndata %&gt;%\n    group_by(year) %&gt;%\n    mutate(tyear = n()) %&gt;%\n    group_by(year, clasificacion, tyear) %&gt;%\n    summarise(tclas = n()) %&gt;%\n    ungroup() %&gt;%\n    mutate(porc = tclas / tyear) %&gt;%\n    ggplot(aes(x = year, y = porc, fill = clasificacion)) +\n    geom_bar(position = \"dodge\", stat = \"identity\") +\n    scale_y_continuous(labels = percent_format()) +\n    scale_fill_manual(values = colores) +\n    theme(legend.position = \"bottom\") +\n    theme_classic() +\n    labs(\n        title = \"Solicitudes por tema\",\n        subtitle = \"Dividido por año\",\n        x = \"\", y = \"\", fill = \"Clasificación\",\n        caption = \"Incluye personas que no proporcionaron información sociodemográfica.\\nTotal de observaciones = 5,168\"\n    )\n\n`summarise()` has grouped output by 'year', 'clasificacion'. You can override\nusing the `.groups` argument.\n\n\n\n\n\n\n\n\n\nAhora, aquí vemos que las solicitudes se concentran en un par de clasificaciones y R lo ajusta al tamaño de la pantalla. Pero acabo de leer un librito que les recomiendo mucho How charts lie: Getting Smarter about Visual Information sobre como entender mejor las gráficas y diseñarlas. En este sentido, quiero ver como se ve cuando el límite es 100%\n\ndata %&gt;%\n    group_by(year) %&gt;%\n    mutate(tyear = n()) %&gt;%\n    group_by(year, clasificacion, tyear) %&gt;%\n    summarise(tclas = n()) %&gt;%\n    ungroup() %&gt;%\n    mutate(porc = tclas / tyear) %&gt;%\n    ggplot(aes(x = year, y = porc, fill = clasificacion)) +\n    geom_bar(position = \"dodge\", stat = \"identity\") +\n    ylim(0, 1) +\n    scale_fill_manual(values = colores) +\n    theme(legend.position = \"bottom\") +\n    theme_classic() +\n    labs(\n        title = \"Solicitudes por tema\",\n        subtitle = \"Dividido por año\",\n        x = \"\", y = \"\", fill = \"Clasificación\",\n        caption = \"Incluye personas que no proporcionaron información sociodemográfica.\\nTotal de observaciones = 5,168\"\n    )\n\n`summarise()` has grouped output by 'year', 'clasificacion'. You can override\nusing the `.groups` argument.\n\n\n\n\n\n\n\n\n\nAquí ya no pude poner el eje “y” como me hubiera gustado, pero la idea es muliplicar la leyenda por 100 para convertirlo en porcentaje.\nPodemos darnos cuenta de que poniendo como límite el 100 pierde todo el impacto la gráfica. Por lo que dejarla acotada hasta el 40% nos da una mejor visión para comparar entre categorías. Jugar con las gráficas siempre nos da perspectiva.\n\nnrow(data %&gt;%\n    filter(!is.na(sexo)))\n\n[1] 3715\n\nsummary(data %&gt;%\n    filter(!is.na(sexo)) %&gt;%\n    select(sexo) %&gt;%\n    mutate(sexo = as.factor(sexo)))\n\n      sexo     \n Hombres:2637  \n Mujeres:1078  \n\ndata %&gt;%\n    filter(!is.na(sexo)) %&gt;%\n    mutate(cont = 1) %&gt;%\n    group_by(sexo, year) %&gt;%\n    mutate(tsex = sum(cont, na.rm = T)) %&gt;%\n    group_by(sexo, year, clasificacion, tsex) %&gt;%\n    summarise(tclas = n()) %&gt;%\n    ungroup() %&gt;%\n    mutate(porc = tclas / tsex) %&gt;%\n    ggplot(aes(x = sexo, y = porc, fill = clasificacion)) +\n    geom_bar(position = \"dodge\", stat = \"identity\") +\n    scale_fill_manual(values = colores) +\n    scale_y_continuous(labels = percent_format()) +\n    coord_flip() +\n    facet_grid(. ~ year) +\n    theme(legend.position = \"bottom\") +\n    theme_classic() +\n    labs(\n        title = \"Solicitudes por tema y sexo\",\n        subtitle = \"Dividido por año\",\n        x = \"\", y = \"\", fill = \"Clasificación\",\n        caption = \"Solo se consideran solicitudes con información sobre el sexo de la persona solicitante\\nTotal de observaciones = 3,715\"\n    )\n\n`summarise()` has grouped output by 'sexo', 'year', 'clasificacion'. You can\noverride using the `.groups` argument.\n\n\n\n\n\n\n\n\n\nAlgo que me parece fundamental es que solo el 71.9% de las solicitudes pusieron información sobre el sexo de la persona solicitante. Y de estas solicitudes, el 70.98% fueron realizadas por personas que se identifican como hombres.\nPor último, vamos a ver el comportamiento de las solicitudes por mes de los años en cuestión.\n\ndata %&gt;%\n    mutate(\n        mes = month(fecha_presentacion)\n    ) %&gt;%\n    group_by(year, mes, clasificacion) %&gt;%\n    summarise(total = n()) %&gt;%\n    filter(year == 2017) %&gt;%\n    ungroup() %&gt;%\n    ggplot(aes(x = as.factor(mes), y = total, group = clasificacion)) +\n    geom_point(aes(color = clasificacion)) +\n    geom_line(aes(color = clasificacion)) +\n    scale_color_manual(\n        name = \"Clasificación\",\n        values = colores\n    ) +\n    scale_x_discrete(labels = c(\"Septiembre\", \"Octubre\", \"Noviembre\", \"Diciembre\")) +\n    labs(\n        title = \"Total de solicitudes por mes\",\n        subtitle = \"2017\",\n        x = \"\", y = \"\"\n    ) +\n    theme_classic() +\n    theme(legend.position = \"bottom\")\n\n`summarise()` has grouped output by 'year', 'mes'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\n\n\nDe esta gráfica lo más interesante es que en septiembre casi no hay solicitudes registradas, lo cual es bastante obvio porque estabaos en medio de una emergencia. Además, en todas estas gráficas utilizo números absolutos. El mes con más registros es octubre de 2017. En los años siguientes el pico nunca es tan alto.\n\ndata %&gt;%\n    mutate(\n        mes = month(fecha_presentacion)\n    ) %&gt;%\n    group_by(year, mes, clasificacion) %&gt;%\n    summarise(total = n()) %&gt;%\n    filter(year == 2018) %&gt;%\n    ungroup() %&gt;%\n    ggplot(aes(x = as.factor(mes), y = total, group = clasificacion)) +\n    geom_point(aes(color = clasificacion)) +\n    geom_line(aes(color = clasificacion)) +\n    scale_color_manual(\n        name = \"Clasificación\",\n        values = colores\n    ) +\n    scale_x_discrete(labels = c(\n        \"Enero\", \"Febrero\", \"Marzo\", \"Abril\", \"Mayo\", \"Junio\",\n        \"Julio\", \"Agosto\", \"Septiembre\", \"Octubre\", \"Noviembre\", \"Diciembre\"\n    )) +\n    labs(\n        title = \"Total de solicitudes por mes\",\n        subtitle = \"2018\",\n        x = \"\", y = \"\"\n    ) +\n    theme_classic() +\n    theme(\n        axis.text.x = element_text(angle = 45, hjust = 0.9),\n        legend.position = \"bottom\"\n    )\n\n`summarise()` has grouped output by 'year', 'mes'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\n\n\n\ndata %&gt;%\n    mutate(\n        mes = month(fecha_presentacion)\n    ) %&gt;%\n    group_by(year, mes, clasificacion) %&gt;%\n    summarise(total = n()) %&gt;%\n    filter(year == 2019) %&gt;%\n    ungroup() %&gt;%\n    ggplot(aes(x = as.factor(mes), y = total, group = clasificacion)) +\n    geom_point(aes(color = clasificacion)) +\n    geom_line(aes(color = clasificacion)) +\n    scale_color_manual(\n        name = \"Clasificación\",\n        values = colores\n    ) +\n    scale_x_discrete(labels = c(\n        \"Enero\", \"Febrero\", \"Marzo\", \"Abril\", \"Mayo\", \"Junio\",\n        \"Julio\", \"Agosto\", \"Septiembre\", \"Octubre\", \"Noviembre\", \"Diciembre\"\n    )) +\n    labs(\n        title = \"Total de solicitudes por mes\",\n        subtitle = \"2019\",\n        x = \"\", y = \"\"\n    ) +\n    theme_classic() +\n    theme(\n        axis.text.x = element_text(angle = 45, hjust = 0.9),\n        legend.position = \"bottom\"\n    )\n\n`summarise()` has grouped output by 'year', 'mes'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\n\n\nCon estas gráficas podemos empezar a plantear preguntas más interesantes. Además, es un esfuerzo institucional. Al igual que todos los datos, necesitamos más contexto para poder realizar preguntas más interesantes. Hay más categorías en estas bases de datos, como ocupación, días hábiles en los que se dio respuesta, número de servidores públicos involucrados, etc. En lo que aprendo mejor text mining una primera aproximación es ver estas gráficas."
  },
  {
    "objectID": "posts/sip-3-anios-reconstruccion/index.html#libraries-o-paquetes",
    "href": "posts/sip-3-anios-reconstruccion/index.html#libraries-o-paquetes",
    "title": "A 3 años del sismo en la CDMX",
    "section": "",
    "text": "library(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(purrr)\n\nWarning: package 'purrr' was built under R version 4.2.3\n\nlibrary(scales)\n\n\nAttaching package: 'scales'\n\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nlibrary(readxl)\nlibrary(stringr)\n\nWarning: package 'stringr' was built under R version 4.2.3\n\nlibrary(ggplot2)\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\n\nComo siempre, lo primero es “llamar” los paquetes. Y luego, definir los “directorios”, es decir las carpetas donde tenemos los archivos que vamos a trabajar. Por eso es muy importante que tengan orden en sus carpetas, sino puede ser muy complicado trabajar.\nIntenté hacerlo con setwd(), que es la manera base, pero la verdad era demasiado escribir y copiar. Si quieren intentarlo tendrían que poner algo así: setwd(“/Users/equipo/carpeta/Bases de SIP sobre reconstrucción en la CDMX”).\nPero yo, como siempre, haré que mis directorios sean objetos de r:\n\ninput &lt;- \"D:/dhumb/Documents/projects/data_blog/Bases de SIP sobre reconstrucción en la CDMX\"\nlist.files(input)\n\n[1] \"2017\"                                                                \n[2] \"2017 final.xlsx\"                                                     \n[3] \"2018\"                                                                \n[4] \"2018 final.xlsx\"                                                     \n[5] \"2019\"                                                                \n[6] \"2019 final.xlsx\"                                                     \n[7] \"2020.09.03_Nota-Criterios de_Bases SIP-Reconstrucción 2017-2019.docx\"\n[8] \"Bases de SIP sobre reconstrucción en la CDMX.rar\"                    \n[9] \"Reconstruccion consolidada.xlsx\"                                     \n\n\nPuse un punto “.” porque para publicar esto r siempre me pone un directorio default, entonces el punto significa lo mismo que copiar este directorio. Y quiero que exploremos esta manera de utilizar directorios.\nAhora, podemos hacer varias cosas: dado que en la carpeta que descomprimimos viene un único archivo con todas las solicitudes de información, obviamente sería más fácil trabajar así. Pero, no aprenderíamos a trabajar con múltiples archivos al mismo tiempo.\nEntonces, vamos a utilizar las carpetas con los archivos individuales. De este modo, podríamos “leer” cada archivo de manera individual de la siguiente manera:\n\narchivo1 &lt;- read_excel(path = paste0(input, \"/2017/Delegación Álvaro Obregón-2017.xlsx\"))\nlist.files(paste(input, \"2017\", sep = \"/\"))\n\n [1] \"Delegación Álvaro Obregón-2017.xlsx\"                                                  \n [2] \"Delegación Azcapotzalco-2017.xlsx\"                                                    \n [3] \"Delegación Benito Juárez-2017.xlsx\"                                                   \n [4] \"Delegación Coyoacán-2017.xlsx\"                                                        \n [5] \"Delegación Cuajimalpa de Morelos-2017.xlsx\"                                           \n [6] \"Delegación Cuauhtémoc-2017.xlsx\"                                                      \n [7] \"Delegación Gustavo A. Madero-2017.xlsx\"                                               \n [8] \"Delegación Iztacalco-2017.xlsx\"                                                       \n [9] \"Delegación Iztapalapa-2017.xlsx\"                                                      \n[10] \"Delegación La Magdalena Contreras-2017.xlsx\"                                          \n[11] \"Delegación Miguel Hidalgo-2017.xlsx\"                                                  \n[12] \"Delegación Milpa Alta-2017.xlsx\"                                                      \n[13] \"Delegación Tláhuac-2017.xlsx\"                                                         \n[14] \"Delegación Tlalpan-2017.xlsx\"                                                         \n[15] \"Delegación Venustiano Carranza-2017.xlsx\"                                             \n[16] \"Delegación Xochimilco-2017.xlsx\"                                                      \n[17] \"Instituto de Vivienda del Distrito Federal-2017.xlsx\"                                 \n[18] \"Instituto Local de la Infraestructura Física Educativa del Distrito Federal-2017.xlsx\"\n[19] \"Instituto para la Seguridad de las Construcciones en el Distrito Federal-2017.xlsx\"   \n[20] \"Jefatura de Gobierno del Distrito Federal-2017.xlsx\"                                  \n[21] \"Secretaría de Desarrollo Urbano y Vivienda-2017.xlsx\"                                 \n[22] \"Secretaría de Educación-2017.xlsx\"                                                    \n[23] \"Secretaría de Obras y Servicios-2017.xlsx\"                                            \n\n\nLo primero que podemos notar es que son 23 archivos para el año 2017… Entonces, cargar cada archivo, sabiendo que tienen la misma estructura, es poco eficiente, especialmente si pensamos que todavía nos faltan los datos de 2018 y 2019.\n\nlist.files(paste(input, \"2018\", sep = \"/\"))\n\n [1] \"Comisión para la Reconstrucción-2018.xlsx\"                                                                                           \n [2] \"Comisión para la Reconstrucción, Recuperación y Transformación de la Ciudad de México, en una CDMX cada vez más resiliente-2018.xlsx\"\n [3] \"Delegación Álvaro Obregón-2018.xlsx\"                                                                                                 \n [4] \"Delegación Azcapotzalco-2018.xlsx\"                                                                                                   \n [5] \"Delegación Benito Juárez-2018.xlsx\"                                                                                                  \n [6] \"Delegación Coyoacán-2018.xlsx\"                                                                                                       \n [7] \"Delegación Cuajimalpa de Morelos-2018.xlsx\"                                                                                          \n [8] \"Delegación Cuauhtémoc-2018.xlsx\"                                                                                                     \n [9] \"Delegación Gustavo A. Madero-2018.xlsx\"                                                                                              \n[10] \"Delegación Iztacalco-2018.xlsx\"                                                                                                      \n[11] \"Delegación Iztapalapa-2018.xlsx\"                                                                                                     \n[12] \"Delegación La Magdalena Contreras-2018.xlsx\"                                                                                         \n[13] \"Delegación Miguel Hidalgo-2018.xlsx\"                                                                                                 \n[14] \"Delegación Milpa Alta-2018.xlsx\"                                                                                                     \n[15] \"Delegación Tláhuac-2018.xlsx\"                                                                                                        \n[16] \"Delegación Tlalpan-2018.xlsx\"                                                                                                        \n[17] \"Delegación Venustiano Carranza-2018.xlsx\"                                                                                            \n[18] \"Delegación Xochimilco-2018.xlsx\"                                                                                                     \n[19] \"Instituto de Vivienda del Distrito Federal-2018.xlsx\"                                                                                \n[20] \"Instituto Local de la Infraestructura Física Educativa del Distrito Federal-2018.xlsx\"                                               \n[21] \"Instituto para la Seguridad de las Construcciones en el Distrito Federal-2018.xlsx\"                                                  \n[22] \"Jefatura de Gobierno del Distrito Federal-2018.xlsx\"                                                                                 \n[23] \"Secretaría de Desarrollo Urbano y Vivienda-2018.xlsx\"                                                                                \n[24] \"Secretaría de Educación-2018.xlsx\"                                                                                                   \n[25] \"Secretaría de Obras y Servicios-2018.xlsx\"                                                                                           \n\n\n\nlist.files(paste(input, \"2019\", sep = \"/\"))\n\n [1] \"Alcaldía Álvaro Obregón-2019.xlsx\"                                                                                                   \n [2] \"Alcaldía Azcapotzalco-2019.xlsx\"                                                                                                     \n [3] \"Alcaldía Benito Juárez-2019.xlsx\"                                                                                                    \n [4] \"Alcaldía Coyoacán-2019.xlsx\"                                                                                                         \n [5] \"Alcaldía Cuajimalpa de Morelos-2019.xlsx\"                                                                                            \n [6] \"Alcaldía Cuauhtémoc-2019.xlsx\"                                                                                                       \n [7] \"Alcaldía Gustavo A. Madero-2019.xlsx\"                                                                                                \n [8] \"Alcaldía Iztacalco-2019.xlsx\"                                                                                                        \n [9] \"Alcaldía Iztapalapa-2019.xlsx\"                                                                                                       \n[10] \"Alcaldía La Magdalena Contreras-2019.xlsx\"                                                                                           \n[11] \"Alcaldía Miguel Hidalgo-2019.xlsx\"                                                                                                   \n[12] \"Alcaldía Milpa Alta-2019.xlsx\"                                                                                                       \n[13] \"Alcaldía Tláhuac-2019.xlsx\"                                                                                                          \n[14] \"Alcaldía Tlalpan-2019.xlsx\"                                                                                                          \n[15] \"Alcaldía Venustiano Carranza-2019.xlsx\"                                                                                              \n[16] \"Alcaldía Xochimilco-2019.xlsx\"                                                                                                       \n[17] \"Comisión para la Reconstrucción-2019.xlsx\"                                                                                           \n[18] \"Comisión para la Reconstrucción, Recuperación y Transformación de la Ciudad de México, en una CDMX cada vez más resiliente-2019.xlsx\"\n[19] \"Instituto de Vivienda de la Ciudad de México-2019.xlsx\"                                                                              \n[20] \"Instituto Local de la Infraestructura Física Educativa de la Ciudad de México-2019.xlsx\"                                             \n[21] \"Instituto para la Seguridad de las Construcciones en la Ciudad de México-2019.xlsx\"                                                  \n[22] \"Jefatura de Gobierno de la Ciudad de México-2019.xlsx\"                                                                               \n[23] \"Secretaría de Administración y Finanzas-2019.xlsx\"                                                                                   \n[24] \"Secretaría de Desarrollo Urbano y Vivienda-2019.xlsx\"                                                                                \n[25] \"Secretaría de Educación, Ciencia, Tecnología e Innovación-2019.xlsx\"                                                                 \n[26] \"Secretaría de Gestión Integral de Riesgos y Protección Civil-2019.xlsx\"                                                              \n[27] \"Secretaría de Inclusión y Bienestar Social-2019.xlsx\"                                                                                \n[28] \"Secretaría de Obras y Servicios-2019.xlsx\"                                                                                           \n\n\nParece intimidante, ¿no? Leer 74 archivos para empezar a trabajar… Pero para eso tenemos purrr."
  },
  {
    "objectID": "posts/sip-3-anios-reconstruccion/index.html#purrrmap",
    "href": "posts/sip-3-anios-reconstruccion/index.html#purrrmap",
    "title": "A 3 años del sismo en la CDMX",
    "section": "",
    "text": "Este paquete nos permite realizar tareas de Functional programming una palabra elegante para decir realizar tareas repetitivas de manera más rápida y eficiente. Pueden consultar la documentación aquí.\n\nprimer &lt;- list.files(paste(input, \"2017\", sep = \"/\"))\n\nprimer_e &lt;- map(\n    primer,\n    ~ read_excel(path = paste(input, \"2017\", .x, sep = \"/\"))\n)\n# View(primer_e)\n\nCon este código ya abrimos los 23 archivos de excel :D\nPero, aún no podemos usarlos como base de datos :(\nEsto se debe a que map es una función especial de purrr. Ya vimos lo que hace, pero no sabemos por qué.\nmap nos permite aplicar una función a todos los elementos de una lista o vector que nosotros le proporcionemos. En este caso, utilicé list.files para crear un objeto llamado primer.\nLuego, le decimos que función queremos que aplique. Como queremos que learchivos en formato xlsx (exceles), le ponemos read_excel. Y aquí vamos a repasar todo. Esta función tiene un montón de parámetros para leer exceles. Pero por ahora nos importa uno: donde está el archivo path = . Aquí utilicé una función paste que sirve para pegar strings lo que nos permite abrir los archivos de Excel.\n\ninput, como mencioné, es la carpeta con todos los datos descomprimidos.\n2017 es la carpeta del año con los archivos individuales\n.x es un argumento de la función map es el i-esímo objeto al que le aplicaremos la función. Como espero hayas notado, primer es el objeto con la lista de archivos excel dentro de la carpeta, por eso necesito el paste para que vaya cambiando. En otras palabras, el .x es la variable que irá cambiando hasta que termine de leer los archivos.\n\nAhora lo que queremos es poder utilizar los datos como siempre, en un data frame.\n\nprimer_f &lt;- bind_rows(primer_e)\n\ndim(primer_f)\n\n[1] 2541   40\n\n\nComo sabemos que todo tiene la misma estructura, podemos combinar los archivos por renglones. Estamos pegando un archivo debajo de otro, debajo de otro y así, siempre y cuando tengan los mismos encabezados. Esto último es fundamental porque bind_rows es un función de dplyr y si no tienen los mismos encabezados y dimensiones no podríamos hacerlo. No es como su “primo” cbind de r base, que solo necesita que tenga el mismo número de columnas y lo une como esté. A veces la utilizaremos, pero necesitamos estar seguras de cómo y cuándo.\nSólo falta hacer lo mismo para los otros años:\n\nsegundo &lt;- list.files(paste(input, \"2018\", sep = \"/\"))\n\nsegundo_e &lt;- map(\n    segundo,\n    ~ read_excel(path = paste(input, \"2018\", .x, sep = \"/\"))\n)\n\nsegundo_f &lt;- bind_rows(segundo_e)\n\ndim(segundo_f)\n\n[1] 3241   40\n\ntercer &lt;- list.files(paste(input, \"2019\", sep = \"/\"))\n\ntercer_e &lt;- map(\n    tercer,\n    ~ read_excel(path = paste(input, \"2019\", .x, sep = \"/\"))\n)\n\ntercer_f &lt;- bind_rows(tercer_e)\n\ndim(tercer_f)\n\n[1] 1717   40\n\n\nEn el caso de 2018, les va a salir un error, y es que el nombre del primer archivo es exageradamente largo: “Comisión para la Reconstrucción, Recuperación y Transformación de la Ciudad de México, en una CDMX cada vez más resiliente-2018.xlsx” por eso hay que cambiarlo a mano en nuestra carpeta. A map no le importa los nombres de los archivos, pero sí la longitud de los strings. Si creen que el nombre es demasiado largo, tal vez tengan razón. Porque lo mismo pasa para el 2019: “Comisión para la Reconstrucción, Recuperación y Transformación de la Ciudad de México, en una CDMX cada vez más resiliente-2019.xlsx”\nY todas tienen 40 columnas, entonces, el siguiente paso es más fácil. Ahora tenemos 3 archivos, uno correspondiente a cada año. Pero, generalmente, es más fácil tener todo dentro de una sola base de datos.\n\ndata &lt;- bind_rows(primer_f, segundo_f, tercer_f)\n\ndim(data)\n\n[1] 7499   40"
  },
  {
    "objectID": "posts/sip-3-anios-reconstruccion/index.html#gráficas",
    "href": "posts/sip-3-anios-reconstruccion/index.html#gráficas",
    "title": "A 3 años del sismo en la CDMX",
    "section": "",
    "text": "Ahora tenemos una base de datos con 6,819 renglones y 40 columnas. Y con esto podemos ponernos a hacer algunas gráficas.\nPero, hay un pequeño, pequeñísimo problema… Los nombres de las columnas.\n\nnames(data)\n\n [1] \"No.\"                                                                                                                  \n [2] \"Sujeto_N\"                                                                                                             \n [3] \"Sujeto\"                                                                                                               \n [4] \"Organo_N\"                                                                                                             \n [5] \"Clave\"                                                                                                                \n [6] \"Propio\"                                                                                                               \n [7] \"( A )\\r\\n\\r\\nFolio\"                                                                                                   \n [8] \"( B )\\r\\n\\r\\nFecha de presentación de la solicitud\\r\\n\\r\\ndd/mm/aaaa\"                                                 \n [9] \"( C )\\r\\n\\r\\nMedio por el que se presentó la solicitud\"                                                               \n[10] \"( D )\\r\\n\\r\\nInformación objeto de la solicitud \\r\\n\\r\\n(PROTEGER EN TODO MOMENTO LOS DATOS PERSONALES)\"              \n[11] \"( E )\\r\\n\\r\\nN° de preguntas que comprende la solicitud\"                                                              \n[12] \"( F )\\r\\n\\r\\nTemática de la información requerida\"                                                                    \n[13] \"( F_1 )\\r\\n\\r\\nÁrea de interés del Solictante\"                                                                        \n[14] \"( G )\\r\\n\\r\\nLa información solicitada fue de oficio\"                                                                 \n[15] \"( H )\\r\\n\\r\\nEstado en que se encontraba la solicitud\"                                                                \n[16] \"prevencion_solicitante\"                                                                                               \n[17] \"( I_1 )\\r\\n\\r\\nFecha en la que el solicitante atendió la prevención\"                                                  \n[18] \"( I_2 )\\r\\n\\r\\n¿La solicitud de información pública fue prevenida total o parcialmente?\"                              \n[19] \"( I_3 )\\r\\n\\r\\nNúmero de preguntas fueron prevenidas\"                                                                 \n[20] \"( J )\\r\\n\\r\\n¿Se notificó al solicitante ampliación de plazo para entregar la información?\"                           \n[21] \"( K )\\r\\n\\r\\nModalidad de repuesta\"                                                                                   \n[22] \"( L_1 ) \\r\\n\\r\\nTotal de Entes públicos a los que se turnó la solicitud\"                                              \n[23] \"( L_2 ) \\r\\n\\r\\nEnte Público al \\r\\nque se turnó la solicitud\"                                                        \n[24] \"( M )\\r\\n\\r\\n¿Se entregó o se envió por algún medio la información al solicitante?\"                                   \n[25] \"( N )\\r\\n\\r\\nPara la entrega de información, ¿se le requirió al solicitante algún monto por concepto de reproducción?\"\n[26] \"( O )\\r\\n\\r\\nMonto total requerido por concepto de reproducción\"                                                      \n[27] \"( P )\\r\\n\\r\\nMedio por el que se puso a disposición la información solicitada\"                                        \n[28] \"( Q )\\r\\n\\r\\nFecha en que se notificó la respuesta o se turnó la solicitud\\r\\n\\r\\ndd/mm/aaaa\"                         \n[29] \"( R )\\r\\n\\r\\nMedio por el que se notificó la respuesta\"                                                               \n[30] \"( S )\\r\\n\\r\\nDías HÁBILES  transcurridos entre la recepción de la solicitud y la notificación de respuesta\"           \n[31] \"( T )\\r\\n\\r\\nNo. de Servidores Públicos directamente involucrados en la respuesta de la solicitud\"                    \n[32] \"( U )\\r\\n\\r\\nSexo del solicitante\"                                                                                    \n[33] \"( V )\\r\\n\\r\\nEdad del solicitante\"                                                                                    \n[34] \"( W )\\r\\n\\r\\nOcupación del solicitante\"                                                                               \n[35] \"( X )\\r\\n\\r\\nEscolaridad del solicitante\"                                                                             \n[36] \"( Y )\\r\\n\\r\\nEstado de la República Mexicana o país que corresponde a la dirección que registró el solicitante\"       \n[37] \"( Z )\\r\\n\\r\\nObservaciones\"                                                                                           \n[38] \"mes\"                                                                                                                  \n[39] \"year\"                                                                                                                 \n[40] \"clasificacion\"                                                                                                        \n\n\nAquí, sí se ven las diagonales inversas, si lo abren en excel verán que está en varios renglones, pero esto es muy difícil de trabajar en r. Para solucionar esto, vamos a cambiarle los nombres a todas las variables.\n\nnombres &lt;- c(\n    \"No.\",\n    \"Sujeto_N\",\n    \"Sujeto\",\n    \"Organo_N\",\n    \"clave\",\n    \"propio\",\n    \"Folio\",\n    \"fecha_presentacion\",\n    \"Medio_presento\",\n    \"Informacion_objeto\",\n    \"Preguntas_solicitud\",\n    \"Tematica_solicitud\",\n    \"Area_interes\",\n    \"info_de_oficio\",\n    \"Estado_info\",\n    \"prevencion_solicitante\",\n    \"fecha_prevencion\",\n    \"solicitud_prevenida\",\n    \"preguntas_prevenidas\",\n    \"notificar_ampliacion\",\n    \"modalidad_respuesta\",\n    \"total_entes_turnados\",\n    \"ente_turnado\",\n    \"info_entregada\",\n    \"costo_reproduccion\",\n    \"monto_reproduccion\",\n    \"medio_disposicion_info\",\n    \"fecha_notificacion\",\n    \"medio_notificacion\",\n    \"dias_transcurridos_recepcion_notificacion\",\n    \"Servidores_publicos_involucrados\",\n    \"sexo\",\n    \"edad\",\n    \"ocupacion\",\n    \"escolaridad\",\n    \"entidad_federativa\",\n    \"observaciones\",\n    \"mes\",\n    \"year\",\n    \"clasificacion\"\n)\n\nnames(data) &lt;- nombres\n\nPuse cada nombre en un reglón y un espacio cada 5 nombres, para no perderme, si se saben otra manera avísenme :P\nAdemás de cambiarle el nombre, vamos a utilizar la forma en que se procesan los datos: cambiar categorías, agrupar, crear nuevas variables, etc. Esto lo voy a hacer porque estoy familiarizado con este procesamiento. Creo que el código es autoexplicativo, pero si tienen alguna duda mandenme un DM en twitter.\n\ndata &lt;- data %&gt;%\n    mutate(semana = week(fecha_presentacion)) %&gt;%\n    group_by(year, Sujeto_N, semana) %&gt;%\n    distinct(Informacion_objeto, .keep_all = T) %&gt;%\n    ungroup() %&gt;%\n    mutate(\n        clasificacion = str_replace_all(\n            clasificacion,\n            c(\n                \"daños\" = \"Daños\", \"evaluacion\" = \"Evaluación\",\n                \"fondos\" = \"Fondos\", \"legalidad\" = \"Legalidad\",\n                \"prevencion\" = \"Prevención\", \"reconstruccion\" = \"Reconstrucción\",\n                \"respuesta al sismo\" = \"Respuesta al sismo\"\n            )\n        ),\n        Tematica_solicitud = ifelse(str_detect(Tematica_solicitud, \"Otros\") == T,\n            \"Otros\",\n            ifelse(Tematica_solicitud == \"Datos Personales\",\n                \"Otros\", Tematica_solicitud\n            )\n        ),\n        modalidad_respuesta_2 = ifelse(str_detect(modalidad_respuesta, \"Aceptada\") == T,\n            \"Aceptada\",\n            ifelse(str_detect(modalidad_respuesta, \"restringido\") == T,\n                \"Acceso restringido\", modalidad_respuesta\n            )\n        ),\n        edad = as.numeric(edad),\n        grupo_edad = ifelse(edad &lt;= 19, \"Hasta 19 años\",\n            ifelse(edad &gt; 19 & edad &lt; 30, \"De 20 a 29 años\",\n                ifelse(edad &gt;= 30 & edad &lt; 40, \"De 30 a 39 años\",\n                    ifelse(edad &gt;= 40 & edad &lt; 50, \"De 40 a 49 años\",\n                        ifelse(edad &gt;= 50 & edad &lt; 60, \"De 50 a 59 años\",\n                            ifelse(edad &gt;= 60 & edad &lt; 70, \"De 60 a 69 años\",\n                                ifelse(edad &gt;= 70, \"70 o mas años\", edad)\n                            )\n                        )\n                    )\n                )\n            )\n        ),\n        grupo_edad = factor(grupo_edad, levels = c(\n            \"Hasta 19 años\", \"De 20 a 29 años\", \"De 30 a 39 años\",\n            \"De 40 a 49 años\", \"De 50 a 59 años\", \"De 60 a 69 años\",\n            \"70 o mas años\"\n        )),\n        escolaridad = str_replace_all(escolaridad, c(\n            \"Bachillerato o carrera técnica\" = \"Bachillerato\",\n            \"Bachillerato\" = \"Bachillerato o carrera técnica\",\n            \"Maestría o Doctorado\" = \"Maestría o doctorado\"\n        )),\n        ocupacion = str_replace_all(ocupacion, c(\n            \"Otros - Amas de Casa\" = \"Hogar\",\n            \"Otros - Organizaciones No Gubernamentales Internacionales\" = \"ONG\",\n            \"Otros - Organizaciones No Gubernamentales Nacionales\" = \"ONG\",\n            \"Otros - Asociación política\" = \"Asociación política\",\n            \"Servidor Público\" = \"Servicio público\",\n            \"Otros - Comerciante\" = \"Comercio\",\n            \"Otros - Empleado u obrero\" = \"Empleada/o u obrera/o\",\n            \"Empleado u obrero\" = \"Empleada/o u obrera/o\"\n        )),\n        ocupacion = ifelse(str_detect(ocupacion, \"Académico\") == T, \"Académico o estudiante\",\n            ifelse(str_detect(ocupacion, \"Empresarial\") == T, \"Empresa\",\n                ifelse(str_detect(ocupacion, \"Gubernamental\") == T, \"Servicio público\",\n                    ifelse(str_detect(ocupacion, \"omunicación\") == T, \"Medios de comunicación\",\n                        ifelse(str_detect(ocupacion, \"Otro\") == T, \"Otro\", ocupacion)\n                    )\n                )\n            )\n        ),\n        Organo_N = str_replace_all(Organo_N, c(\n            \"1\" = \"Administración Pública Central\",\n            \"2\" = \"Desconcentrados y Paraestales\",\n            \"3\" = \"Alcaldías\",\n            \"4\" = \"Judicial\",\n            \"5\" = \"Legislativo\",\n            \"6\" = \"Autónomo\",\n            \"7\" = \"Partidos Políticos\",\n            \"8\" = \"Sindicatos\"\n        )),\n        Preguntas_solicitud = as.numeric(Preguntas_solicitud),\n        preguntas_prevenidas = as.numeric(preguntas_prevenidas),\n        total_entes_turnados = as.numeric(total_entes_turnados),\n        info_entregada_2 = ifelse(str_detect(info_entregada, \"No\"), \"No\",\n            ifelse(str_detect(info_entregada, \"Si\"),\n                \"S?\", info_entregada\n            )\n        ),\n        dias_transcurridos_recepcion_notificacion =\n            as.numeric(dias_transcurridos_recepcion_notificacion),\n        Servidores_publicos_involucrados = as.numeric(Servidores_publicos_involucrados),\n        sexo = str_replace_all(sexo, c(\"Femenino\" = \"Mujeres\", \"Masculino\" = \"Hombres\"))\n    )\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `preguntas_prevenidas = as.numeric(preguntas_prevenidas)`.\nCaused by warning:\n! NAs introduced by coercion\n\ndim(data)\n\n[1] 5168   44\n\n\nLo que me gustaría enfatizar son las primeras 5 líneas de código. Yo revise esta base de datos y sé que hay muchas solicitudes repetidas. Pero, no puedo descartarlas solo por el hecho de estar repetidas. Quizás una persona estuvo realizando la misma solicitud sistemáticamente cada semana, o quizás a una persona se le fue el internet al terminar y realizó exactamente la misma solicitud. Por esa razón, y siguiendo los criterios del Natalia Torres y Guillermo Cejudo para que solo se quede una solicitud con el mismo texto a la semana. Es decir, si es idéntico el texto de dos solicitudes con folio diferentes, y se presentó en la misma semana, solo se contará la más antigua.\n\ncolores &lt;- c(\n    \"Daños\" = \"#ae3a3d\", \"Evaluación\" = \"#fc8d33\",\n    \"Fondos\" = \"#faef59\", \"Legalidad\" = \"#bcfa3d\",\n    \"Prevención\" = \"#4fc6c4\", \"Reconstrucción\" = \"#FF0066\",\n    \"Respuesta al sismo\" = \"#6600cc\"\n)\n\nCódigos de colores para que todas las gráficas estén uniformes.\n\ndata %&gt;%\n    group_by(year) %&gt;%\n    mutate(tyear = n()) %&gt;%\n    group_by(year, clasificacion, tyear) %&gt;%\n    summarise(tclas = n()) %&gt;%\n    ungroup() %&gt;%\n    mutate(porc = tclas / tyear) %&gt;%\n    ggplot(aes(x = year, y = porc, fill = clasificacion)) +\n    geom_bar(position = \"dodge\", stat = \"identity\") +\n    scale_y_continuous(labels = percent_format()) +\n    scale_fill_manual(values = colores) +\n    theme(legend.position = \"bottom\") +\n    theme_classic() +\n    labs(\n        title = \"Solicitudes por tema\",\n        subtitle = \"Dividido por año\",\n        x = \"\", y = \"\", fill = \"Clasificación\",\n        caption = \"Incluye personas que no proporcionaron información sociodemográfica.\\nTotal de observaciones = 5,168\"\n    )\n\n`summarise()` has grouped output by 'year', 'clasificacion'. You can override\nusing the `.groups` argument.\n\n\n\n\n\n\n\n\n\nAhora, aquí vemos que las solicitudes se concentran en un par de clasificaciones y R lo ajusta al tamaño de la pantalla. Pero acabo de leer un librito que les recomiendo mucho How charts lie: Getting Smarter about Visual Information sobre como entender mejor las gráficas y diseñarlas. En este sentido, quiero ver como se ve cuando el límite es 100%\n\ndata %&gt;%\n    group_by(year) %&gt;%\n    mutate(tyear = n()) %&gt;%\n    group_by(year, clasificacion, tyear) %&gt;%\n    summarise(tclas = n()) %&gt;%\n    ungroup() %&gt;%\n    mutate(porc = tclas / tyear) %&gt;%\n    ggplot(aes(x = year, y = porc, fill = clasificacion)) +\n    geom_bar(position = \"dodge\", stat = \"identity\") +\n    ylim(0, 1) +\n    scale_fill_manual(values = colores) +\n    theme(legend.position = \"bottom\") +\n    theme_classic() +\n    labs(\n        title = \"Solicitudes por tema\",\n        subtitle = \"Dividido por año\",\n        x = \"\", y = \"\", fill = \"Clasificación\",\n        caption = \"Incluye personas que no proporcionaron información sociodemográfica.\\nTotal de observaciones = 5,168\"\n    )\n\n`summarise()` has grouped output by 'year', 'clasificacion'. You can override\nusing the `.groups` argument.\n\n\n\n\n\n\n\n\n\nAquí ya no pude poner el eje “y” como me hubiera gustado, pero la idea es muliplicar la leyenda por 100 para convertirlo en porcentaje.\nPodemos darnos cuenta de que poniendo como límite el 100 pierde todo el impacto la gráfica. Por lo que dejarla acotada hasta el 40% nos da una mejor visión para comparar entre categorías. Jugar con las gráficas siempre nos da perspectiva.\n\nnrow(data %&gt;%\n    filter(!is.na(sexo)))\n\n[1] 3715\n\nsummary(data %&gt;%\n    filter(!is.na(sexo)) %&gt;%\n    select(sexo) %&gt;%\n    mutate(sexo = as.factor(sexo)))\n\n      sexo     \n Hombres:2637  \n Mujeres:1078  \n\ndata %&gt;%\n    filter(!is.na(sexo)) %&gt;%\n    mutate(cont = 1) %&gt;%\n    group_by(sexo, year) %&gt;%\n    mutate(tsex = sum(cont, na.rm = T)) %&gt;%\n    group_by(sexo, year, clasificacion, tsex) %&gt;%\n    summarise(tclas = n()) %&gt;%\n    ungroup() %&gt;%\n    mutate(porc = tclas / tsex) %&gt;%\n    ggplot(aes(x = sexo, y = porc, fill = clasificacion)) +\n    geom_bar(position = \"dodge\", stat = \"identity\") +\n    scale_fill_manual(values = colores) +\n    scale_y_continuous(labels = percent_format()) +\n    coord_flip() +\n    facet_grid(. ~ year) +\n    theme(legend.position = \"bottom\") +\n    theme_classic() +\n    labs(\n        title = \"Solicitudes por tema y sexo\",\n        subtitle = \"Dividido por año\",\n        x = \"\", y = \"\", fill = \"Clasificación\",\n        caption = \"Solo se consideran solicitudes con información sobre el sexo de la persona solicitante\\nTotal de observaciones = 3,715\"\n    )\n\n`summarise()` has grouped output by 'sexo', 'year', 'clasificacion'. You can\noverride using the `.groups` argument.\n\n\n\n\n\n\n\n\n\nAlgo que me parece fundamental es que solo el 71.9% de las solicitudes pusieron información sobre el sexo de la persona solicitante. Y de estas solicitudes, el 70.98% fueron realizadas por personas que se identifican como hombres.\nPor último, vamos a ver el comportamiento de las solicitudes por mes de los años en cuestión.\n\ndata %&gt;%\n    mutate(\n        mes = month(fecha_presentacion)\n    ) %&gt;%\n    group_by(year, mes, clasificacion) %&gt;%\n    summarise(total = n()) %&gt;%\n    filter(year == 2017) %&gt;%\n    ungroup() %&gt;%\n    ggplot(aes(x = as.factor(mes), y = total, group = clasificacion)) +\n    geom_point(aes(color = clasificacion)) +\n    geom_line(aes(color = clasificacion)) +\n    scale_color_manual(\n        name = \"Clasificación\",\n        values = colores\n    ) +\n    scale_x_discrete(labels = c(\"Septiembre\", \"Octubre\", \"Noviembre\", \"Diciembre\")) +\n    labs(\n        title = \"Total de solicitudes por mes\",\n        subtitle = \"2017\",\n        x = \"\", y = \"\"\n    ) +\n    theme_classic() +\n    theme(legend.position = \"bottom\")\n\n`summarise()` has grouped output by 'year', 'mes'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\n\n\nDe esta gráfica lo más interesante es que en septiembre casi no hay solicitudes registradas, lo cual es bastante obvio porque estabaos en medio de una emergencia. Además, en todas estas gráficas utilizo números absolutos. El mes con más registros es octubre de 2017. En los años siguientes el pico nunca es tan alto.\n\ndata %&gt;%\n    mutate(\n        mes = month(fecha_presentacion)\n    ) %&gt;%\n    group_by(year, mes, clasificacion) %&gt;%\n    summarise(total = n()) %&gt;%\n    filter(year == 2018) %&gt;%\n    ungroup() %&gt;%\n    ggplot(aes(x = as.factor(mes), y = total, group = clasificacion)) +\n    geom_point(aes(color = clasificacion)) +\n    geom_line(aes(color = clasificacion)) +\n    scale_color_manual(\n        name = \"Clasificación\",\n        values = colores\n    ) +\n    scale_x_discrete(labels = c(\n        \"Enero\", \"Febrero\", \"Marzo\", \"Abril\", \"Mayo\", \"Junio\",\n        \"Julio\", \"Agosto\", \"Septiembre\", \"Octubre\", \"Noviembre\", \"Diciembre\"\n    )) +\n    labs(\n        title = \"Total de solicitudes por mes\",\n        subtitle = \"2018\",\n        x = \"\", y = \"\"\n    ) +\n    theme_classic() +\n    theme(\n        axis.text.x = element_text(angle = 45, hjust = 0.9),\n        legend.position = \"bottom\"\n    )\n\n`summarise()` has grouped output by 'year', 'mes'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\n\n\n\ndata %&gt;%\n    mutate(\n        mes = month(fecha_presentacion)\n    ) %&gt;%\n    group_by(year, mes, clasificacion) %&gt;%\n    summarise(total = n()) %&gt;%\n    filter(year == 2019) %&gt;%\n    ungroup() %&gt;%\n    ggplot(aes(x = as.factor(mes), y = total, group = clasificacion)) +\n    geom_point(aes(color = clasificacion)) +\n    geom_line(aes(color = clasificacion)) +\n    scale_color_manual(\n        name = \"Clasificación\",\n        values = colores\n    ) +\n    scale_x_discrete(labels = c(\n        \"Enero\", \"Febrero\", \"Marzo\", \"Abril\", \"Mayo\", \"Junio\",\n        \"Julio\", \"Agosto\", \"Septiembre\", \"Octubre\", \"Noviembre\", \"Diciembre\"\n    )) +\n    labs(\n        title = \"Total de solicitudes por mes\",\n        subtitle = \"2019\",\n        x = \"\", y = \"\"\n    ) +\n    theme_classic() +\n    theme(\n        axis.text.x = element_text(angle = 45, hjust = 0.9),\n        legend.position = \"bottom\"\n    )\n\n`summarise()` has grouped output by 'year', 'mes'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\n\n\nCon estas gráficas podemos empezar a plantear preguntas más interesantes. Además, es un esfuerzo institucional. Al igual que todos los datos, necesitamos más contexto para poder realizar preguntas más interesantes. Hay más categorías en estas bases de datos, como ocupación, días hábiles en los que se dio respuesta, número de servidores públicos involucrados, etc. En lo que aprendo mejor text mining una primera aproximación es ver estas gráficas."
  }
]